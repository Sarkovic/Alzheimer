{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import kerastuner as kt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline \n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"all_data_LSTM_full_feature.csv\")\n",
    "test=pd.read_csv(\"y_DX_month.csv\")\n",
    "df=df.sort_values(by='RID', ascending=True)\n",
    "test=test.sort_values(by='RID', ascending=True)\n",
    "groupby=df.groupby(\"RID\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.VISCODE2=='bl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['RID', 'VISCODE2'],axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=len(df.columns)\n",
    "y= np.array(test.DX_Month)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(df)\n",
    "x = scaler.transform(df)\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1))\n",
    "y = scaler2.fit_transform(pd.DataFrame(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     x, y, test_size=0.10, stratify= y, shuffle=True, random_state=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    num_units_min  =  200\n",
    "    num_units_max  =  1000\n",
    "    num_units_step =  50\n",
    "\n",
    "    dropout_min  =  .2\n",
    "    dropout_max  =  0.9\n",
    "    dropout_step =  0.1\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=hp.Int('unit1',  min_value=num_units_min,\n",
    "                                                 max_value=num_units_max,\n",
    "                                                 step=num_units_step),\n",
    "                                                 activation='relu',\n",
    "                                                 input_dim=num_features, \n",
    "                                                 kernel_initializer='normal', \n",
    "                                                 kernel_regularizer=keras.regularizers.l2(hp.Choice('reg_rate',values=[0.01, 0.05, 0.1]))\n",
    "                          \n",
    "                                               ))\n",
    "    model.add(layers.Dropout(hp.Float('dropout_1',min_value=dropout_min,\n",
    "                                      max_value=dropout_max,\n",
    "                                      step=dropout_step) ) )\n",
    " \n",
    " \n",
    "    model.add(layers.Flatten())\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        model.add(layers.Dense(units=hp.Int('unitsdense_'+ str(i),\n",
    "                                            min_value=200,\n",
    "                                            max_value=800,\n",
    "                                            step=200),\n",
    "                                            activation='relu',\n",
    "                              kernel_regularizer=keras.regularizers.l2(hp.Choice('reg_rate1',values=[0.01, 0.05, 0.1]))))   \n",
    "        model.add(layers.Dropout(hp.Float('dropoutdense_'+ str(i), \n",
    "                                      min_value=dropout_min,\n",
    "                                      max_value=dropout_max,\n",
    "                                      step=dropout_step)))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[ 1e-4])),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\hager\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\hager\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='mean_squared_error',\n",
    "    max_trials=4,\n",
    "    project_name='hager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000001A7434A02E0> and <tensorflow.python.keras.layers.core.Dropout object at 0x000001A744DC6610>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000001A744DB7CD0> and <tensorflow.python.keras.layers.core.Dropout object at 0x000001A744CEF280>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000001A744D87DC0> and <tensorflow.python.keras.layers.core.Dropout object at 0x000001A744CAAC40>).\n"
     ]
    }
   ],
   "source": [
    "arly_stopping = EarlyStopping(monitor='mean_squared_error', patience=30, verbose=1)\n",
    "callback_list = [ early_stopping ]\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=60,\n",
    "             batch_size=50, \n",
    "             callbacks=callback_list,\n",
    "             validation_data=(X_test,y_test))\n",
    "model = tuner.get_best_models(num_models=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               39900     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 600)               180600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               120200    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 340,901\n",
      "Trainable params: 340,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit1': 300,\n",
       " 'reg_rate': 0.01,\n",
       " 'dropout_1': 0.6000000000000001,\n",
       " 'num_layers': 2,\n",
       " 'unitsdense_0': 600,\n",
       " 'reg_rate1': 0.1,\n",
       " 'dropoutdense_0': 0.4000000000000001,\n",
       " 'learning_rate': 0.0001,\n",
       " 'unitsdense_1': 200,\n",
       " 'dropoutdense_1': 0.2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000001A744CEFB20> and <tensorflow.python.keras.layers.core.Dropout object at 0x000001A744D619D0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000001A744DB7910> and <tensorflow.python.keras.layers.core.Dropout object at 0x000001A744F3F280>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000001A744E04C40> and <tensorflow.python.keras.layers.core.Dropout object at 0x000001A744E04C70>).\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict_Train={\"RMSE\": [],\"MSE\": [],\"MBE\": []};\n",
    "my_dict_Test={\"RMSE\": [],\"MSE\": [],\"MBE\": []};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 5.7848 - mean_squared_error: 0.0644 - mean_absolute_error: 0.1624 - val_loss: 5.6071 - val_mean_squared_error: 0.0633 - val_mean_absolute_error: 0.1612\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 5.4859 - mean_squared_error: 0.0648 - mean_absolute_error: 0.1625 - val_loss: 5.3164 - val_mean_squared_error: 0.0634 - val_mean_absolute_error: 0.1613\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 5.2007 - mean_squared_error: 0.0644 - mean_absolute_error: 0.1624 - val_loss: 5.0396 - val_mean_squared_error: 0.0634 - val_mean_absolute_error: 0.1616\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 4.9296 - mean_squared_error: 0.0645 - mean_absolute_error: 0.1628 - val_loss: 4.7762 - val_mean_squared_error: 0.0634 - val_mean_absolute_error: 0.1621\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.6719 - mean_squared_error: 0.0649 - mean_absolute_error: 0.1633 - val_loss: 4.5257 - val_mean_squared_error: 0.0635 - val_mean_absolute_error: 0.1618\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.4263 - mean_squared_error: 0.0647 - mean_absolute_error: 0.1632 - val_loss: 4.2874 - val_mean_squared_error: 0.0635 - val_mean_absolute_error: 0.1616\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.1929 - mean_squared_error: 0.0647 - mean_absolute_error: 0.1630 - val_loss: 4.0608 - val_mean_squared_error: 0.0636 - val_mean_absolute_error: 0.1617\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.9711 - mean_squared_error: 0.0648 - mean_absolute_error: 0.1639 - val_loss: 3.8455 - val_mean_squared_error: 0.0636 - val_mean_absolute_error: 0.1626\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.7600 - mean_squared_error: 0.0645 - mean_absolute_error: 0.1640 - val_loss: 3.6409 - val_mean_squared_error: 0.0636 - val_mean_absolute_error: 0.1623\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.5598 - mean_squared_error: 0.0646 - mean_absolute_error: 0.1633 - val_loss: 3.4466 - val_mean_squared_error: 0.0637 - val_mean_absolute_error: 0.1612\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.3694 - mean_squared_error: 0.0644 - mean_absolute_error: 0.1620 - val_loss: 3.2621 - val_mean_squared_error: 0.0637 - val_mean_absolute_error: 0.1617\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.1886 - mean_squared_error: 0.0641 - mean_absolute_error: 0.1657 - val_loss: 3.0870 - val_mean_squared_error: 0.0636 - val_mean_absolute_error: 0.1668\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.0176 - mean_squared_error: 0.0644 - mean_absolute_error: 0.1698 - val_loss: 2.9209 - val_mean_squared_error: 0.0636 - val_mean_absolute_error: 0.1685\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.8552 - mean_squared_error: 0.0643 - mean_absolute_error: 0.1736 - val_loss: 2.7638 - val_mean_squared_error: 0.0638 - val_mean_absolute_error: 0.1742\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.7017 - mean_squared_error: 0.0647 - mean_absolute_error: 0.1771 - val_loss: 2.6143 - val_mean_squared_error: 0.0637 - val_mean_absolute_error: 0.1732\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 2.5556 - mean_squared_error: 0.0649 - mean_absolute_error: 0.1747 - val_loss: 2.4719 - val_mean_squared_error: 0.0632 - val_mean_absolute_error: 0.1699\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.4165 - mean_squared_error: 0.0646 - mean_absolute_error: 0.1726 - val_loss: 2.3375 - val_mean_squared_error: 0.0632 - val_mean_absolute_error: 0.1689\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.2858 - mean_squared_error: 0.0653 - mean_absolute_error: 0.1728 - val_loss: 2.2103 - val_mean_squared_error: 0.0633 - val_mean_absolute_error: 0.1683\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.1608 - mean_squared_error: 0.0648 - mean_absolute_error: 0.1708 - val_loss: 2.0897 - val_mean_squared_error: 0.0634 - val_mean_absolute_error: 0.1668\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.0433 - mean_squared_error: 0.0652 - mean_absolute_error: 0.1698 - val_loss: 1.9756 - val_mean_squared_error: 0.0635 - val_mean_absolute_error: 0.1651\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.9315 - mean_squared_error: 0.0649 - mean_absolute_error: 0.1679 - val_loss: 1.8677 - val_mean_squared_error: 0.0635 - val_mean_absolute_error: 0.1641\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.8261 - mean_squared_error: 0.0652 - mean_absolute_error: 0.1674 - val_loss: 1.7655 - val_mean_squared_error: 0.0636 - val_mean_absolute_error: 0.1640\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.7258 - mean_squared_error: 0.0647 - mean_absolute_error: 0.1662 - val_loss: 1.6689 - val_mean_squared_error: 0.0636 - val_mean_absolute_error: 0.1641\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.6316 - mean_squared_error: 0.0650 - mean_absolute_error: 0.1668 - val_loss: 1.5775 - val_mean_squared_error: 0.0637 - val_mean_absolute_error: 0.1638\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.5420 - mean_squared_error: 0.0647 - mean_absolute_error: 0.1670 - val_loss: 1.4911 - val_mean_squared_error: 0.0637 - val_mean_absolute_error: 0.1652\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.4578 - mean_squared_error: 0.0648 - mean_absolute_error: 0.1681 - val_loss: 1.4095 - val_mean_squared_error: 0.0637 - val_mean_absolute_error: 0.1663\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.3785 - mean_squared_error: 0.0651 - mean_absolute_error: 0.1723 - val_loss: 1.3326 - val_mean_squared_error: 0.0637 - val_mean_absolute_error: 0.1713\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.3030 - mean_squared_error: 0.0649 - mean_absolute_error: 0.1739 - val_loss: 1.2598 - val_mean_squared_error: 0.0638 - val_mean_absolute_error: 0.1706\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.2320 - mean_squared_error: 0.0651 - mean_absolute_error: 0.1729 - val_loss: 1.1910 - val_mean_squared_error: 0.0638 - val_mean_absolute_error: 0.1693\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.1646 - mean_squared_error: 0.0649 - mean_absolute_error: 0.1713 - val_loss: 1.1261 - val_mean_squared_error: 0.0638 - val_mean_absolute_error: 0.1678\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,2):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.10, stratify= y, shuffle=True, random_state=None)\n",
    "        history= best_model.fit(X_train, y_train, epochs=15, batch_size=50,  verbose=1,shuffle=True, validation_data=(X_test,y_test))\n",
    "        my_dict_Train[\"RMSE\"].append(np.sqrt(np.mean(history.history['val_mean_squared_error'])) )\n",
    "        my_dict_Train[\"MSE\"].append(np.mean(history.history['val_mean_squared_error']))\n",
    "        my_dict_Train[\"MBE\"].append(np.mean(history.history['val_mean_absolute_error']))\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        my_dict_Test[\"RMSE\"].append(np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
    "        my_dict_Test[\"MSE\"].append(metrics.mean_squared_error(y_test,y_pred))\n",
    "        my_dict_Test[\"MBE\"].append(metrics.mean_absolute_error(y_test,y_pred))\n",
    "        best_model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training result\n",
      "RMSE: 0.252\n",
      "MSE: 0.064\n",
      "MBE: 0.165\n"
     ]
    }
   ],
   "source": [
    "print(\"Training result\")\n",
    "for metric in my_dict_Train.keys():\n",
    "    print(\"%s: %.3f\" % (metric, np.mean(my_dict_Train[metric])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing result\n",
      "RMSE: 0.253\n",
      "MSE: 0.064\n",
      "MBE: 0.171\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing result\")\n",
    "for metric in my_dict_Test.keys():\n",
    "    print(\"%s: %.3f\" % (metric, np.mean(my_dict_Test[metric])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
