{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import kerastuner as kt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score ,recall_score\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder() \n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import np_utils\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from numpy import average\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1371"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df= pd.read_csv(\"Full_LSTM_Classification.csv\")\n",
    "DX=pd.read_csv(\"DX_Four_Classes.csv\")\n",
    "df=df.sort_values(by='RID', ascending=True)\n",
    "DX=DX.sort_values(by='RID', ascending=True)\n",
    "groupby=df.groupby(\"RID\").count()\n",
    "len(groupby)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"DX_test_four_classes.csv\")\n",
    "df1=pd.merge(df, test, on='RID', how='inner')\n",
    "for j in range(0,len(test)):\n",
    "    df=df[df.RID!=test['RID'][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.merge(DX, test, on='RID', how='inner')                        \n",
    "for j in range(0,len(test)):\n",
    "    DX=DX[DX.RID!=test['RID'][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by='RID', ascending=True)\n",
    "X_train1=df.drop(['RID','VISCODE2'],axis = 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.sort_values(by='RID', ascending=True)\n",
    "X_test1=df1.drop(['RID','VISCODE2'],axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=len(X_train1.columns)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train1)\n",
    "scaler1 = MinMaxScaler(feature_range=(0, 1))\n",
    "X_test = scaler1.fit_transform(X_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train.reshape(len(DX), 4, num_features)\n",
    "DX=DX.sort_values(by='RID', ascending=True)\n",
    "train_label=DX.drop(['RID'],axis = 1 )\n",
    "X_test= X_test.reshape(len(y_test), 4, num_features)\n",
    "test_label1=y_test.sort_values(by='RID', ascending=True)\n",
    "test_label=test_label1.drop(['RID'],axis = 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hager\\anaconda3\\envs\\hager\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_label)\n",
    "encoded_Y= encoder.transform(train_label)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "encoder1 = LabelEncoder()\n",
    "encoder1.fit(test_label)\n",
    "y_test = encoder.transform(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    num_units_min  =  50\n",
    "    num_units_max  =  500\n",
    "    num_units_step =  20\n",
    "\n",
    "    dropout_min  =  .2\n",
    "    dropout_max  =  0.5\n",
    "    dropout_step =  0.1\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.LSTM(units=hp.Int('unit1',  min_value=num_units_min,\n",
    "                                                 max_value=num_units_max,\n",
    "                                                 step=num_units_step),\n",
    "                                                 input_shape=(X_train.shape[1], X_train.shape[2]), \n",
    "                                                 activation='relu',  kernel_regularizer=keras.regularizers.l2(hp.Choice('reg_rate1',values=[0.01, 0.05, 0.1,.2,.3,.4,.5])),                  \n",
    "                                                 return_sequences = True))\n",
    "    model.add(layers.Dropout(hp.Float('dropout_1',min_value=dropout_min,\n",
    "                                      max_value=dropout_max,\n",
    "                                      step=dropout_step) ) )\n",
    " \n",
    "    for i in range(hp.Int('num_layers', 1, 1)):\n",
    "        model.add(layers.LSTM(units=hp.Int('unitfor_'+ str(i),\n",
    "                                           min_value=num_units_min,\n",
    "                                           max_value=num_units_max,\n",
    "                                         step=num_units_step),\n",
    "                                        activation='relu',  kernel_regularizer=keras.regularizers.l2(hp.Choice('reg_rate2',values=[0.01, 0.05, 0.1, .2,.3,.4,.5])),                  \n",
    "                                          return_sequences = True))\n",
    "        model.add(layers.Dropout(hp.Float('dropoutfor_'+ str(i), \n",
    "                                    min_value=dropout_min,\n",
    "                                    max_value=dropout_max,\n",
    "                                      step=dropout_step)))\n",
    "    model.add(layers.LSTM(units=hp.Int('unit4',  min_value=num_units_min,\n",
    "                                                 max_value=num_units_max,\n",
    "                                                 step=num_units_step),\n",
    "                                                 activation='relu',  kernel_regularizer=keras.regularizers.l2(hp.Choice('reg_rate3',values=[0.01, 0.05, 0.1,.2,.3,.4,.5])),                  \n",
    "                                                 return_sequences = False))\n",
    "    model.add(layers.Dropout(hp.Float('dropout_4',min_value=dropout_min,\n",
    "                                      max_value=dropout_max,\n",
    "                                      step=dropout_step) ) ) \n",
    "    \n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[ 1e-4])),\n",
    "       loss='categorical_crossentropy', \n",
    "       metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1109"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t, X_val, y_t, y_val = train_test_split(\n",
    "     X_train, y_train, test_size=0.10, stratify= y_train, shuffle=True, random_state=None) \n",
    "len(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_acc',\n",
    "    max_trials=2,\n",
    "    project_name='lstm1Warpper')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 02m 23s]\n",
      "val_acc: 0.8548387289047241\n",
      "\n",
      "Best val_acc So Far: 0.8790322542190552\n",
      "Total elapsed time: 00h 05m 36s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=30, verbose=1)\n",
    "callback_list = [ early_stopping ]\n",
    "\n",
    "# split training data into stratified train/dev sets\n",
    "\n",
    "h=tuner.search(X_t, y_t,\n",
    "             epochs=100,\n",
    "             batch_size=50, \n",
    "             callbacks=callback_list, validation_data=(X_val,y_val) )\n",
    "            \n",
    "model = tuner.get_best_models(num_models=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 4, 350)            676200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 350)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 4, 210)            471240    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 210)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 70)                78680     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 284       \n",
      "=================================================================\n",
      "Total params: 1,226,404\n",
      "Trainable params: 1,226,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit1': 350,\n",
       " 'reg_rate1': 0.3,\n",
       " 'dropout_1': 0.30000000000000004,\n",
       " 'num_layers': 1,\n",
       " 'unitfor_0': 210,\n",
       " 'reg_rate2': 0.05,\n",
       " 'dropoutfor_0': 0.30000000000000004,\n",
       " 'unit4': 70,\n",
       " 'reg_rate3': 0.01,\n",
       " 'dropout_4': 0.5000000000000001,\n",
       " 'learning_rate': 0.0001}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "23/23 [==============================] - 11s 121ms/step - loss: 0.7597 - acc: 0.8011 - f1_m: 0.8013 - precision_m: 0.8451 - recall_m: 0.7627 - val_loss: 0.6429 - val_acc: 0.8548 - val_f1_m: 0.8587 - val_precision_m: 0.8973 - val_recall_m: 0.8239\n",
      "Epoch 2/70\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.7155 - acc: 0.8193 - f1_m: 0.8195 - precision_m: 0.8604 - recall_m: 0.7837 - val_loss: 0.5997 - val_acc: 0.8629 - val_f1_m: 0.8616 - val_precision_m: 0.8802 - val_recall_m: 0.8439\n",
      "Epoch 3/70\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.7703 - acc: 0.8129 - f1_m: 0.8056 - precision_m: 0.8472 - recall_m: 0.7683 - val_loss: 0.5821 - val_acc: 0.8629 - val_f1_m: 0.8502 - val_precision_m: 0.8786 - val_recall_m: 0.8239\n",
      "Epoch 4/70\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.7302 - acc: 0.8053 - f1_m: 0.8008 - precision_m: 0.8465 - recall_m: 0.7608 - val_loss: 0.5978 - val_acc: 0.8548 - val_f1_m: 0.8468 - val_precision_m: 0.8716 - val_recall_m: 0.8239\n",
      "Epoch 5/70\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.7698 - acc: 0.7974 - f1_m: 0.7962 - precision_m: 0.8358 - recall_m: 0.7607 - val_loss: 0.6156 - val_acc: 0.8306 - val_f1_m: 0.8156 - val_precision_m: 0.8361 - val_recall_m: 0.7961\n",
      "Epoch 6/70\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.6933 - acc: 0.8129 - f1_m: 0.8194 - precision_m: 0.8694 - recall_m: 0.7755 - val_loss: 0.9321 - val_acc: 0.7742 - val_f1_m: 0.7547 - val_precision_m: 0.7677 - val_recall_m: 0.7422\n",
      "Epoch 7/70\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.7962 - acc: 0.7910 - f1_m: 0.7880 - precision_m: 0.8252 - recall_m: 0.7546 - val_loss: 0.9977 - val_acc: 0.6694 - val_f1_m: 0.6190 - val_precision_m: 0.6843 - val_recall_m: 0.5661\n",
      "Epoch 8/70\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.8774 - acc: 0.7582 - f1_m: 0.7490 - precision_m: 0.7987 - recall_m: 0.7061 - val_loss: 0.6400 - val_acc: 0.8306 - val_f1_m: 0.8141 - val_precision_m: 0.8408 - val_recall_m: 0.7894\n",
      "Epoch 9/70\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.7317 - acc: 0.7918 - f1_m: 0.7902 - precision_m: 0.8279 - recall_m: 0.7563 - val_loss: 0.6032 - val_acc: 0.8387 - val_f1_m: 0.8470 - val_precision_m: 0.8718 - val_recall_m: 0.8239\n",
      "Epoch 10/70\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.7815 - acc: 0.7843 - f1_m: 0.7844 - precision_m: 0.8280 - recall_m: 0.7459 - val_loss: 0.6122 - val_acc: 0.8548 - val_f1_m: 0.8567 - val_precision_m: 0.8847 - val_recall_m: 0.8306\n",
      "Epoch 11/70\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.7490 - acc: 0.7977 - f1_m: 0.7876 - precision_m: 0.8463 - recall_m: 0.7373 - val_loss: 0.6545 - val_acc: 0.8226 - val_f1_m: 0.8110 - val_precision_m: 0.8340 - val_recall_m: 0.7894\n",
      "Epoch 12/70\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.7268 - acc: 0.8029 - f1_m: 0.8012 - precision_m: 0.8454 - recall_m: 0.7626 - val_loss: 0.6118 - val_acc: 0.8548 - val_f1_m: 0.8617 - val_precision_m: 0.9037 - val_recall_m: 0.8239\n",
      "Epoch 13/70\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.7174 - acc: 0.8060 - f1_m: 0.8044 - precision_m: 0.8454 - recall_m: 0.7683 - val_loss: 0.6074 - val_acc: 0.8387 - val_f1_m: 0.8353 - val_precision_m: 0.8624 - val_recall_m: 0.8100\n",
      "Epoch 14/70\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.7302 - acc: 0.7903 - f1_m: 0.8063 - precision_m: 0.8525 - recall_m: 0.7658 - val_loss: 0.6842 - val_acc: 0.8226 - val_f1_m: 0.7993 - val_precision_m: 0.8247 - val_recall_m: 0.7756\n",
      "Epoch 15/70\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.7669 - acc: 0.8009 - f1_m: 0.7974 - precision_m: 0.8388 - recall_m: 0.7607 - val_loss: 0.6396 - val_acc: 0.8387 - val_f1_m: 0.8487 - val_precision_m: 0.8829 - val_recall_m: 0.8172\n",
      "Epoch 16/70\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.7492 - acc: 0.8117 - f1_m: 0.8019 - precision_m: 0.8515 - recall_m: 0.7587 - val_loss: 0.5852 - val_acc: 0.8548 - val_f1_m: 0.8576 - val_precision_m: 0.8791 - val_recall_m: 0.8372\n",
      "Epoch 17/70\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.6986 - acc: 0.8131 - f1_m: 0.8131 - precision_m: 0.8605 - recall_m: 0.7722 - val_loss: 0.5811 - val_acc: 0.8548 - val_f1_m: 0.8507 - val_precision_m: 0.8722 - val_recall_m: 0.8306\n",
      "Epoch 18/70\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.7386 - acc: 0.7798 - f1_m: 0.7836 - precision_m: 0.8213 - recall_m: 0.7500 - val_loss: 0.9164 - val_acc: 0.7500 - val_f1_m: 0.7329 - val_precision_m: 0.7511 - val_recall_m: 0.7156\n",
      "Epoch 19/70\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.7493 - acc: 0.7916 - f1_m: 0.7956 - precision_m: 0.8377 - recall_m: 0.7585 - val_loss: 0.5851 - val_acc: 0.8548 - val_f1_m: 0.8507 - val_precision_m: 0.8722 - val_recall_m: 0.8306\n",
      "Epoch 20/70\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.6589 - acc: 0.8340 - f1_m: 0.8293 - precision_m: 0.8696 - recall_m: 0.7936 - val_loss: 0.6269 - val_acc: 0.8387 - val_f1_m: 0.8126 - val_precision_m: 0.8297 - val_recall_m: 0.7961\n",
      "Epoch 21/70\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.6569 - acc: 0.8432 - f1_m: 0.8434 - precision_m: 0.8856 - recall_m: 0.8056 - val_loss: 0.6882 - val_acc: 0.8226 - val_f1_m: 0.7965 - val_precision_m: 0.8188 - val_recall_m: 0.7756\n",
      "Epoch 22/70\n",
      "23/23 [==============================] - 2s 90ms/step - loss: 0.6884 - acc: 0.8200 - f1_m: 0.8175 - precision_m: 0.8644 - recall_m: 0.7761 - val_loss: 0.6574 - val_acc: 0.8226 - val_f1_m: 0.8003 - val_precision_m: 0.8195 - val_recall_m: 0.7822\n",
      "Epoch 23/70\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.7151 - acc: 0.7996 - f1_m: 0.8009 - precision_m: 0.8361 - recall_m: 0.7694 - val_loss: 0.5874 - val_acc: 0.8629 - val_f1_m: 0.8467 - val_precision_m: 0.8711 - val_recall_m: 0.8239\n",
      "Epoch 24/70\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.7304 - acc: 0.7905 - f1_m: 0.7874 - precision_m: 0.8393 - recall_m: 0.7427 - val_loss: 0.6720 - val_acc: 0.7984 - val_f1_m: 0.7887 - val_precision_m: 0.8173 - val_recall_m: 0.7622\n",
      "Epoch 25/70\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.6930 - acc: 0.8061 - f1_m: 0.8091 - precision_m: 0.8548 - recall_m: 0.7686 - val_loss: 0.5708 - val_acc: 0.8629 - val_f1_m: 0.8576 - val_precision_m: 0.8789 - val_recall_m: 0.8372\n",
      "Epoch 26/70\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.7089 - acc: 0.7941 - f1_m: 0.8089 - precision_m: 0.8588 - recall_m: 0.7654 - val_loss: 0.6515 - val_acc: 0.8226 - val_f1_m: 0.8058 - val_precision_m: 0.8228 - val_recall_m: 0.7894\n",
      "Epoch 27/70\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.6655 - acc: 0.8322 - f1_m: 0.8296 - precision_m: 0.8686 - recall_m: 0.7950 - val_loss: 0.6670 - val_acc: 0.8065 - val_f1_m: 0.7917 - val_precision_m: 0.8239 - val_recall_m: 0.7622\n",
      "Epoch 28/70\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.7132 - acc: 0.8077 - f1_m: 0.8004 - precision_m: 0.8586 - recall_m: 0.7508 - val_loss: 0.5936 - val_acc: 0.8387 - val_f1_m: 0.8353 - val_precision_m: 0.8624 - val_recall_m: 0.8100\n",
      "Epoch 29/70\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6685 - acc: 0.8129 - f1_m: 0.8188 - precision_m: 0.8607 - recall_m: 0.7814 - val_loss: 0.6052 - val_acc: 0.8226 - val_f1_m: 0.8223 - val_precision_m: 0.8494 - val_recall_m: 0.7972\n",
      "Epoch 30/70\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.7322 - acc: 0.7909 - f1_m: 0.7891 - precision_m: 0.8311 - recall_m: 0.7518 - val_loss: 0.5871 - val_acc: 0.8306 - val_f1_m: 0.8156 - val_precision_m: 0.8361 - val_recall_m: 0.7961\n",
      "Epoch 31/70\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6668 - acc: 0.8213 - f1_m: 0.8106 - precision_m: 0.8475 - recall_m: 0.7771 - val_loss: 0.5401 - val_acc: 0.8790 - val_f1_m: 0.8674 - val_precision_m: 0.8924 - val_recall_m: 0.8439\n",
      "Epoch 32/70\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.6476 - acc: 0.8264 - f1_m: 0.8241 - precision_m: 0.8669 - recall_m: 0.7863 - val_loss: 0.6280 - val_acc: 0.8145 - val_f1_m: 0.8047 - val_precision_m: 0.8279 - val_recall_m: 0.7828\n",
      "Epoch 33/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 2s 70ms/step - loss: 0.6700 - acc: 0.8052 - f1_m: 0.8087 - precision_m: 0.8678 - recall_m: 0.7584 - val_loss: 0.5936 - val_acc: 0.8387 - val_f1_m: 0.8323 - val_precision_m: 0.8561 - val_recall_m: 0.8100\n",
      "Epoch 34/70\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.6514 - acc: 0.8176 - f1_m: 0.8191 - precision_m: 0.8705 - recall_m: 0.7740 - val_loss: 0.5406 - val_acc: 0.8710 - val_f1_m: 0.8608 - val_precision_m: 0.8864 - val_recall_m: 0.8372\n",
      "Epoch 35/70\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.6731 - acc: 0.8077 - f1_m: 0.8098 - precision_m: 0.8607 - recall_m: 0.7657 - val_loss: 0.6162 - val_acc: 0.7984 - val_f1_m: 0.8078 - val_precision_m: 0.8342 - val_recall_m: 0.7833\n",
      "Epoch 36/70\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.7210 - acc: 0.7827 - f1_m: 0.7783 - precision_m: 0.8277 - recall_m: 0.7353 - val_loss: 0.5464 - val_acc: 0.8468 - val_f1_m: 0.8366 - val_precision_m: 0.8576 - val_recall_m: 0.8167\n",
      "Epoch 37/70\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.6839 - acc: 0.8184 - f1_m: 0.8183 - precision_m: 0.8611 - recall_m: 0.7803 - val_loss: 0.5401 - val_acc: 0.8468 - val_f1_m: 0.8328 - val_precision_m: 0.8572 - val_recall_m: 0.8100\n",
      "Epoch 38/70\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.6556 - acc: 0.8155 - f1_m: 0.8135 - precision_m: 0.8501 - recall_m: 0.7805 - val_loss: 0.5546 - val_acc: 0.8468 - val_f1_m: 0.8422 - val_precision_m: 0.8695 - val_recall_m: 0.8167\n",
      "Epoch 39/70\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.7025 - acc: 0.7935 - f1_m: 0.7924 - precision_m: 0.8403 - recall_m: 0.7502 - val_loss: 0.5362 - val_acc: 0.8629 - val_f1_m: 0.8546 - val_precision_m: 0.8728 - val_recall_m: 0.8372\n",
      "Epoch 40/70\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.6670 - acc: 0.8053 - f1_m: 0.8006 - precision_m: 0.8457 - recall_m: 0.7606 - val_loss: 0.5372 - val_acc: 0.8710 - val_f1_m: 0.8577 - val_precision_m: 0.8795 - val_recall_m: 0.8372\n",
      "Epoch 41/70\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.7672 - acc: 0.7789 - f1_m: 0.7786 - precision_m: 0.8290 - recall_m: 0.7351 - val_loss: 0.7294 - val_acc: 0.8226 - val_f1_m: 0.7887 - val_precision_m: 0.8023 - val_recall_m: 0.7756\n",
      "Epoch 42/70\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.7465 - acc: 0.7814 - f1_m: 0.7783 - precision_m: 0.8229 - recall_m: 0.7393 - val_loss: 0.5400 - val_acc: 0.8790 - val_f1_m: 0.8538 - val_precision_m: 0.8790 - val_recall_m: 0.8306\n",
      "Epoch 43/70\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.6551 - acc: 0.8269 - f1_m: 0.8177 - precision_m: 0.8613 - recall_m: 0.7790 - val_loss: 0.5985 - val_acc: 0.8145 - val_f1_m: 0.8259 - val_precision_m: 0.8729 - val_recall_m: 0.7839\n",
      "Epoch 44/70\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.7547 - acc: 0.7787 - f1_m: 0.7733 - precision_m: 0.8165 - recall_m: 0.7351 - val_loss: 0.8520 - val_acc: 0.7661 - val_f1_m: 0.7465 - val_precision_m: 0.7650 - val_recall_m: 0.7289\n",
      "Epoch 45/70\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.7292 - acc: 0.7918 - f1_m: 0.7886 - precision_m: 0.8401 - recall_m: 0.7443 - val_loss: 0.5501 - val_acc: 0.8468 - val_f1_m: 0.8353 - val_precision_m: 0.8624 - val_recall_m: 0.8100\n",
      "Epoch 46/70\n",
      "23/23 [==============================] - 2s 93ms/step - loss: 0.6455 - acc: 0.8307 - f1_m: 0.8253 - precision_m: 0.8602 - recall_m: 0.7937 - val_loss: 0.6445 - val_acc: 0.8145 - val_f1_m: 0.7886 - val_precision_m: 0.8022 - val_recall_m: 0.7756\n",
      "Epoch 47/70\n",
      "23/23 [==============================] - 2s 99ms/step - loss: 0.6451 - acc: 0.8050 - f1_m: 0.8166 - precision_m: 0.8607 - recall_m: 0.7772 - val_loss: 0.5481 - val_acc: 0.8548 - val_f1_m: 0.8557 - val_precision_m: 0.8901 - val_recall_m: 0.8239\n",
      "Epoch 48/70\n",
      "23/23 [==============================] - 2s 102ms/step - loss: 0.6938 - acc: 0.7922 - f1_m: 0.7999 - precision_m: 0.8445 - recall_m: 0.7603 - val_loss: 0.6225 - val_acc: 0.8145 - val_f1_m: 0.8063 - val_precision_m: 0.8321 - val_recall_m: 0.7822\n",
      "Epoch 49/70\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.6857 - acc: 0.8080 - f1_m: 0.8069 - precision_m: 0.8503 - recall_m: 0.7682 - val_loss: 0.6144 - val_acc: 0.8065 - val_f1_m: 0.8136 - val_precision_m: 0.8463 - val_recall_m: 0.7833\n",
      "Epoch 50/70\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.6880 - acc: 0.8060 - f1_m: 0.8012 - precision_m: 0.8559 - recall_m: 0.7543 - val_loss: 0.6312 - val_acc: 0.8065 - val_f1_m: 0.7936 - val_precision_m: 0.8127 - val_recall_m: 0.7756\n",
      "Epoch 51/70\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.6999 - acc: 0.7992 - f1_m: 0.7889 - precision_m: 0.8274 - recall_m: 0.7545 - val_loss: 0.5566 - val_acc: 0.8468 - val_f1_m: 0.8468 - val_precision_m: 0.8716 - val_recall_m: 0.8239\n",
      "Epoch 52/70\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.6475 - acc: 0.8104 - f1_m: 0.8152 - precision_m: 0.8586 - recall_m: 0.7765 - val_loss: 0.6019 - val_acc: 0.8306 - val_f1_m: 0.8102 - val_precision_m: 0.8397 - val_recall_m: 0.7828\n",
      "Epoch 53/70\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.6418 - acc: 0.8148 - f1_m: 0.8173 - precision_m: 0.8733 - recall_m: 0.7688 - val_loss: 0.6474 - val_acc: 0.7984 - val_f1_m: 0.8056 - val_precision_m: 0.8451 - val_recall_m: 0.7700\n",
      "Epoch 54/70\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6961 - acc: 0.8075 - f1_m: 0.7973 - precision_m: 0.8497 - recall_m: 0.7518 - val_loss: 0.5262 - val_acc: 0.8710 - val_f1_m: 0.8576 - val_precision_m: 0.8791 - val_recall_m: 0.8372\n",
      "Epoch 55/70\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.6365 - acc: 0.8254 - f1_m: 0.8231 - precision_m: 0.8676 - recall_m: 0.7835 - val_loss: 0.5761 - val_acc: 0.8306 - val_f1_m: 0.8208 - val_precision_m: 0.8473 - val_recall_m: 0.7961\n",
      "Epoch 56/70\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.6282 - acc: 0.8359 - f1_m: 0.8378 - precision_m: 0.8819 - recall_m: 0.7989 - val_loss: 0.8757 - val_acc: 0.7661 - val_f1_m: 0.7505 - val_precision_m: 0.7661 - val_recall_m: 0.7356\n",
      "Epoch 57/70\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.7093 - acc: 0.7968 - f1_m: 0.7935 - precision_m: 0.8316 - recall_m: 0.7596 - val_loss: 0.5502 - val_acc: 0.8548 - val_f1_m: 0.8353 - val_precision_m: 0.8624 - val_recall_m: 0.8100\n",
      "Epoch 58/70\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.6584 - acc: 0.8279 - f1_m: 0.8242 - precision_m: 0.8746 - recall_m: 0.7805 - val_loss: 0.5477 - val_acc: 0.8468 - val_f1_m: 0.8496 - val_precision_m: 0.8775 - val_recall_m: 0.8239\n",
      "Epoch 59/70\n",
      "23/23 [==============================] - 2s 91ms/step - loss: 0.6575 - acc: 0.8067 - f1_m: 0.7990 - precision_m: 0.8394 - recall_m: 0.7627 - val_loss: 0.5554 - val_acc: 0.8468 - val_f1_m: 0.8438 - val_precision_m: 0.8650 - val_recall_m: 0.8239\n",
      "Epoch 60/70\n",
      "23/23 [==============================] - 2s 97ms/step - loss: 0.6713 - acc: 0.8060 - f1_m: 0.8023 - precision_m: 0.8413 - recall_m: 0.7674 - val_loss: 0.5247 - val_acc: 0.8629 - val_f1_m: 0.8508 - val_precision_m: 0.8720 - val_recall_m: 0.8306\n",
      "Epoch 61/70\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.6297 - acc: 0.8204 - f1_m: 0.8301 - precision_m: 0.8755 - recall_m: 0.7899 - val_loss: 0.5873 - val_acc: 0.8145 - val_f1_m: 0.8309 - val_precision_m: 0.8676 - val_recall_m: 0.7972\n",
      "Epoch 62/70\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.6787 - acc: 0.8082 - f1_m: 0.8188 - precision_m: 0.8649 - recall_m: 0.7784 - val_loss: 0.5511 - val_acc: 0.8387 - val_f1_m: 0.8353 - val_precision_m: 0.8624 - val_recall_m: 0.8100\n",
      "Epoch 63/70\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.7011 - acc: 0.7963 - f1_m: 0.7773 - precision_m: 0.8268 - recall_m: 0.7345 - val_loss: 0.6037 - val_acc: 0.8145 - val_f1_m: 0.7995 - val_precision_m: 0.8252 - val_recall_m: 0.7756\n",
      "Epoch 64/70\n",
      "23/23 [==============================] - 2s 92ms/step - loss: 0.6369 - acc: 0.8323 - f1_m: 0.8237 - precision_m: 0.8679 - recall_m: 0.7841 - val_loss: 0.6070 - val_acc: 0.8065 - val_f1_m: 0.7995 - val_precision_m: 0.8252 - val_recall_m: 0.7756\n",
      "Epoch 65/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 2s 70ms/step - loss: 0.6835 - acc: 0.7827 - f1_m: 0.7848 - precision_m: 0.8361 - recall_m: 0.7401 - val_loss: 0.5210 - val_acc: 0.8629 - val_f1_m: 0.8567 - val_precision_m: 0.8847 - val_recall_m: 0.8306\n",
      "Epoch 66/70\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.6256 - acc: 0.8006 - f1_m: 0.8040 - precision_m: 0.8435 - recall_m: 0.7685 - val_loss: 0.5261 - val_acc: 0.8710 - val_f1_m: 0.8568 - val_precision_m: 0.8852 - val_recall_m: 0.8306\n",
      "Epoch 67/70\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 0.6506 - acc: 0.7874 - f1_m: 0.7945 - precision_m: 0.8577 - recall_m: 0.7411 - val_loss: 0.5696 - val_acc: 0.8468 - val_f1_m: 0.8353 - val_precision_m: 0.8624 - val_recall_m: 0.8100\n",
      "Epoch 68/70\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.6071 - acc: 0.8323 - f1_m: 0.8267 - precision_m: 0.8699 - recall_m: 0.7881 - val_loss: 0.7030 - val_acc: 0.7984 - val_f1_m: 0.7819 - val_precision_m: 0.7954 - val_recall_m: 0.7689\n",
      "Epoch 69/70\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.6485 - acc: 0.8152 - f1_m: 0.8112 - precision_m: 0.8480 - recall_m: 0.7783 - val_loss: 0.5225 - val_acc: 0.8548 - val_f1_m: 0.8508 - val_precision_m: 0.8721 - val_recall_m: 0.8306\n",
      "Epoch 70/70\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.6003 - acc: 0.8259 - f1_m: 0.8205 - precision_m: 0.8673 - recall_m: 0.7796 - val_loss: 0.5353 - val_acc: 0.8629 - val_f1_m: 0.8576 - val_precision_m: 0.8793 - val_recall_m: 0.8372\n"
     ]
    }
   ],
   "source": [
    "#model.reset_states()\n",
    "history= model.fit(X_t, y_t, epochs=70, batch_size=50,  verbose=1,shuffle=True, validation_data=(X_val,y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m', 'val_loss', 'val_acc', 'val_f1_m', 'val_precision_m', 'val_recall_m'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict_Train={\"Accuracy_Train\": [],\"Precision_Train\": [],\"Recall_Train\": [], \"F1_score_Train\":[]};\n",
    "my_dict_STD={\"Accuracy_Train\": [],\"Precision_Train\": [],\"Recall_Train\": [], \"F1_score_Train\":[]};\n",
    "my_dict_Test={\"Accuracy_Test\": [],\"Precision_Test\": [],\"Recall_Test\": [], \"F1_score_Test\":[]};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.6201 - acc: 0.8323 - f1_m: 0.8291 - precision_m: 0.8749 - recall_m: 0.7891 - val_loss: 0.4504 - val_acc: 0.8710 - val_f1_m: 0.8859 - val_precision_m: 0.9078 - val_recall_m: 0.8656\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.6419 - acc: 0.8188 - f1_m: 0.8169 - precision_m: 0.8562 - recall_m: 0.7820 - val_loss: 0.4748 - val_acc: 0.8710 - val_f1_m: 0.8733 - val_precision_m: 0.9118 - val_recall_m: 0.8383\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6291 - acc: 0.8133 - f1_m: 0.8194 - precision_m: 0.8645 - recall_m: 0.7800 - val_loss: 0.4533 - val_acc: 0.8952 - val_f1_m: 0.8794 - val_precision_m: 0.9256 - val_recall_m: 0.8383\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.6656 - acc: 0.8052 - f1_m: 0.8023 - precision_m: 0.8558 - recall_m: 0.7572 - val_loss: 0.5032 - val_acc: 0.8710 - val_f1_m: 0.8725 - val_precision_m: 0.9533 - val_recall_m: 0.8044\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6896 - acc: 0.7899 - f1_m: 0.7959 - precision_m: 0.8318 - recall_m: 0.7639 - val_loss: 0.4929 - val_acc: 0.8710 - val_f1_m: 0.8770 - val_precision_m: 0.9125 - val_recall_m: 0.8456\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.6388 - acc: 0.8323 - f1_m: 0.8268 - precision_m: 0.8723 - recall_m: 0.7873 - val_loss: 0.5840 - val_acc: 0.8548 - val_f1_m: 0.8674 - val_precision_m: 0.8761 - val_recall_m: 0.8589\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.6762 - acc: 0.7998 - f1_m: 0.7978 - precision_m: 0.8348 - recall_m: 0.7651 - val_loss: 0.5141 - val_acc: 0.8710 - val_f1_m: 0.8785 - val_precision_m: 0.9677 - val_recall_m: 0.8044\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6400 - acc: 0.8161 - f1_m: 0.8050 - precision_m: 0.8474 - recall_m: 0.7672 - val_loss: 0.5439 - val_acc: 0.8629 - val_f1_m: 0.8674 - val_precision_m: 0.8761 - val_recall_m: 0.8589\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.6375 - acc: 0.8179 - f1_m: 0.8147 - precision_m: 0.8601 - recall_m: 0.7747 - val_loss: 0.5586 - val_acc: 0.8548 - val_f1_m: 0.8712 - val_precision_m: 0.8770 - val_recall_m: 0.8656\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.6072 - acc: 0.8188 - f1_m: 0.8141 - precision_m: 0.8619 - recall_m: 0.7729 - val_loss: 0.5934 - val_acc: 0.8548 - val_f1_m: 0.8674 - val_precision_m: 0.8761 - val_recall_m: 0.8589\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.6496 - acc: 0.8242 - f1_m: 0.8242 - precision_m: 0.8680 - recall_m: 0.7856 - val_loss: 0.4977 - val_acc: 0.8790 - val_f1_m: 0.8737 - val_precision_m: 0.9385 - val_recall_m: 0.8178\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.6422 - acc: 0.8170 - f1_m: 0.8167 - precision_m: 0.8626 - recall_m: 0.7760 - val_loss: 0.4983 - val_acc: 0.8710 - val_f1_m: 0.8702 - val_precision_m: 0.8821 - val_recall_m: 0.8589\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.6002 - acc: 0.8323 - f1_m: 0.8285 - precision_m: 0.8709 - recall_m: 0.7907 - val_loss: 0.4685 - val_acc: 0.8710 - val_f1_m: 0.8794 - val_precision_m: 0.9256 - val_recall_m: 0.8383\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.6103 - acc: 0.8296 - f1_m: 0.8129 - precision_m: 0.8657 - recall_m: 0.7672 - val_loss: 0.4640 - val_acc: 0.8710 - val_f1_m: 0.8750 - val_precision_m: 0.8998 - val_recall_m: 0.8522\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.6419 - acc: 0.8124 - f1_m: 0.8194 - precision_m: 0.8562 - recall_m: 0.7865 - val_loss: 0.5406 - val_acc: 0.8548 - val_f1_m: 0.8634 - val_precision_m: 0.8752 - val_recall_m: 0.8522\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.6431 - acc: 0.8043 - f1_m: 0.7987 - precision_m: 0.8450 - recall_m: 0.7586 - val_loss: 0.4630 - val_acc: 0.8790 - val_f1_m: 0.8693 - val_precision_m: 0.9117 - val_recall_m: 0.8311\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.6270 - acc: 0.8097 - f1_m: 0.8068 - precision_m: 0.8510 - recall_m: 0.7677 - val_loss: 0.4720 - val_acc: 0.8710 - val_f1_m: 0.8699 - val_precision_m: 0.9049 - val_recall_m: 0.8389\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.6207 - acc: 0.8341 - f1_m: 0.8249 - precision_m: 0.8631 - recall_m: 0.7903 - val_loss: 0.4705 - val_acc: 0.8548 - val_f1_m: 0.8740 - val_precision_m: 0.9056 - val_recall_m: 0.8456\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 2s 92ms/step - loss: 0.6303 - acc: 0.8115 - f1_m: 0.8106 - precision_m: 0.8527 - recall_m: 0.7729 - val_loss: 0.5046 - val_acc: 0.8710 - val_f1_m: 0.8674 - val_precision_m: 0.8761 - val_recall_m: 0.8589\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 2s 96ms/step - loss: 0.6583 - acc: 0.8115 - f1_m: 0.8083 - precision_m: 0.8514 - recall_m: 0.7700 - val_loss: 0.4889 - val_acc: 0.8710 - val_f1_m: 0.8751 - val_precision_m: 0.9000 - val_recall_m: 0.8522\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 2s 96ms/step - loss: 0.6289 - acc: 0.8224 - f1_m: 0.8244 - precision_m: 0.8679 - recall_m: 0.7861 - val_loss: 0.4755 - val_acc: 0.8710 - val_f1_m: 0.8721 - val_precision_m: 0.8934 - val_recall_m: 0.8522\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.6012 - acc: 0.8251 - f1_m: 0.8156 - precision_m: 0.8573 - recall_m: 0.7798 - val_loss: 0.4941 - val_acc: 0.8387 - val_f1_m: 0.8406 - val_precision_m: 0.9069 - val_recall_m: 0.7839acc: 0.8267 - f1_m: 0.8294 - precision_m: 0.8638 - recall_m\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.6091 - acc: 0.8251 - f1_m: 0.8317 - precision_m: 0.8729 - recall_m: 0.7952 - val_loss: 0.4718 - val_acc: 0.8387 - val_f1_m: 0.8699 - val_precision_m: 0.9047 - val_recall_m: 0.8389\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.6145 - acc: 0.8179 - f1_m: 0.8245 - precision_m: 0.8676 - recall_m: 0.7865 - val_loss: 0.5224 - val_acc: 0.8306 - val_f1_m: 0.8290 - val_precision_m: 0.8980 - val_recall_m: 0.7706\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.6244 - acc: 0.8197 - f1_m: 0.8063 - precision_m: 0.8597 - recall_m: 0.7599 - val_loss: 0.4757 - val_acc: 0.8710 - val_f1_m: 0.8622 - val_precision_m: 0.8801 - val_recall_m: 0.8456\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5896 - acc: 0.8296 - f1_m: 0.8323 - precision_m: 0.8675 - recall_m: 0.8004 - val_loss: 0.4648 - val_acc: 0.8629 - val_f1_m: 0.8785 - val_precision_m: 0.9323 - val_recall_m: 0.8317\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.6307 - acc: 0.7971 - f1_m: 0.7994 - precision_m: 0.8379 - recall_m: 0.7646 - val_loss: 0.4635 - val_acc: 0.8710 - val_f1_m: 0.8721 - val_precision_m: 0.8934 - val_recall_m: 0.8522\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6835 - acc: 0.7989 - f1_m: 0.8028 - precision_m: 0.8546 - recall_m: 0.7583 - val_loss: 0.5675 - val_acc: 0.8548 - val_f1_m: 0.8634 - val_precision_m: 0.8752 - val_recall_m: 0.8522\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.6242 - acc: 0.8133 - f1_m: 0.8079 - precision_m: 0.8576 - recall_m: 0.7655 - val_loss: 0.5052 - val_acc: 0.8629 - val_f1_m: 0.8663 - val_precision_m: 0.8811 - val_recall_m: 0.8522\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.6096 - acc: 0.8233 - f1_m: 0.8153 - precision_m: 0.8553 - recall_m: 0.7799 - val_loss: 0.4939 - val_acc: 0.8629 - val_f1_m: 0.8663 - val_precision_m: 0.8811 - val_recall_m: 0.8522\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 2s 65ms/step - loss: 0.6021 - acc: 0.8224 - f1_m: 0.8249 - precision_m: 0.8750 - recall_m: 0.7813 - val_loss: 0.4672 - val_acc: 0.8710 - val_f1_m: 0.8652 - val_precision_m: 0.8866 - val_recall_m: 0.8456\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5875 - acc: 0.8278 - f1_m: 0.8209 - precision_m: 0.8705 - recall_m: 0.7777 - val_loss: 0.4596 - val_acc: 0.8548 - val_f1_m: 0.8711 - val_precision_m: 0.8991 - val_recall_m: 0.8456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5930 - acc: 0.8278 - f1_m: 0.8360 - precision_m: 0.8721 - recall_m: 0.8035 - val_loss: 0.4827 - val_acc: 0.8710 - val_f1_m: 0.8825 - val_precision_m: 0.9326 - val_recall_m: 0.8383\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.6057 - acc: 0.8197 - f1_m: 0.8200 - precision_m: 0.8666 - recall_m: 0.7791 - val_loss: 0.4663 - val_acc: 0.8710 - val_f1_m: 0.8741 - val_precision_m: 0.8829 - val_recall_m: 0.8656\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.5827 - acc: 0.8242 - f1_m: 0.8196 - precision_m: 0.8509 - recall_m: 0.7907 - val_loss: 0.4646 - val_acc: 0.8629 - val_f1_m: 0.8740 - val_precision_m: 0.9056 - val_recall_m: 0.8456\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.5992 - acc: 0.8142 - f1_m: 0.8174 - precision_m: 0.8585 - recall_m: 0.7813 - val_loss: 0.4619 - val_acc: 0.8387 - val_f1_m: 0.8799 - val_precision_m: 0.9190 - val_recall_m: 0.8456\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.6142 - acc: 0.8170 - f1_m: 0.8148 - precision_m: 0.8611 - recall_m: 0.7742 - val_loss: 0.4952 - val_acc: 0.8548 - val_f1_m: 0.8641 - val_precision_m: 0.8919 - val_recall_m: 0.8389\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.5810 - acc: 0.8287 - f1_m: 0.8326 - precision_m: 0.8782 - recall_m: 0.7926 - val_loss: 0.4537 - val_acc: 0.8710 - val_f1_m: 0.8870 - val_precision_m: 0.9267 - val_recall_m: 0.8522\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5793 - acc: 0.8305 - f1_m: 0.8304 - precision_m: 0.8741 - recall_m: 0.7917 - val_loss: 0.5282 - val_acc: 0.8468 - val_f1_m: 0.8634 - val_precision_m: 0.8752 - val_recall_m: 0.8522\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.6626 - acc: 0.8161 - f1_m: 0.8048 - precision_m: 0.8468 - recall_m: 0.7677 - val_loss: 0.5408 - val_acc: 0.8065 - val_f1_m: 0.8333 - val_precision_m: 0.8990 - val_recall_m: 0.7772\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.6177 - acc: 0.8151 - f1_m: 0.8137 - precision_m: 0.8505 - recall_m: 0.7808 - val_loss: 0.6506 - val_acc: 0.8065 - val_f1_m: 0.8155 - val_precision_m: 0.8264 - val_recall_m: 0.8050\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.6237 - acc: 0.8170 - f1_m: 0.8075 - precision_m: 0.8500 - recall_m: 0.7700 - val_loss: 0.4717 - val_acc: 0.8629 - val_f1_m: 0.8692 - val_precision_m: 0.8874 - val_recall_m: 0.8522\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6081 - acc: 0.8251 - f1_m: 0.8086 - precision_m: 0.8461 - recall_m: 0.7751 - val_loss: 0.6200 - val_acc: 0.8065 - val_f1_m: 0.8182 - val_precision_m: 0.8323 - val_recall_m: 0.8050\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.6294 - acc: 0.8142 - f1_m: 0.8086 - precision_m: 0.8505 - recall_m: 0.7712 - val_loss: 0.4661 - val_acc: 0.8548 - val_f1_m: 0.8790 - val_precision_m: 0.9257 - val_recall_m: 0.8389\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.6460 - acc: 0.7998 - f1_m: 0.7867 - precision_m: 0.8332 - recall_m: 0.7458 - val_loss: 0.4865 - val_acc: 0.8710 - val_f1_m: 0.8744 - val_precision_m: 0.9317 - val_recall_m: 0.8250\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5943 - acc: 0.8251 - f1_m: 0.8144 - precision_m: 0.8684 - recall_m: 0.7672 - val_loss: 0.4507 - val_acc: 0.8548 - val_f1_m: 0.8711 - val_precision_m: 0.8991 - val_recall_m: 0.8456\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5788 - acc: 0.8314 - f1_m: 0.8291 - precision_m: 0.8745 - recall_m: 0.7895 - val_loss: 0.5588 - val_acc: 0.8548 - val_f1_m: 0.8634 - val_precision_m: 0.8750 - val_recall_m: 0.8522\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5982 - acc: 0.8197 - f1_m: 0.8197 - precision_m: 0.8677 - recall_m: 0.7777 - val_loss: 0.4922 - val_acc: 0.8629 - val_f1_m: 0.8595 - val_precision_m: 0.8741 - val_recall_m: 0.8456\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5709 - acc: 0.8377 - f1_m: 0.8341 - precision_m: 0.8729 - recall_m: 0.7990 - val_loss: 0.4565 - val_acc: 0.8629 - val_f1_m: 0.8692 - val_precision_m: 0.8874 - val_recall_m: 0.8522\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.6209 - acc: 0.8197 - f1_m: 0.8138 - precision_m: 0.8462 - recall_m: 0.7843 - val_loss: 0.4768 - val_acc: 0.8790 - val_f1_m: 0.8770 - val_precision_m: 0.9125 - val_recall_m: 0.8456\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.6260 - acc: 0.7989 - f1_m: 0.7915 - precision_m: 0.8391 - recall_m: 0.7507 - val_loss: 0.4924 - val_acc: 0.8548 - val_f1_m: 0.8425 - val_precision_m: 0.8698 - val_recall_m: 0.8172\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.5819 - acc: 0.8242 - f1_m: 0.8232 - precision_m: 0.8636 - recall_m: 0.7877 - val_loss: 0.5043 - val_acc: 0.8548 - val_f1_m: 0.8496 - val_precision_m: 0.8771 - val_recall_m: 0.8239\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.5676 - acc: 0.8287 - f1_m: 0.8265 - precision_m: 0.8643 - recall_m: 0.7925 - val_loss: 0.5682 - val_acc: 0.8145 - val_f1_m: 0.8187 - val_precision_m: 0.8650 - val_recall_m: 0.7772\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6025 - acc: 0.8278 - f1_m: 0.8194 - precision_m: 0.8618 - recall_m: 0.7816 - val_loss: 0.5156 - val_acc: 0.8548 - val_f1_m: 0.8350 - val_precision_m: 0.8687 - val_recall_m: 0.8039\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6139 - acc: 0.8070 - f1_m: 0.8091 - precision_m: 0.8543 - recall_m: 0.7707 - val_loss: 0.5064 - val_acc: 0.8629 - val_f1_m: 0.8458 - val_precision_m: 0.8765 - val_recall_m: 0.8172\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.5767 - acc: 0.8206 - f1_m: 0.8257 - precision_m: 0.8630 - recall_m: 0.7921 - val_loss: 0.5036 - val_acc: 0.8468 - val_f1_m: 0.8565 - val_precision_m: 0.8842 - val_recall_m: 0.8306\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5774 - acc: 0.8296 - f1_m: 0.8308 - precision_m: 0.8705 - recall_m: 0.7952 - val_loss: 0.4964 - val_acc: 0.8468 - val_f1_m: 0.8565 - val_precision_m: 0.8842 - val_recall_m: 0.8306\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5841 - acc: 0.8133 - f1_m: 0.8098 - precision_m: 0.8483 - recall_m: 0.7759 - val_loss: 0.5480 - val_acc: 0.8387 - val_f1_m: 0.8304 - val_precision_m: 0.8914 - val_recall_m: 0.7772\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5972 - acc: 0.8269 - f1_m: 0.8182 - precision_m: 0.8629 - recall_m: 0.7786 - val_loss: 0.5045 - val_acc: 0.8548 - val_f1_m: 0.8525 - val_precision_m: 0.8833 - val_recall_m: 0.8239\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5763 - acc: 0.8278 - f1_m: 0.8306 - precision_m: 0.8796 - recall_m: 0.7877 - val_loss: 0.5179 - val_acc: 0.8629 - val_f1_m: 0.8565 - val_precision_m: 0.8842 - val_recall_m: 0.8306\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6597 - acc: 0.7918 - f1_m: 0.7869 - precision_m: 0.8261 - recall_m: 0.751 - 2s 72ms/step - loss: 0.6579 - acc: 0.7926 - f1_m: 0.7914 - precision_m: 0.8288 - recall_m: 0.7578 - val_loss: 0.8010 - val_acc: 0.7177 - val_f1_m: 0.6872 - val_precision_m: 0.7156 - val_recall_m: 0.6611\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.6277 - acc: 0.8188 - f1_m: 0.8154 - precision_m: 0.8690 - recall_m: 0.7691 - val_loss: 0.5072 - val_acc: 0.8548 - val_f1_m: 0.8497 - val_precision_m: 0.8773 - val_recall_m: 0.8239\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.6301 - acc: 0.8151 - f1_m: 0.8175 - precision_m: 0.8559 - recall_m: 0.7834 - val_loss: 0.5983 - val_acc: 0.8145 - val_f1_m: 0.8009 - val_precision_m: 0.8271 - val_recall_m: 0.7767\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 2s 73ms/step - loss: 0.5876 - acc: 0.8287 - f1_m: 0.8314 - precision_m: 0.8718 - recall_m: 0.7952 - val_loss: 0.5367 - val_acc: 0.8548 - val_f1_m: 0.8326 - val_precision_m: 0.8795 - val_recall_m: 0.7906\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5599 - acc: 0.8386 - f1_m: 0.8336 - precision_m: 0.8713 - recall_m: 0.8003 - val_loss: 0.5370 - val_acc: 0.8468 - val_f1_m: 0.8197 - val_precision_m: 0.8591 - val_recall_m: 0.7839\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.6098 - acc: 0.8133 - f1_m: 0.8026 - precision_m: 0.8525 - recall_m: 0.7594 - val_loss: 0.5243 - val_acc: 0.8468 - val_f1_m: 0.8484 - val_precision_m: 0.8823 - val_recall_m: 0.8172\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5859 - acc: 0.8179 - f1_m: 0.8195 - precision_m: 0.8729 - recall_m: 0.7733 - val_loss: 0.5098 - val_acc: 0.8468 - val_f1_m: 0.8466 - val_precision_m: 0.8709 - val_recall_m: 0.8239\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5838 - acc: 0.8233 - f1_m: 0.8172 - precision_m: 0.8535 - recall_m: 0.7843 - val_loss: 0.5604 - val_acc: 0.8468 - val_f1_m: 0.8191 - val_precision_m: 0.8424 - val_recall_m: 0.7972\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5573 - acc: 0.8404 - f1_m: 0.8481 - precision_m: 0.8786 - recall_m: 0.8209 - val_loss: 0.5653 - val_acc: 0.8468 - val_f1_m: 0.8318 - val_precision_m: 0.8619 - val_recall_m: 0.8039\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5902 - acc: 0.8206 - f1_m: 0.8108 - precision_m: 0.8480 - recall_m: 0.7773 - val_loss: 0.5179 - val_acc: 0.8387 - val_f1_m: 0.8185 - val_precision_m: 0.8645 - val_recall_m: 0.7772\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5636 - acc: 0.8314 - f1_m: 0.8252 - precision_m: 0.8636 - recall_m: 0.7907 - val_loss: 0.6346 - val_acc: 0.7742 - val_f1_m: 0.7860 - val_precision_m: 0.8333 - val_recall_m: 0.7439\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5718 - acc: 0.8251 - f1_m: 0.8258 - precision_m: 0.8592 - recall_m: 0.7956 - val_loss: 0.5129 - val_acc: 0.8468 - val_f1_m: 0.8279 - val_precision_m: 0.8611 - val_recall_m: 0.7972\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.5861 - acc: 0.8161 - f1_m: 0.8265 - precision_m: 0.8725 - recall_m: 0.7856 - val_loss: 0.5676 - val_acc: 0.8226 - val_f1_m: 0.8192 - val_precision_m: 0.8427 - val_recall_m: 0.7972\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5544 - acc: 0.8305 - f1_m: 0.8309 - precision_m: 0.8643 - recall_m: 0.8004 - val_loss: 0.5180 - val_acc: 0.8468 - val_f1_m: 0.8223 - val_precision_m: 0.8650 - val_recall_m: 0.7839\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.6663 - acc: 0.7755 - f1_m: 0.7827 - precision_m: 0.8378 - recall_m: 0.7356 - val_loss: 0.7793 - val_acc: 0.7177 - val_f1_m: 0.7072 - val_precision_m: 0.7277 - val_recall_m: 0.6878\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 1s 66ms/step - loss: 0.6070 - acc: 0.8052 - f1_m: 0.8126 - precision_m: 0.8540 - recall_m: 0.7760 - val_loss: 0.6514 - val_acc: 0.7742 - val_f1_m: 0.7888 - val_precision_m: 0.8235 - val_recall_m: 0.7572\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5981 - acc: 0.8179 - f1_m: 0.7992 - precision_m: 0.8346 - recall_m: 0.7675 - val_loss: 0.5180 - val_acc: 0.8306 - val_f1_m: 0.8428 - val_precision_m: 0.8702 - val_recall_m: 0.8172\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.6014 - acc: 0.8133 - f1_m: 0.8224 - precision_m: 0.8695 - recall_m: 0.7809 - val_loss: 0.5659 - val_acc: 0.8226 - val_f1_m: 0.8331 - val_precision_m: 0.8573 - val_recall_m: 0.8106\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 1s 66ms/step - loss: 0.5712 - acc: 0.8197 - f1_m: 0.8294 - precision_m: 0.8663 - recall_m: 0.7964 - val_loss: 0.5249 - val_acc: 0.8629 - val_f1_m: 0.8458 - val_precision_m: 0.8765 - val_recall_m: 0.8172\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5699 - acc: 0.8242 - f1_m: 0.8252 - precision_m: 0.8636 - recall_m: 0.7908 - val_loss: 0.6443 - val_acc: 0.7823 - val_f1_m: 0.7784 - val_precision_m: 0.8248 - val_recall_m: 0.7372\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.6655 - acc: 0.7998 - f1_m: 0.8052 - precision_m: 0.8484 - recall_m: 0.7669 - val_loss: 0.6256 - val_acc: 0.8065 - val_f1_m: 0.7872 - val_precision_m: 0.8128 - val_recall_m: 0.7633\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.5660 - acc: 0.8350 - f1_m: 0.8257 - precision_m: 0.8646 - recall_m: 0.7908 - val_loss: 0.5235 - val_acc: 0.8306 - val_f1_m: 0.8269 - val_precision_m: 0.8668 - val_recall_m: 0.7906\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5645 - acc: 0.8251 - f1_m: 0.8360 - precision_m: 0.8789 - recall_m: 0.7983 - val_loss: 0.5905 - val_acc: 0.8306 - val_f1_m: 0.8158 - val_precision_m: 0.8362 - val_recall_m: 0.7967\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5801 - acc: 0.8224 - f1_m: 0.8231 - precision_m: 0.8671 - recall_m: 0.7843 - val_loss: 0.5126 - val_acc: 0.8468 - val_f1_m: 0.8169 - val_precision_m: 0.8531 - val_recall_m: 0.7839\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.5561 - acc: 0.8332 - f1_m: 0.8386 - precision_m: 0.8894 - recall_m: 0.7943 - val_loss: 0.5094 - val_acc: 0.8145 - val_f1_m: 0.8359 - val_precision_m: 0.8631 - val_recall_m: 0.8106\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5680 - acc: 0.8305 - f1_m: 0.8192 - precision_m: 0.8591 - recall_m: 0.7833 - val_loss: 0.5135 - val_acc: 0.8468 - val_f1_m: 0.8350 - val_precision_m: 0.8687 - val_recall_m: 0.8039\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5492 - acc: 0.8305 - f1_m: 0.8386 - precision_m: 0.8870 - recall_m: 0.7956 - val_loss: 0.5055 - val_acc: 0.8548 - val_f1_m: 0.8429 - val_precision_m: 0.8705 - val_recall_m: 0.8172\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5751 - acc: 0.8296 - f1_m: 0.8239 - precision_m: 0.8640 - recall_m: 0.7877 - val_loss: 0.5402 - val_acc: 0.8387 - val_f1_m: 0.8171 - val_precision_m: 0.8700 - val_recall_m: 0.7706\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6226 - acc: 0.8079 - f1_m: 0.8056 - precision_m: 0.8501 - recall_m: 0.7669 - val_loss: 0.5154 - val_acc: 0.8468 - val_f1_m: 0.8458 - val_precision_m: 0.8765 - val_recall_m: 0.8172\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5593 - acc: 0.8269 - f1_m: 0.8260 - precision_m: 0.8684 - recall_m: 0.7886 - val_loss: 0.5302 - val_acc: 0.8387 - val_f1_m: 0.8428 - val_precision_m: 0.8702 - val_recall_m: 0.8172\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5467 - acc: 0.8332 - f1_m: 0.8309 - precision_m: 0.8650 - recall_m: 0.7999 - val_loss: 0.5063 - val_acc: 0.8629 - val_f1_m: 0.8497 - val_precision_m: 0.8773 - val_recall_m: 0.8239\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5886 - acc: 0.8133 - f1_m: 0.8159 - precision_m: 0.8556 - recall_m: 0.7808 - val_loss: 0.5870 - val_acc: 0.7984 - val_f1_m: 0.8058 - val_precision_m: 0.8615 - val_recall_m: 0.7572\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5792 - acc: 0.8269 - f1_m: 0.8265 - precision_m: 0.8770 - recall_m: 0.7830 - val_loss: 0.5181 - val_acc: 0.8548 - val_f1_m: 0.8407 - val_precision_m: 0.8811 - val_recall_m: 0.8039\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5702 - acc: 0.8332 - f1_m: 0.8301 - precision_m: 0.8766 - recall_m: 0.7896 - val_loss: 0.5243 - val_acc: 0.8387 - val_f1_m: 0.8428 - val_precision_m: 0.8702 - val_recall_m: 0.8172\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5574 - acc: 0.8242 - f1_m: 0.8282 - precision_m: 0.8667 - recall_m: 0.7939 - val_loss: 0.5369 - val_acc: 0.8387 - val_f1_m: 0.8428 - val_precision_m: 0.8702 - val_recall_m: 0.8172\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5629 - acc: 0.8242 - f1_m: 0.8225 - precision_m: 0.8601 - recall_m: 0.7886 - val_loss: 0.5977 - val_acc: 0.8306 - val_f1_m: 0.8055 - val_precision_m: 0.8285 - val_recall_m: 0.7839\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5435 - acc: 0.8395 - f1_m: 0.8194 - precision_m: 0.8648 - recall_m: 0.7794 - val_loss: 0.5094 - val_acc: 0.8548 - val_f1_m: 0.8487 - val_precision_m: 0.8827 - val_recall_m: 0.8172\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5438 - acc: 0.8323 - f1_m: 0.8288 - precision_m: 0.8739 - recall_m: 0.7890 - val_loss: 0.5782 - val_acc: 0.8065 - val_f1_m: 0.8127 - val_precision_m: 0.8516 - val_recall_m: 0.7772\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5505 - acc: 0.8269 - f1_m: 0.8185 - precision_m: 0.8638 - recall_m: 0.7811 - val_loss: 0.5174 - val_acc: 0.8548 - val_f1_m: 0.8351 - val_precision_m: 0.8688 - val_recall_m: 0.8039\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5534 - acc: 0.8260 - f1_m: 0.8310 - precision_m: 0.8755 - recall_m: 0.7917 - val_loss: 0.5675 - val_acc: 0.8145 - val_f1_m: 0.7984 - val_precision_m: 0.8368 - val_recall_m: 0.7639\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.6214 - acc: 0.8043 - f1_m: 0.8075 - precision_m: 0.8560 - recall_m: 0.7656 - val_loss: 0.5486 - val_acc: 0.8468 - val_f1_m: 0.8440 - val_precision_m: 0.8883 - val_recall_m: 0.8044\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.6210 - acc: 0.7962 - f1_m: 0.7928 - precision_m: 0.8405 - recall_m: 0.7512 - val_loss: 0.5217 - val_acc: 0.8387 - val_f1_m: 0.8312 - val_precision_m: 0.8687 - val_recall_m: 0.7972\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.5743 - acc: 0.8224 - f1_m: 0.8196 - precision_m: 0.8557 - recall_m: 0.7872 - val_loss: 0.8332 - val_acc: 0.7258 - val_f1_m: 0.7271 - val_precision_m: 0.7610 - val_recall_m: 0.6967\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 0.6058 - acc: 0.8215 - f1_m: 0.8162 - precision_m: 0.8692 - recall_m: 0.7704 - val_loss: 0.5323 - val_acc: 0.8145 - val_f1_m: 0.8327 - val_precision_m: 0.8801 - val_recall_m: 0.7906\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5450 - acc: 0.8269 - f1_m: 0.8239 - precision_m: 0.8591 - recall_m: 0.7925 - val_loss: 0.5196 - val_acc: 0.8629 - val_f1_m: 0.8501 - val_precision_m: 0.9015 - val_recall_m: 0.8044\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 2s 91ms/step - loss: 0.6016 - acc: 0.8133 - f1_m: 0.8079 - precision_m: 0.8537 - recall_m: 0.7673 - val_loss: 1.0185 - val_acc: 0.6855 - val_f1_m: 0.6695 - val_precision_m: 0.7239 - val_recall_m: 0.6228\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 1s 66ms/step - loss: 0.7235 - acc: 0.7610 - f1_m: 0.7466 - precision_m: 0.8026 - recall_m: 0.6989 - val_loss: 0.5670 - val_acc: 0.8226 - val_f1_m: 0.8286 - val_precision_m: 0.8791 - val_recall_m: 0.7839\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.6239 - acc: 0.7935 - f1_m: 0.7953 - precision_m: 0.8327 - recall_m: 0.7621 - val_loss: 0.5289 - val_acc: 0.8548 - val_f1_m: 0.8380 - val_precision_m: 0.8756 - val_recall_m: 0.8039\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5808 - acc: 0.8206 - f1_m: 0.8199 - precision_m: 0.8567 - recall_m: 0.7869 - val_loss: 0.5501 - val_acc: 0.8226 - val_f1_m: 0.8258 - val_precision_m: 0.8728 - val_recall_m: 0.7839\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5978 - acc: 0.8034 - f1_m: 0.8129 - precision_m: 0.8540 - recall_m: 0.7765 - val_loss: 0.5656 - val_acc: 0.8145 - val_f1_m: 0.8340 - val_precision_m: 0.8744 - val_recall_m: 0.7978\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5783 - acc: 0.8287 - f1_m: 0.8326 - precision_m: 0.8719 - recall_m: 0.7974 - val_loss: 0.5447 - val_acc: 0.7984 - val_f1_m: 0.8299 - val_precision_m: 0.8735 - val_recall_m: 0.7906\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5480 - acc: 0.8314 - f1_m: 0.8284 - precision_m: 0.8743 - recall_m: 0.7877 - val_loss: 0.5202 - val_acc: 0.8629 - val_f1_m: 0.8368 - val_precision_m: 0.8805 - val_recall_m: 0.7972\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5418 - acc: 0.8287 - f1_m: 0.8318 - precision_m: 0.8669 - recall_m: 0.8004 - val_loss: 0.5329 - val_acc: 0.8468 - val_f1_m: 0.8311 - val_precision_m: 0.8682 - val_recall_m: 0.7972\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.5483 - acc: 0.8377 - f1_m: 0.8392 - precision_m: 0.8791 - recall_m: 0.8035 - val_loss: 0.5163 - val_acc: 0.8548 - val_f1_m: 0.8327 - val_precision_m: 0.8798 - val_recall_m: 0.7906\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.5878 - acc: 0.8350 - f1_m: 0.8316 - precision_m: 0.8701 - recall_m: 0.7969 - val_loss: 0.5397 - val_acc: 0.8387 - val_f1_m: 0.8358 - val_precision_m: 0.8868 - val_recall_m: 0.7906\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.5543 - acc: 0.8377 - f1_m: 0.8362 - precision_m: 0.8823 - recall_m: 0.7964 - val_loss: 0.5153 - val_acc: 0.8629 - val_f1_m: 0.8370 - val_precision_m: 0.8811 - val_recall_m: 0.7972\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.5653 - acc: 0.8296 - f1_m: 0.8112 - precision_m: 0.8576 - recall_m: 0.7702 - val_loss: 0.5126 - val_acc: 0.8548 - val_f1_m: 0.8300 - val_precision_m: 0.8738 - val_recall_m: 0.7906\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.5754 - acc: 0.8251 - f1_m: 0.8124 - precision_m: 0.8613 - recall_m: 0.7711 - val_loss: 0.5133 - val_acc: 0.8548 - val_f1_m: 0.8411 - val_precision_m: 0.8822 - val_recall_m: 0.8039\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.5344 - acc: 0.8314 - f1_m: 0.8347 - precision_m: 0.8757 - recall_m: 0.7986 - val_loss: 0.5178 - val_acc: 0.8548 - val_f1_m: 0.8370 - val_precision_m: 0.8811 - val_recall_m: 0.7972\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.5579 - acc: 0.8278 - f1_m: 0.8173 - precision_m: 0.8605 - recall_m: 0.7794 - val_loss: 0.5210 - val_acc: 0.8548 - val_f1_m: 0.8327 - val_precision_m: 0.8798 - val_recall_m: 0.7906\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5421 - acc: 0.8404 - f1_m: 0.8389 - precision_m: 0.8800 - recall_m: 0.8021 - val_loss: 0.5230 - val_acc: 0.8629 - val_f1_m: 0.8381 - val_precision_m: 0.8756 - val_recall_m: 0.8039\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5471 - acc: 0.8341 - f1_m: 0.8162 - precision_m: 0.8560 - recall_m: 0.7811 - val_loss: 0.6296 - val_acc: 0.7903 - val_f1_m: 0.8123 - val_precision_m: 0.8355 - val_recall_m: 0.7911\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5995 - acc: 0.8124 - f1_m: 0.8066 - precision_m: 0.8547 - recall_m: 0.7647 - val_loss: 0.7437 - val_acc: 0.7500 - val_f1_m: 0.7260 - val_precision_m: 0.7610 - val_recall_m: 0.6944\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6535 - acc: 0.7827 - f1_m: 0.7808 - precision_m: 0.8271 - recall_m: 0.7399 - val_loss: 0.6216 - val_acc: 0.8065 - val_f1_m: 0.8171 - val_precision_m: 0.8545 - val_recall_m: 0.7844\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5731 - acc: 0.8269 - f1_m: 0.8299 - precision_m: 0.8717 - recall_m: 0.7926 - val_loss: 0.5328 - val_acc: 0.8468 - val_f1_m: 0.8490 - val_precision_m: 0.8837 - val_recall_m: 0.8172\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5995 - acc: 0.8115 - f1_m: 0.8193 - precision_m: 0.8545 - recall_m: 0.7878 - val_loss: 0.5454 - val_acc: 0.8468 - val_f1_m: 0.8327 - val_precision_m: 0.8798 - val_recall_m: 0.7906\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5784 - acc: 0.8142 - f1_m: 0.8211 - precision_m: 0.8593 - recall_m: 0.7869 - val_loss: 0.6103 - val_acc: 0.7903 - val_f1_m: 0.8111 - val_precision_m: 0.8407 - val_recall_m: 0.7844\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5886 - acc: 0.8079 - f1_m: 0.8006 - precision_m: 0.8461 - recall_m: 0.7612 - val_loss: 0.5774 - val_acc: 0.8306 - val_f1_m: 0.8131 - val_precision_m: 0.8533 - val_recall_m: 0.7772\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5505 - acc: 0.8314 - f1_m: 0.8275 - precision_m: 0.8736 - recall_m: 0.7873 - val_loss: 0.5229 - val_acc: 0.8387 - val_f1_m: 0.8368 - val_precision_m: 0.8808 - val_recall_m: 0.7972\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5364 - acc: 0.8440 - f1_m: 0.8463 - precision_m: 0.8827 - recall_m: 0.8134 - val_loss: 0.5265 - val_acc: 0.8548 - val_f1_m: 0.8340 - val_precision_m: 0.8744 - val_recall_m: 0.7972\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5569 - acc: 0.8296 - f1_m: 0.8250 - precision_m: 0.8585 - recall_m: 0.7947 - val_loss: 0.6283 - val_acc: 0.8065 - val_f1_m: 0.8123 - val_precision_m: 0.8524 - val_recall_m: 0.7778\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5723 - acc: 0.8188 - f1_m: 0.8118 - precision_m: 0.8603 - recall_m: 0.7695 - val_loss: 0.5355 - val_acc: 0.8548 - val_f1_m: 0.8314 - val_precision_m: 0.8693 - val_recall_m: 0.7972\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5678 - acc: 0.8215 - f1_m: 0.8214 - precision_m: 0.8639 - recall_m: 0.7834 - val_loss: 0.7138 - val_acc: 0.7500 - val_f1_m: 0.7511 - val_precision_m: 0.7839 - val_recall_m: 0.7222\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5874 - acc: 0.8179 - f1_m: 0.8195 - precision_m: 0.8648 - recall_m: 0.7804 - val_loss: 0.5935 - val_acc: 0.8145 - val_f1_m: 0.8251 - val_precision_m: 0.8555 - val_recall_m: 0.7978\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5917 - acc: 0.8188 - f1_m: 0.8207 - precision_m: 0.8557 - recall_m: 0.7896 - val_loss: 0.5928 - val_acc: 0.7984 - val_f1_m: 0.8112 - val_precision_m: 0.8416 - val_recall_m: 0.7839\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5867 - acc: 0.8142 - f1_m: 0.8027 - precision_m: 0.8329 - recall_m: 0.7755 - val_loss: 0.6190 - val_acc: 0.7823 - val_f1_m: 0.8080 - val_precision_m: 0.8342 - val_recall_m: 0.7844\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5408 - acc: 0.8404 - f1_m: 0.8387 - precision_m: 0.8794 - recall_m: 0.8021 - val_loss: 0.5277 - val_acc: 0.8548 - val_f1_m: 0.8340 - val_precision_m: 0.8746 - val_recall_m: 0.7972\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5541 - acc: 0.8269 - f1_m: 0.8328 - precision_m: 0.8692 - recall_m: 0.8000 - val_loss: 0.5408 - val_acc: 0.8226 - val_f1_m: 0.8354 - val_precision_m: 0.8698 - val_recall_m: 0.8039\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5272 - acc: 0.8386 - f1_m: 0.8376 - precision_m: 0.8742 - recall_m: 0.8047 - val_loss: 0.5200 - val_acc: 0.8548 - val_f1_m: 0.8381 - val_precision_m: 0.8756 - val_recall_m: 0.8039\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5469 - acc: 0.8350 - f1_m: 0.8311 - precision_m: 0.8702 - recall_m: 0.7964 - val_loss: 0.5146 - val_acc: 0.8226 - val_f1_m: 0.8409 - val_precision_m: 0.8816 - val_recall_m: 0.8039\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5651 - acc: 0.8242 - f1_m: 0.8255 - precision_m: 0.8706 - recall_m: 0.7856 - val_loss: 0.5151 - val_acc: 0.8629 - val_f1_m: 0.8543 - val_precision_m: 0.9025 - val_recall_m: 0.8111\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5373 - acc: 0.8350 - f1_m: 0.8340 - precision_m: 0.8724 - recall_m: 0.7995 - val_loss: 0.5283 - val_acc: 0.8468 - val_f1_m: 0.8381 - val_precision_m: 0.8750 - val_recall_m: 0.8044\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5117 - acc: 0.8368 - f1_m: 0.8345 - precision_m: 0.8667 - recall_m: 0.8051 - val_loss: 0.7080 - val_acc: 0.7581 - val_f1_m: 0.7843 - val_precision_m: 0.8059 - val_recall_m: 0.7644\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5970 - acc: 0.8097 - f1_m: 0.7992 - precision_m: 0.8565 - recall_m: 0.7511 - val_loss: 0.5391 - val_acc: 0.8387 - val_f1_m: 0.8342 - val_precision_m: 0.8751 - val_recall_m: 0.7972\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5486 - acc: 0.8332 - f1_m: 0.8405 - precision_m: 0.8802 - recall_m: 0.8047 - val_loss: 0.5564 - val_acc: 0.8306 - val_f1_m: 0.8269 - val_precision_m: 0.8673 - val_recall_m: 0.7906\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5323 - acc: 0.8341 - f1_m: 0.8428 - precision_m: 0.8792 - recall_m: 0.8104 - val_loss: 0.5269 - val_acc: 0.8629 - val_f1_m: 0.8383 - val_precision_m: 0.8763 - val_recall_m: 0.8039\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5435 - acc: 0.8278 - f1_m: 0.8328 - precision_m: 0.8656 - recall_m: 0.8035 - val_loss: 0.5161 - val_acc: 0.8468 - val_f1_m: 0.8291 - val_precision_m: 0.8800 - val_recall_m: 0.7839\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5327 - acc: 0.8368 - f1_m: 0.8423 - precision_m: 0.8838 - recall_m: 0.8052 - val_loss: 0.5159 - val_acc: 0.8790 - val_f1_m: 0.8446 - val_precision_m: 0.8897 - val_recall_m: 0.8044\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5174 - acc: 0.8467 - f1_m: 0.8211 - precision_m: 0.8695 - recall_m: 0.7806 - val_loss: 0.6896 - val_acc: 0.7581 - val_f1_m: 0.7801 - val_precision_m: 0.8047 - val_recall_m: 0.7578\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6526 - acc: 0.7872 - f1_m: 0.7824 - precision_m: 0.8296 - recall_m: 0.7416 - val_loss: 0.6484 - val_acc: 0.7823 - val_f1_m: 0.7452 - val_precision_m: 0.7950 - val_recall_m: 0.7017\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6127 - acc: 0.8106 - f1_m: 0.8126 - precision_m: 0.8628 - recall_m: 0.7691 - val_loss: 0.5175 - val_acc: 0.8710 - val_f1_m: 0.8679 - val_precision_m: 0.9176 - val_recall_m: 0.8250\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5257 - acc: 0.8431 - f1_m: 0.8412 - precision_m: 0.8703 - recall_m: 0.8147 - val_loss: 0.5909 - val_acc: 0.8306 - val_f1_m: 0.8329 - val_precision_m: 0.8797 - val_recall_m: 0.7911\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5156 - acc: 0.8494 - f1_m: 0.8527 - precision_m: 0.8867 - recall_m: 0.8217 - val_loss: 0.5322 - val_acc: 0.8468 - val_f1_m: 0.8576 - val_precision_m: 0.9030 - val_recall_m: 0.8183\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5226 - acc: 0.8332 - f1_m: 0.8363 - precision_m: 0.8679 - recall_m: 0.8078 - val_loss: 0.5422 - val_acc: 0.8468 - val_f1_m: 0.8491 - val_precision_m: 0.9007 - val_recall_m: 0.8044\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5071 - acc: 0.8404 - f1_m: 0.8437 - precision_m: 0.8894 - recall_m: 0.8039 - val_loss: 0.5423 - val_acc: 0.8548 - val_f1_m: 0.8550 - val_precision_m: 0.8960 - val_recall_m: 0.8183\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5568 - acc: 0.8206 - f1_m: 0.8215 - precision_m: 0.8574 - recall_m: 0.7891 - val_loss: 0.7056 - val_acc: 0.7258 - val_f1_m: 0.7384 - val_precision_m: 0.8062 - val_recall_m: 0.6822\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.6067 - acc: 0.8079 - f1_m: 0.7988 - precision_m: 0.8424 - recall_m: 0.7608 - val_loss: 0.5982 - val_acc: 0.7984 - val_f1_m: 0.8274 - val_precision_m: 0.8675 - val_recall_m: 0.7911\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.6291 - acc: 0.8061 - f1_m: 0.7940 - precision_m: 0.8411 - recall_m: 0.7525 - val_loss: 0.5880 - val_acc: 0.8306 - val_f1_m: 0.8146 - val_precision_m: 0.8643 - val_recall_m: 0.7706\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5370 - acc: 0.8314 - f1_m: 0.8392 - precision_m: 0.8776 - recall_m: 0.8047 - val_loss: 0.5410 - val_acc: 0.8629 - val_f1_m: 0.8610 - val_precision_m: 0.9104 - val_recall_m: 0.81830.8324 - f1_m: 0.8387 - precision_m: 0.8786 - recall_m: 0.802\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5383 - acc: 0.8332 - f1_m: 0.8318 - precision_m: 0.8646 - recall_m: 0.8021 - val_loss: 0.5433 - val_acc: 0.8548 - val_f1_m: 0.8632 - val_precision_m: 0.9159 - val_recall_m: 0.8183\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5271 - acc: 0.8386 - f1_m: 0.8427 - precision_m: 0.8854 - recall_m: 0.8047 - val_loss: 0.6711 - val_acc: 0.7742 - val_f1_m: 0.7714 - val_precision_m: 0.8354 - val_recall_m: 0.7167\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5690 - acc: 0.8251 - f1_m: 0.8239 - precision_m: 0.8643 - recall_m: 0.7877 - val_loss: 0.5501 - val_acc: 0.8387 - val_f1_m: 0.8557 - val_precision_m: 0.9076 - val_recall_m: 0.8117\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5559 - acc: 0.8377 - f1_m: 0.8329 - precision_m: 0.8769 - recall_m: 0.7939 - val_loss: 0.5514 - val_acc: 0.8145 - val_f1_m: 0.8503 - val_precision_m: 0.8949 - val_recall_m: 0.8117\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5060 - acc: 0.8431 - f1_m: 0.8355 - precision_m: 0.8681 - recall_m: 0.8059 - val_loss: 0.5914 - val_acc: 0.7984 - val_f1_m: 0.8141 - val_precision_m: 0.8625 - val_recall_m: 0.7711\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5905 - acc: 0.8079 - f1_m: 0.7997 - precision_m: 0.8438 - recall_m: 0.7608 - val_loss: 0.5724 - val_acc: 0.8226 - val_f1_m: 0.8398 - val_precision_m: 0.8875 - val_recall_m: 0.7978\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 0.5405 - acc: 0.8278 - f1_m: 0.8286 - precision_m: 0.8748 - recall_m: 0.7877 - val_loss: 0.6562 - val_acc: 0.7984 - val_f1_m: 0.8121 - val_precision_m: 0.8420 - val_recall_m: 0.7844\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5746 - acc: 0.8088 - f1_m: 0.8075 - precision_m: 0.8415 - recall_m: 0.7773 - val_loss: 0.5358 - val_acc: 0.8548 - val_f1_m: 0.8505 - val_precision_m: 0.9150 - val_recall_m: 0.7978\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5302 - acc: 0.8332 - f1_m: 0.8340 - precision_m: 0.8701 - recall_m: 0.8012 - val_loss: 0.5827 - val_acc: 0.8306 - val_f1_m: 0.8394 - val_precision_m: 0.8869 - val_recall_m: 0.7983\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5420 - acc: 0.8278 - f1_m: 0.8332 - precision_m: 0.8775 - recall_m: 0.7943 - val_loss: 0.5357 - val_acc: 0.8548 - val_f1_m: 0.8556 - val_precision_m: 0.9085 - val_recall_m: 0.8117\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5526 - acc: 0.8323 - f1_m: 0.8220 - precision_m: 0.8620 - recall_m: 0.7868 - val_loss: 0.5782 - val_acc: 0.8387 - val_f1_m: 0.8293 - val_precision_m: 0.8979 - val_recall_m: 0.7706\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.5242 - acc: 0.8449 - f1_m: 0.8270 - precision_m: 0.8681 - recall_m: 0.7907 - val_loss: 0.5611 - val_acc: 0.8468 - val_f1_m: 0.8412 - val_precision_m: 0.9001 - val_recall_m: 0.7911\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.5128 - acc: 0.8413 - f1_m: 0.8406 - precision_m: 0.8807 - recall_m: 0.8047 - val_loss: 0.5530 - val_acc: 0.8387 - val_f1_m: 0.8456 - val_precision_m: 0.9009 - val_recall_m: 0.7978\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.5005 - acc: 0.8413 - f1_m: 0.8505 - precision_m: 0.8801 - recall_m: 0.8235 - val_loss: 0.5511 - val_acc: 0.8468 - val_f1_m: 0.8556 - val_precision_m: 0.9085 - val_recall_m: 0.8117\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5805 - acc: 0.8106 - f1_m: 0.8073 - precision_m: 0.8582 - recall_m: 0.7629 - val_loss: 0.5961 - val_acc: 0.8306 - val_f1_m: 0.8244 - val_precision_m: 0.8783 - val_recall_m: 0.7778\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5309 - acc: 0.8350 - f1_m: 0.8358 - precision_m: 0.8867 - recall_m: 0.7917 - val_loss: 0.6366 - val_acc: 0.7984 - val_f1_m: 0.8163 - val_precision_m: 0.8434 - val_recall_m: 0.7911\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5495 - acc: 0.8287 - f1_m: 0.8260 - precision_m: 0.8654 - recall_m: 0.7908 - val_loss: 0.6937 - val_acc: 0.7823 - val_f1_m: 0.8106 - val_precision_m: 0.8305 - val_recall_m: 0.7917\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5703 - acc: 0.8233 - f1_m: 0.8223 - precision_m: 0.8694 - recall_m: 0.7808 - val_loss: 0.5754 - val_acc: 0.8306 - val_f1_m: 0.8458 - val_precision_m: 0.8939 - val_recall_m: 0.8050\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5153 - acc: 0.8440 - f1_m: 0.8471 - precision_m: 0.8894 - recall_m: 0.8091 - val_loss: 0.5749 - val_acc: 0.8226 - val_f1_m: 0.8299 - val_precision_m: 0.8729 - val_recall_m: 0.7911\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5171 - acc: 0.8368 - f1_m: 0.8311 - precision_m: 0.8668 - recall_m: 0.7986 - val_loss: 0.5450 - val_acc: 0.8548 - val_f1_m: 0.8527 - val_precision_m: 0.9010 - val_recall_m: 0.8117\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5035 - acc: 0.8422 - f1_m: 0.8416 - precision_m: 0.8760 - recall_m: 0.8103 - val_loss: 0.5590 - val_acc: 0.8468 - val_f1_m: 0.8556 - val_precision_m: 0.9085 - val_recall_m: 0.8117\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5388 - acc: 0.8287 - f1_m: 0.8315 - precision_m: 0.8803 - recall_m: 0.7891 - val_loss: 0.5647 - val_acc: 0.8145 - val_f1_m: 0.8332 - val_precision_m: 0.8980 - val_recall_m: 0.7778\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5172 - acc: 0.8368 - f1_m: 0.8416 - precision_m: 0.8824 - recall_m: 0.8052 - val_loss: 0.5351 - val_acc: 0.8468 - val_f1_m: 0.8487 - val_precision_m: 0.9014 - val_recall_m: 0.8050\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5181 - acc: 0.8440 - f1_m: 0.8496 - precision_m: 0.8898 - recall_m: 0.8139 - val_loss: 0.5985 - val_acc: 0.8226 - val_f1_m: 0.8315 - val_precision_m: 0.8687 - val_recall_m: 0.7978\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5136 - acc: 0.8269 - f1_m: 0.8337 - precision_m: 0.8763 - recall_m: 0.7965 - val_loss: 0.5680 - val_acc: 0.8387 - val_f1_m: 0.8378 - val_precision_m: 0.8926 - val_recall_m: 0.7911\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.4985 - acc: 0.8413 - f1_m: 0.8390 - precision_m: 0.8829 - recall_m: 0.7999 - val_loss: 0.5392 - val_acc: 0.8468 - val_f1_m: 0.8632 - val_precision_m: 0.9159 - val_recall_m: 0.8183\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5215 - acc: 0.8350 - f1_m: 0.8355 - precision_m: 0.8772 - recall_m: 0.7986 - val_loss: 0.5546 - val_acc: 0.8387 - val_f1_m: 0.8527 - val_precision_m: 0.9010 - val_recall_m: 0.8117\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5117 - acc: 0.8278 - f1_m: 0.8188 - precision_m: 0.8621 - recall_m: 0.7807 - val_loss: 0.5546 - val_acc: 0.8306 - val_f1_m: 0.8473 - val_precision_m: 0.9061 - val_recall_m: 0.7983\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5088 - acc: 0.8314 - f1_m: 0.8293 - precision_m: 0.8741 - recall_m: 0.7895 - val_loss: 0.5529 - val_acc: 0.8629 - val_f1_m: 0.8631 - val_precision_m: 0.9170 - val_recall_m: 0.8183\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5129 - acc: 0.8341 - f1_m: 0.8358 - precision_m: 0.8763 - recall_m: 0.8000 - val_loss: 0.5399 - val_acc: 0.8548 - val_f1_m: 0.8562 - val_precision_m: 0.9099 - val_recall_m: 0.8117\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5176 - acc: 0.8467 - f1_m: 0.8374 - precision_m: 0.8828 - recall_m: 0.7978 - val_loss: 0.6449 - val_acc: 0.7823 - val_f1_m: 0.7891 - val_precision_m: 0.8582 - val_recall_m: 0.7306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5255 - acc: 0.8314 - f1_m: 0.8320 - precision_m: 0.8781 - recall_m: 0.7917 - val_loss: 0.6728 - val_acc: 0.7742 - val_f1_m: 0.7914 - val_precision_m: 0.8452 - val_recall_m: 0.7444\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5912 - acc: 0.8079 - f1_m: 0.8058 - precision_m: 0.8502 - recall_m: 0.7665 - val_loss: 0.5754 - val_acc: 0.8387 - val_f1_m: 0.8314 - val_precision_m: 0.8856 - val_recall_m: 0.7844\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5547 - acc: 0.8142 - f1_m: 0.8165 - precision_m: 0.8583 - recall_m: 0.7790 - val_loss: 0.5646 - val_acc: 0.8306 - val_f1_m: 0.8314 - val_precision_m: 0.8856 - val_recall_m: 0.7844\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5393 - acc: 0.8314 - f1_m: 0.8309 - precision_m: 0.8757 - recall_m: 0.7917 - val_loss: 0.5983 - val_acc: 0.8306 - val_f1_m: 0.8244 - val_precision_m: 0.8783 - val_recall_m: 0.7778\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5436 - acc: 0.8341 - f1_m: 0.8283 - precision_m: 0.8783 - recall_m: 0.7851 - val_loss: 0.5762 - val_acc: 0.8226 - val_f1_m: 0.8328 - val_precision_m: 0.8977 - val_recall_m: 0.7778\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5993 - acc: 0.7854 - f1_m: 0.7978 - precision_m: 0.8445 - recall_m: 0.7569 - val_loss: 0.5588 - val_acc: 0.8387 - val_f1_m: 0.8517 - val_precision_m: 0.9078 - val_recall_m: 0.8050\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5153 - acc: 0.8305 - f1_m: 0.8388 - precision_m: 0.8739 - recall_m: 0.8073 - val_loss: 0.5815 - val_acc: 0.8306 - val_f1_m: 0.8314 - val_precision_m: 0.8856 - val_recall_m: 0.7844\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5168 - acc: 0.8314 - f1_m: 0.8346 - precision_m: 0.8712 - recall_m: 0.8016 - val_loss: 0.5608 - val_acc: 0.8306 - val_f1_m: 0.8446 - val_precision_m: 0.8997 - val_recall_m: 0.7978\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.5124 - acc: 0.8458 - f1_m: 0.8288 - precision_m: 0.8697 - recall_m: 0.7925 - val_loss: 0.6984 - val_acc: 0.7984 - val_f1_m: 0.8202 - val_precision_m: 0.8434 - val_recall_m: 0.7983\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5358 - acc: 0.8296 - f1_m: 0.8246 - precision_m: 0.8705 - recall_m: 0.7843 - val_loss: 0.5396 - val_acc: 0.8387 - val_f1_m: 0.8576 - val_precision_m: 0.9030 - val_recall_m: 0.8183\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.4861 - acc: 0.8476 - f1_m: 0.8529 - precision_m: 0.8904 - recall_m: 0.8190 - val_loss: 0.6156 - val_acc: 0.8226 - val_f1_m: 0.8370 - val_precision_m: 0.8804 - val_recall_m: 0.7978\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5592 - acc: 0.8151 - f1_m: 0.8136 - precision_m: 0.8606 - recall_m: 0.7721 - val_loss: 0.6136 - val_acc: 0.8145 - val_f1_m: 0.8184 - val_precision_m: 0.8646 - val_recall_m: 0.7772\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.5795 - acc: 0.8115 - f1_m: 0.7992 - precision_m: 0.8490 - recall_m: 0.7558 - val_loss: 0.5629 - val_acc: 0.8226 - val_f1_m: 0.8350 - val_precision_m: 0.8683 - val_recall_m: 0.8044\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.5878 - acc: 0.8097 - f1_m: 0.7941 - precision_m: 0.8435 - recall_m: 0.7516 - val_loss: 0.5692 - val_acc: 0.8387 - val_f1_m: 0.8323 - val_precision_m: 0.8790 - val_recall_m: 0.7906\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5123 - acc: 0.8305 - f1_m: 0.8287 - precision_m: 0.8697 - recall_m: 0.7925 - val_loss: 0.5717 - val_acc: 0.8145 - val_f1_m: 0.8281 - val_precision_m: 0.8610 - val_recall_m: 0.7978\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5119 - acc: 0.8332 - f1_m: 0.8311 - precision_m: 0.8687 - recall_m: 0.7973 - val_loss: 0.5990 - val_acc: 0.8387 - val_f1_m: 0.8323 - val_precision_m: 0.8790 - val_recall_m: 0.7906\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.5338 - acc: 0.8260 - f1_m: 0.8255 - precision_m: 0.8774 - recall_m: 0.7799 - val_loss: 0.6162 - val_acc: 0.8306 - val_f1_m: 0.8197 - val_precision_m: 0.8591 - val_recall_m: 0.7839\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.5173 - acc: 0.8404 - f1_m: 0.8478 - precision_m: 0.8842 - recall_m: 0.8152 - val_loss: 0.5981 - val_acc: 0.8145 - val_f1_m: 0.8040 - val_precision_m: 0.8493 - val_recall_m: 0.7633\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5088 - acc: 0.8422 - f1_m: 0.8453 - precision_m: 0.8954 - recall_m: 0.8017 - val_loss: 0.6014 - val_acc: 0.8306 - val_f1_m: 0.8350 - val_precision_m: 0.8683 - val_recall_m: 0.8044\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.4958 - acc: 0.8521 - f1_m: 0.8555 - precision_m: 0.8889 - recall_m: 0.8252 - val_loss: 0.5969 - val_acc: 0.8226 - val_f1_m: 0.8350 - val_precision_m: 0.8683 - val_recall_m: 0.8044\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.4999 - acc: 0.8368 - f1_m: 0.8485 - precision_m: 0.8809 - recall_m: 0.8191 - val_loss: 0.6086 - val_acc: 0.8145 - val_f1_m: 0.8125 - val_precision_m: 0.8518 - val_recall_m: 0.7772\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 2s 65ms/step - loss: 0.5004 - acc: 0.8404 - f1_m: 0.8473 - precision_m: 0.8883 - recall_m: 0.8108 - val_loss: 0.6023 - val_acc: 0.8226 - val_f1_m: 0.8267 - val_precision_m: 0.8663 - val_recall_m: 0.7911\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5147 - acc: 0.8494 - f1_m: 0.8309 - precision_m: 0.8764 - recall_m: 0.7906 - val_loss: 0.6151 - val_acc: 0.8145 - val_f1_m: 0.8311 - val_precision_m: 0.8676 - val_recall_m: 0.7978\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5308 - acc: 0.8251 - f1_m: 0.8283 - precision_m: 0.8734 - recall_m: 0.7886 - val_loss: 0.5945 - val_acc: 0.8226 - val_f1_m: 0.8307 - val_precision_m: 0.8669 - val_recall_m: 0.7978\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5009 - acc: 0.8345 - f1_m: 0.8408 - precision_m: 0.8807 - recall_m: 0.805 - 1s 60ms/step - loss: 0.5006 - acc: 0.8350 - f1_m: 0.8401 - precision_m: 0.8805 - recall_m: 0.8043 - val_loss: 0.5971 - val_acc: 0.8226 - val_f1_m: 0.8307 - val_precision_m: 0.8669 - val_recall_m: 0.7978\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 1s 66ms/step - loss: 0.4769 - acc: 0.8395 - f1_m: 0.8403 - precision_m: 0.8841 - recall_m: 0.8016 - val_loss: 0.6240 - val_acc: 0.8145 - val_f1_m: 0.8122 - val_precision_m: 0.8511 - val_recall_m: 0.7767\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.4817 - acc: 0.8413 - f1_m: 0.8499 - precision_m: 0.8886 - recall_m: 0.8152 - val_loss: 0.6267 - val_acc: 0.8145 - val_f1_m: 0.8281 - val_precision_m: 0.8610 - val_recall_m: 0.7978\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5039 - acc: 0.8332 - f1_m: 0.8422 - precision_m: 0.8826 - recall_m: 0.8061 - val_loss: 0.6236 - val_acc: 0.8145 - val_f1_m: 0.8224 - val_precision_m: 0.8488 - val_recall_m: 0.7978\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.4810 - acc: 0.8449 - f1_m: 0.8364 - precision_m: 0.8791 - recall_m: 0.7993 - val_loss: 0.6339 - val_acc: 0.8145 - val_f1_m: 0.8240 - val_precision_m: 0.8603 - val_recall_m: 0.7906\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5138 - acc: 0.8314 - f1_m: 0.8294 - precision_m: 0.8737 - recall_m: 0.7899 - val_loss: 0.6031 - val_acc: 0.8226 - val_f1_m: 0.8197 - val_precision_m: 0.8589 - val_recall_m: 0.7844\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5244 - acc: 0.8224 - f1_m: 0.8146 - precision_m: 0.8701 - recall_m: 0.767 - 2s 70ms/step - loss: 0.5244 - acc: 0.8224 - f1_m: 0.8146 - precision_m: 0.8701 - recall_m: 0.7672 - val_loss: 0.6771 - val_acc: 0.8145 - val_f1_m: 0.8168 - val_precision_m: 0.8527 - val_recall_m: 0.7839\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 2s 87ms/step - loss: 0.5348 - acc: 0.8332 - f1_m: 0.8127 - precision_m: 0.8517 - recall_m: 0.7777 - val_loss: 0.6249 - val_acc: 0.7984 - val_f1_m: 0.8067 - val_precision_m: 0.8555 - val_recall_m: 0.7633\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.5018 - acc: 0.8440 - f1_m: 0.8456 - precision_m: 0.8909 - recall_m: 0.8056 - val_loss: 0.7559 - val_acc: 0.8065 - val_f1_m: 0.7986 - val_precision_m: 0.8213 - val_recall_m: 0.7778\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.7134 - acc: 0.7638 - f1_m: 0.7542 - precision_m: 0.8204 - recall_m: 0.6998 - val_loss: 0.6364 - val_acc: 0.8226 - val_f1_m: 0.8081 - val_precision_m: 0.8504 - val_recall_m: 0.7706\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5430 - acc: 0.8305 - f1_m: 0.8311 - precision_m: 0.8723 - recall_m: 0.7947 - val_loss: 0.6572 - val_acc: 0.7984 - val_f1_m: 0.8139 - val_precision_m: 0.8465 - val_recall_m: 0.7839\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.5028 - acc: 0.8404 - f1_m: 0.8404 - precision_m: 0.8751 - recall_m: 0.8091 - val_loss: 0.6253 - val_acc: 0.8145 - val_f1_m: 0.8267 - val_precision_m: 0.8663 - val_recall_m: 0.7911\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5042 - acc: 0.8404 - f1_m: 0.8366 - precision_m: 0.8804 - recall_m: 0.7977 - val_loss: 0.6241 - val_acc: 0.8065 - val_f1_m: 0.8153 - val_precision_m: 0.8581 - val_recall_m: 0.7772\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5304 - acc: 0.8215 - f1_m: 0.8355 - precision_m: 0.8765 - recall_m: 0.7991 - val_loss: 0.6399 - val_acc: 0.8065 - val_f1_m: 0.7950 - val_precision_m: 0.8464 - val_recall_m: 0.7494\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.4965 - acc: 0.8341 - f1_m: 0.8335 - precision_m: 0.8764 - recall_m: 0.7951 - val_loss: 0.6314 - val_acc: 0.8145 - val_f1_m: 0.8125 - val_precision_m: 0.8518 - val_recall_m: 0.7772\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.5358 - acc: 0.8215 - f1_m: 0.8274 - precision_m: 0.8711 - recall_m: 0.7887 - val_loss: 0.8414 - val_acc: 0.7339 - val_f1_m: 0.7308 - val_precision_m: 0.8046 - val_recall_m: 0.6694\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.4903 - acc: 0.8440 - f1_m: 0.8356 - precision_m: 0.8771 - recall_m: 0.7994 - val_loss: 0.7788 - val_acc: 0.7984 - val_f1_m: 0.7917 - val_precision_m: 0.8296 - val_recall_m: 0.7572\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.5775 - acc: 0.8133 - f1_m: 0.8068 - precision_m: 0.8515 - recall_m: 0.7676 - val_loss: 0.6056 - val_acc: 0.7984 - val_f1_m: 0.8211 - val_precision_m: 0.8707 - val_recall_m: 0.7772\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.5171 - acc: 0.8332 - f1_m: 0.8231 - precision_m: 0.8591 - recall_m: 0.7907 - val_loss: 0.6625 - val_acc: 0.8145 - val_f1_m: 0.8026 - val_precision_m: 0.8548 - val_recall_m: 0.7567\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.5722 - acc: 0.8206 - f1_m: 0.8117 - precision_m: 0.8670 - recall_m: 0.7643 - val_loss: 0.6279 - val_acc: 0.8145 - val_f1_m: 0.8156 - val_precision_m: 0.8587 - val_recall_m: 0.7772\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.5476 - acc: 0.8350 - f1_m: 0.8353 - precision_m: 0.8766 - recall_m: 0.7986 - val_loss: 0.6643 - val_acc: 0.8145 - val_f1_m: 0.8082 - val_precision_m: 0.8343 - val_recall_m: 0.7844\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.5374 - acc: 0.8332 - f1_m: 0.8291 - precision_m: 0.8766 - recall_m: 0.7877 - val_loss: 0.6428 - val_acc: 0.8226 - val_f1_m: 0.8110 - val_precision_m: 0.8563 - val_recall_m: 0.7706\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.5340 - acc: 0.8269 - f1_m: 0.8282 - precision_m: 0.8638 - recall_m: 0.7960 - val_loss: 0.6176 - val_acc: 0.8226 - val_f1_m: 0.8307 - val_precision_m: 0.8669 - val_recall_m: 0.7978\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.4929 - acc: 0.8395 - f1_m: 0.8449 - precision_m: 0.8853 - recall_m: 0.8087 - val_loss: 0.6898 - val_acc: 0.8145 - val_f1_m: 0.8098 - val_precision_m: 0.8453 - val_recall_m: 0.7772\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.5675 - acc: 0.8197 - f1_m: 0.8080 - precision_m: 0.8500 - recall_m: 0.7712 - val_loss: 0.6284 - val_acc: 0.8226 - val_f1_m: 0.8211 - val_precision_m: 0.8707 - val_recall_m: 0.7772\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.5768 - acc: 0.8179 - f1_m: 0.8163 - precision_m: 0.8720 - recall_m: 0.7691 - val_loss: 0.6238 - val_acc: 0.8145 - val_f1_m: 0.8297 - val_precision_m: 0.8731 - val_recall_m: 0.7906\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.5128 - acc: 0.8305 - f1_m: 0.8349 - precision_m: 0.8728 - recall_m: 0.8008 - val_loss: 0.6337 - val_acc: 0.8145 - val_f1_m: 0.8165 - val_precision_m: 0.8524 - val_recall_m: 0.7839\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.4858 - acc: 0.8377 - f1_m: 0.8453 - precision_m: 0.8775 - recall_m: 0.8160 - val_loss: 0.6469 - val_acc: 0.8226 - val_f1_m: 0.8350 - val_precision_m: 0.8683 - val_recall_m: 0.8044\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.4994 - acc: 0.8368 - f1_m: 0.8327 - precision_m: 0.8710 - recall_m: 0.7986 - val_loss: 0.6578 - val_acc: 0.8065 - val_f1_m: 0.8095 - val_precision_m: 0.8452 - val_recall_m: 0.7772\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.4929 - acc: 0.8467 - f1_m: 0.8476 - precision_m: 0.8916 - recall_m: 0.8086 - val_loss: 0.7231 - val_acc: 0.8226 - val_f1_m: 0.8221 - val_precision_m: 0.8488 - val_recall_m: 0.7978\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.4861 - acc: 0.8269 - f1_m: 0.8369 - precision_m: 0.8845 - recall_m: 0.7952 - val_loss: 0.6693 - val_acc: 0.8226 - val_f1_m: 0.8234 - val_precision_m: 0.8438 - val_recall_m: 0.8044\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.4865 - acc: 0.8449 - f1_m: 0.8424 - precision_m: 0.8847 - recall_m: 0.8043 - val_loss: 0.7038 - val_acc: 0.7984 - val_f1_m: 0.7865 - val_precision_m: 0.8444 - val_recall_m: 0.7361\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.4882 - acc: 0.8368 - f1_m: 0.8384 - precision_m: 0.8804 - recall_m: 0.8013 - val_loss: 0.6499 - val_acc: 0.8145 - val_f1_m: 0.8237 - val_precision_m: 0.8597 - val_recall_m: 0.7911\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.5174 - acc: 0.8323 - f1_m: 0.8270 - precision_m: 0.8744 - recall_m: 0.7855 - val_loss: 0.7161 - val_acc: 0.8226 - val_f1_m: 0.8125 - val_precision_m: 0.8357 - val_recall_m: 0.7911\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.5376 - acc: 0.8170 - f1_m: 0.8187 - precision_m: 0.8589 - recall_m: 0.7830 - val_loss: 0.6658 - val_acc: 0.8306 - val_f1_m: 0.8125 - val_precision_m: 0.8357 - val_recall_m: 0.7911\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.4863 - acc: 0.8386 - f1_m: 0.8371 - precision_m: 0.8759 - recall_m: 0.8025 - val_loss: 0.6571 - val_acc: 0.7903 - val_f1_m: 0.8054 - val_precision_m: 0.8442 - val_recall_m: 0.7706\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.5357 - acc: 0.8179 - f1_m: 0.8098 - precision_m: 0.8590 - recall_m: 0.7675 - val_loss: 0.6061 - val_acc: 0.7742 - val_f1_m: 0.7957 - val_precision_m: 0.8652 - val_recall_m: 0.7372\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.7216 - acc: 0.7529 - f1_m: 0.7569 - precision_m: 0.8119 - recall_m: 0.7103 - val_loss: 0.6681 - val_acc: 0.7742 - val_f1_m: 0.7824 - val_precision_m: 0.8618 - val_recall_m: 0.7167\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5795 - acc: 0.8251 - f1_m: 0.8166 - precision_m: 0.8714 - recall_m: 0.7722 - val_loss: 0.5691 - val_acc: 0.8145 - val_f1_m: 0.8146 - val_precision_m: 0.8410 - val_recall_m: 0.7900\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5489 - acc: 0.8359 - f1_m: 0.8221 - precision_m: 0.8574 - recall_m: 0.7902 - val_loss: 0.5695 - val_acc: 0.8145 - val_f1_m: 0.8214 - val_precision_m: 0.8479 - val_recall_m: 0.7967\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5810 - acc: 0.8106 - f1_m: 0.7985 - precision_m: 0.8479 - recall_m: 0.7555 - val_loss: 0.6022 - val_acc: 0.7984 - val_f1_m: 0.8051 - val_precision_m: 0.8282 - val_recall_m: 0.7833\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5167 - acc: 0.8332 - f1_m: 0.8397 - precision_m: 0.8833 - recall_m: 0.8009 - val_loss: 0.5843 - val_acc: 0.7984 - val_f1_m: 0.7897 - val_precision_m: 0.8517 - val_recall_m: 0.7367\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.4949 - acc: 0.8440 - f1_m: 0.8452 - precision_m: 0.8772 - recall_m: 0.8160 - val_loss: 0.6639 - val_acc: 0.7823 - val_f1_m: 0.7870 - val_precision_m: 0.8636 - val_recall_m: 0.7233\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5020 - acc: 0.8449 - f1_m: 0.8408 - precision_m: 0.8800 - recall_m: 0.8059 - val_loss: 0.5994 - val_acc: 0.8306 - val_f1_m: 0.8162 - val_precision_m: 0.8367 - val_recall_m: 0.7967\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.4997 - acc: 0.8494 - f1_m: 0.8432 - precision_m: 0.8855 - recall_m: 0.8056 - val_loss: 0.5798 - val_acc: 0.8065 - val_f1_m: 0.7970 - val_precision_m: 0.8419 - val_recall_m: 0.7567\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4913 - acc: 0.8359 - f1_m: 0.8437 - precision_m: 0.8901 - recall_m: 0.8025 - val_loss: 0.6713 - val_acc: 0.7903 - val_f1_m: 0.7815 - val_precision_m: 0.8095 - val_recall_m: 0.7556\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5282 - acc: 0.8314 - f1_m: 0.8268 - precision_m: 0.8676 - recall_m: 0.7907 - val_loss: 0.6604 - val_acc: 0.7661 - val_f1_m: 0.7870 - val_precision_m: 0.8636 - val_recall_m: 0.7233\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5167 - acc: 0.8413 - f1_m: 0.8448 - precision_m: 0.8865 - recall_m: 0.8078 - val_loss: 0.6424 - val_acc: 0.7742 - val_f1_m: 0.7743 - val_precision_m: 0.7935 - val_recall_m: 0.7561\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.4987 - acc: 0.8422 - f1_m: 0.8326 - precision_m: 0.8739 - recall_m: 0.7959 - val_loss: 0.5944 - val_acc: 0.7984 - val_f1_m: 0.7916 - val_precision_m: 0.8304 - val_recall_m: 0.7567\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4995 - acc: 0.8467 - f1_m: 0.8421 - precision_m: 0.8811 - recall_m: 0.8069 - val_loss: 0.5987 - val_acc: 0.7500 - val_f1_m: 0.7662 - val_precision_m: 0.8331 - val_recall_m: 0.7094\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.4874 - acc: 0.8368 - f1_m: 0.8349 - precision_m: 0.8784 - recall_m: 0.7964 - val_loss: 0.6161 - val_acc: 0.7661 - val_f1_m: 0.7782 - val_precision_m: 0.8424 - val_recall_m: 0.7233\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5032 - acc: 0.8386 - f1_m: 0.8398 - precision_m: 0.8772 - recall_m: 0.8061 - val_loss: 0.8840 - val_acc: 0.7097 - val_f1_m: 0.6969 - val_precision_m: 0.7300 - val_recall_m: 0.6672\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5190 - acc: 0.8521 - f1_m: 0.8431 - precision_m: 0.8903 - recall_m: 0.8029 - val_loss: 0.6251 - val_acc: 0.8065 - val_f1_m: 0.7983 - val_precision_m: 0.8212 - val_recall_m: 0.7767\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.4995 - acc: 0.8341 - f1_m: 0.8460 - precision_m: 0.8826 - recall_m: 0.8130 - val_loss: 0.6174 - val_acc: 0.8065 - val_f1_m: 0.7940 - val_precision_m: 0.8196 - val_recall_m: 0.7700\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4803 - acc: 0.8476 - f1_m: 0.8590 - precision_m: 0.8954 - recall_m: 0.8261 - val_loss: 0.6036 - val_acc: 0.8226 - val_f1_m: 0.8040 - val_precision_m: 0.8665 - val_recall_m: 0.7500\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.4927 - acc: 0.8377 - f1_m: 0.8340 - precision_m: 0.8764 - recall_m: 0.7964 - val_loss: 0.6097 - val_acc: 0.7823 - val_f1_m: 0.7909 - val_precision_m: 0.8456 - val_recall_m: 0.7433\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5128 - acc: 0.8440 - f1_m: 0.8433 - precision_m: 0.8902 - recall_m: 0.8021 - val_loss: 0.6321 - val_acc: 0.7984 - val_f1_m: 0.7712 - val_precision_m: 0.8182 - val_recall_m: 0.7294\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4871 - acc: 0.8413 - f1_m: 0.8432 - precision_m: 0.8793 - recall_m: 0.8108 - val_loss: 0.6039 - val_acc: 0.7661 - val_f1_m: 0.7813 - val_precision_m: 0.8319 - val_recall_m: 0.7367\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5299 - acc: 0.8188 - f1_m: 0.8216 - precision_m: 0.8703 - recall_m: 0.7795 - val_loss: 0.6171 - val_acc: 0.7903 - val_f1_m: 0.7786 - val_precision_m: 0.8258 - val_recall_m: 0.7367\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.5157 - acc: 0.8368 - f1_m: 0.8349 - precision_m: 0.8730 - recall_m: 0.8008 - val_loss: 0.6161 - val_acc: 0.7823 - val_f1_m: 0.7807 - val_precision_m: 0.8490 - val_recall_m: 0.7228\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.5211 - acc: 0.8404 - f1_m: 0.8282 - precision_m: 0.8736 - recall_m: 0.7882 - val_loss: 0.6262 - val_acc: 0.7984 - val_f1_m: 0.7680 - val_precision_m: 0.8280 - val_recall_m: 0.7161\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.4830 - acc: 0.8548 - f1_m: 0.8461 - precision_m: 0.8820 - recall_m: 0.8134 - val_loss: 0.6664 - val_acc: 0.7661 - val_f1_m: 0.7796 - val_precision_m: 0.8553 - val_recall_m: 0.7167\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5610 - acc: 0.8088 - f1_m: 0.8094 - precision_m: 0.8531 - recall_m: 0.7712 - val_loss: 0.9039 - val_acc: 0.7097 - val_f1_m: 0.6990 - val_precision_m: 0.7770 - val_recall_m: 0.6356\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.5747 - acc: 0.7998 - f1_m: 0.8008 - precision_m: 0.8519 - recall_m: 0.7560 - val_loss: 0.6531 - val_acc: 0.7742 - val_f1_m: 0.7729 - val_precision_m: 0.7980 - val_recall_m: 0.7494\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5038 - acc: 0.8359 - f1_m: 0.8325 - precision_m: 0.8770 - recall_m: 0.7933 - val_loss: 0.7024 - val_acc: 0.7903 - val_f1_m: 0.7815 - val_precision_m: 0.8012 - val_recall_m: 0.7628\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5774 - acc: 0.8070 - f1_m: 0.8073 - precision_m: 0.8506 - recall_m: 0.7700 - val_loss: 0.6045 - val_acc: 0.7823 - val_f1_m: 0.7639 - val_precision_m: 0.8267 - val_recall_m: 0.7100\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5020 - acc: 0.8476 - f1_m: 0.8449 - precision_m: 0.8887 - recall_m: 0.8060 - val_loss: 0.6297 - val_acc: 0.7984 - val_f1_m: 0.7924 - val_precision_m: 0.8241 - val_recall_m: 0.7633\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.4991 - acc: 0.8449 - f1_m: 0.8397 - precision_m: 0.8820 - recall_m: 0.8025 - val_loss: 0.6638 - val_acc: 0.7661 - val_f1_m: 0.7677 - val_precision_m: 0.8473 - val_recall_m: 0.7028\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 1s 66ms/step - loss: 0.5245 - acc: 0.8197 - f1_m: 0.8261 - precision_m: 0.8679 - recall_m: 0.7886 - val_loss: 0.6934 - val_acc: 0.7984 - val_f1_m: 0.7851 - val_precision_m: 0.8165 - val_recall_m: 0.7561\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5050 - acc: 0.8386 - f1_m: 0.8251 - precision_m: 0.8786 - recall_m: 0.7793 - val_loss: 0.6353 - val_acc: 0.7984 - val_f1_m: 0.7831 - val_precision_m: 0.8274 - val_recall_m: 0.7433\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.4728 - acc: 0.8521 - f1_m: 0.8401 - precision_m: 0.8862 - recall_m: 0.7999 - val_loss: 0.6421 - val_acc: 0.8145 - val_f1_m: 0.7985 - val_precision_m: 0.8371 - val_recall_m: 0.7633\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5067 - acc: 0.8368 - f1_m: 0.8270 - precision_m: 0.8719 - recall_m: 0.7872 - val_loss: 0.6483 - val_acc: 0.7419 - val_f1_m: 0.7704 - val_precision_m: 0.8535 - val_recall_m: 0.7028\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.4840 - acc: 0.8431 - f1_m: 0.8478 - precision_m: 0.8889 - recall_m: 0.8108 - val_loss: 0.8151 - val_acc: 0.7258 - val_f1_m: 0.7140 - val_precision_m: 0.7427 - val_recall_m: 0.6878\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5153 - acc: 0.8332 - f1_m: 0.8269 - precision_m: 0.8688 - recall_m: 0.7895 - val_loss: 0.7432 - val_acc: 0.7661 - val_f1_m: 0.7718 - val_precision_m: 0.8470 - val_recall_m: 0.7094\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5302 - acc: 0.8179 - f1_m: 0.8211 - precision_m: 0.8700 - recall_m: 0.7782 - val_loss: 0.6230 - val_acc: 0.8065 - val_f1_m: 0.7914 - val_precision_m: 0.8141 - val_recall_m: 0.7700\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.4858 - acc: 0.8440 - f1_m: 0.8471 - precision_m: 0.8906 - recall_m: 0.8082 - val_loss: 0.6460 - val_acc: 0.7742 - val_f1_m: 0.7691 - val_precision_m: 0.8401 - val_recall_m: 0.7094\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5373 - acc: 0.8368 - f1_m: 0.8284 - precision_m: 0.8707 - recall_m: 0.7912 - val_loss: 0.6669 - val_acc: 0.7823 - val_f1_m: 0.7671 - val_precision_m: 0.8099 - val_recall_m: 0.7289\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.4669 - acc: 0.8503 - f1_m: 0.8572 - precision_m: 0.9070 - recall_m: 0.8139 - val_loss: 0.6907 - val_acc: 0.7339 - val_f1_m: 0.7498 - val_precision_m: 0.8233 - val_recall_m: 0.6889\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.4799 - acc: 0.8413 - f1_m: 0.8408 - precision_m: 0.8795 - recall_m: 0.8064 - val_loss: 0.6565 - val_acc: 0.7984 - val_f1_m: 0.7808 - val_precision_m: 0.8150 - val_recall_m: 0.7494\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.4774 - acc: 0.8431 - f1_m: 0.8420 - precision_m: 0.8899 - recall_m: 0.8003 - val_loss: 0.6578 - val_acc: 0.7742 - val_f1_m: 0.7900 - val_precision_m: 0.8516 - val_recall_m: 0.7367\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.4577 - acc: 0.8557 - f1_m: 0.8538 - precision_m: 0.8912 - recall_m: 0.8199 - val_loss: 0.6913 - val_acc: 0.7823 - val_f1_m: 0.7797 - val_precision_m: 0.8205 - val_recall_m: 0.7428\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5114 - acc: 0.8350 - f1_m: 0.8413 - precision_m: 0.8842 - recall_m: 0.8034 - val_loss: 0.6838 - val_acc: 0.7581 - val_f1_m: 0.7782 - val_precision_m: 0.8092 - val_recall_m: 0.7494\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.4720 - acc: 0.8404 - f1_m: 0.8370 - precision_m: 0.8911 - recall_m: 0.7907 - val_loss: 0.6676 - val_acc: 0.7903 - val_f1_m: 0.7938 - val_precision_m: 0.8350 - val_recall_m: 0.7567\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5155 - acc: 0.8368 - f1_m: 0.8279 - precision_m: 0.8824 - recall_m: 0.7871 - val_loss: 0.6847 - val_acc: 0.7742 - val_f1_m: 0.7421 - val_precision_m: 0.7785 - val_recall_m: 0.7094\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5105 - acc: 0.8386 - f1_m: 0.8416 - precision_m: 0.8864 - recall_m: 0.8021 - val_loss: 0.6322 - val_acc: 0.7903 - val_f1_m: 0.7786 - val_precision_m: 0.8258 - val_recall_m: 0.7367\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.4705 - acc: 0.8512 - f1_m: 0.8513 - precision_m: 0.8930 - recall_m: 0.8138 - val_loss: 0.6387 - val_acc: 0.7823 - val_f1_m: 0.7901 - val_precision_m: 0.8348 - val_recall_m: 0.7500\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.5147 - acc: 0.8350 - f1_m: 0.8247 - precision_m: 0.8787 - recall_m: 0.7777 - val_loss: 0.4766 - val_acc: 0.8306 - val_f1_m: 0.8467 - val_precision_m: 0.9024 - val_recall_m: 0.7978\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5176 - acc: 0.8323 - f1_m: 0.8360 - precision_m: 0.8788 - recall_m: 0.7983 - val_loss: 0.4242 - val_acc: 0.8871 - val_f1_m: 0.8658 - val_precision_m: 0.9108 - val_recall_m: 0.8250\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.4925 - acc: 0.8440 - f1_m: 0.8384 - precision_m: 0.8853 - recall_m: 0.7977 - val_loss: 0.4698 - val_acc: 0.8468 - val_f1_m: 0.8537 - val_precision_m: 0.9094 - val_recall_m: 0.8044\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.4890 - acc: 0.8395 - f1_m: 0.8458 - precision_m: 0.8816 - recall_m: 0.8139 - val_loss: 0.4614 - val_acc: 0.8548 - val_f1_m: 0.8657 - val_precision_m: 0.9107 - val_recall_m: 0.8250\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5426 - acc: 0.8242 - f1_m: 0.8259 - precision_m: 0.8714 - recall_m: 0.7860 - val_loss: 0.6088 - val_acc: 0.7984 - val_f1_m: 0.7816 - val_precision_m: 0.8323 - val_recall_m: 0.7372\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5104 - acc: 0.8296 - f1_m: 0.8229 - precision_m: 0.8729 - recall_m: 0.7794 - val_loss: 0.4886 - val_acc: 0.8306 - val_f1_m: 0.8393 - val_precision_m: 0.8952 - val_recall_m: 0.7906\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5097 - acc: 0.8314 - f1_m: 0.8278 - precision_m: 0.8732 - recall_m: 0.7881 - val_loss: 0.6411 - val_acc: 0.7903 - val_f1_m: 0.7916 - val_precision_m: 0.8297 - val_recall_m: 0.7572\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.6174 - acc: 0.7953 - f1_m: 0.7889 - precision_m: 0.8400 - recall_m: 0.7451 - val_loss: 0.4768 - val_acc: 0.8387 - val_f1_m: 0.8425 - val_precision_m: 0.9013 - val_recall_m: 0.7911\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5105 - acc: 0.8314 - f1_m: 0.8333 - precision_m: 0.8774 - recall_m: 0.7947 - val_loss: 0.4962 - val_acc: 0.8387 - val_f1_m: 0.8407 - val_precision_m: 0.8888 - val_recall_m: 0.7978\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5110 - acc: 0.8377 - f1_m: 0.8194 - precision_m: 0.8602 - recall_m: 0.7833 - val_loss: 0.4821 - val_acc: 0.8387 - val_f1_m: 0.8407 - val_precision_m: 0.8888 - val_recall_m: 0.7978\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5510 - acc: 0.8142 - f1_m: 0.8176 - precision_m: 0.8642 - recall_m: 0.7768 - val_loss: 0.4655 - val_acc: 0.8548 - val_f1_m: 0.8586 - val_precision_m: 0.9032 - val_recall_m: 0.8183\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.4889 - acc: 0.8476 - f1_m: 0.8459 - precision_m: 0.8862 - recall_m: 0.8100 - val_loss: 0.5064 - val_acc: 0.8387 - val_f1_m: 0.8382 - val_precision_m: 0.9012 - val_recall_m: 0.7839\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5137 - acc: 0.8449 - f1_m: 0.8382 - precision_m: 0.8819 - recall_m: 0.7999 - val_loss: 0.4502 - val_acc: 0.8468 - val_f1_m: 0.8537 - val_precision_m: 0.9094 - val_recall_m: 0.8044\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5471 - acc: 0.8287 - f1_m: 0.8270 - precision_m: 0.8649 - recall_m: 0.7930 - val_loss: 0.6479 - val_acc: 0.7742 - val_f1_m: 0.7911 - val_precision_m: 0.8367 - val_recall_m: 0.7506\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.6011 - acc: 0.7908 - f1_m: 0.7920 - precision_m: 0.8462 - recall_m: 0.7456 - val_loss: 0.6994 - val_acc: 0.7339 - val_f1_m: 0.7517 - val_precision_m: 0.8174 - val_recall_m: 0.6967\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5557 - acc: 0.8115 - f1_m: 0.8132 - precision_m: 0.8649 - recall_m: 0.7686 - val_loss: 0.5687 - val_acc: 0.8226 - val_f1_m: 0.8044 - val_precision_m: 0.8497 - val_recall_m: 0.7639\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.4890 - acc: 0.8422 - f1_m: 0.8455 - precision_m: 0.8915 - recall_m: 0.8047 - val_loss: 0.4902 - val_acc: 0.8468 - val_f1_m: 0.8380 - val_precision_m: 0.8827 - val_recall_m: 0.7978\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 61ms/step - loss: 0.4881 - acc: 0.8485 - f1_m: 0.8384 - precision_m: 0.8855 - recall_m: 0.7968 - val_loss: 0.5036 - val_acc: 0.8387 - val_f1_m: 0.8453 - val_precision_m: 0.8827 - val_recall_m: 0.8111\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5034 - acc: 0.8377 - f1_m: 0.8340 - precision_m: 0.8733 - recall_m: 0.7990 - val_loss: 0.4602 - val_acc: 0.8306 - val_f1_m: 0.8449 - val_precision_m: 0.8899 - val_recall_m: 0.8044\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.4999 - acc: 0.8458 - f1_m: 0.8420 - precision_m: 0.8878 - recall_m: 0.8021 - val_loss: 0.5340 - val_acc: 0.8306 - val_f1_m: 0.8269 - val_precision_m: 0.8743 - val_recall_m: 0.7844\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5159 - acc: 0.8224 - f1_m: 0.8201 - precision_m: 0.8680 - recall_m: 0.7777 - val_loss: 0.5927 - val_acc: 0.7903 - val_f1_m: 0.8163 - val_precision_m: 0.8767 - val_recall_m: 0.7639\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.4871 - acc: 0.8485 - f1_m: 0.8476 - precision_m: 0.8962 - recall_m: 0.8051 - val_loss: 0.4588 - val_acc: 0.8468 - val_f1_m: 0.8464 - val_precision_m: 0.9015 - val_recall_m: 0.7978\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.4993 - acc: 0.8494 - f1_m: 0.8420 - precision_m: 0.8864 - recall_m: 0.8025 - val_loss: 0.4891 - val_acc: 0.8548 - val_f1_m: 0.8546 - val_precision_m: 0.9024 - val_recall_m: 0.8117\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5091 - acc: 0.8386 - f1_m: 0.8357 - precision_m: 0.8884 - recall_m: 0.7895 - val_loss: 0.4849 - val_acc: 0.8226 - val_f1_m: 0.8437 - val_precision_m: 0.8952 - val_recall_m: 0.7978\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5599 - acc: 0.8161 - f1_m: 0.8082 - precision_m: 0.8566 - recall_m: 0.7660 - val_loss: 0.5287 - val_acc: 0.8145 - val_f1_m: 0.8343 - val_precision_m: 0.9008 - val_recall_m: 0.7772\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.4925 - acc: 0.8485 - f1_m: 0.8434 - precision_m: 0.8861 - recall_m: 0.8056 - val_loss: 0.4704 - val_acc: 0.8387 - val_f1_m: 0.8410 - val_precision_m: 0.8893 - val_recall_m: 0.7978\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5067 - acc: 0.8350 - f1_m: 0.8331 - precision_m: 0.8746 - recall_m: 0.7960 - val_loss: 0.4823 - val_acc: 0.8468 - val_f1_m: 0.8409 - val_precision_m: 0.8891 - val_recall_m: 0.7978\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5065 - acc: 0.8377 - f1_m: 0.8330 - precision_m: 0.8656 - recall_m: 0.8034 - val_loss: 0.5068 - val_acc: 0.8226 - val_f1_m: 0.8282 - val_precision_m: 0.8870 - val_recall_m: 0.7772\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.4807 - acc: 0.8485 - f1_m: 0.8472 - precision_m: 0.8917 - recall_m: 0.8073 - val_loss: 0.6615 - val_acc: 0.7903 - val_f1_m: 0.7807 - val_precision_m: 0.8394 - val_recall_m: 0.7300\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5611 - acc: 0.8079 - f1_m: 0.8137 - precision_m: 0.8682 - recall_m: 0.7665 - val_loss: 0.4775 - val_acc: 0.8468 - val_f1_m: 0.8546 - val_precision_m: 0.9024 - val_recall_m: 0.8117\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.4725 - acc: 0.8440 - f1_m: 0.8482 - precision_m: 0.8935 - recall_m: 0.8082 - val_loss: 0.4653 - val_acc: 0.8468 - val_f1_m: 0.8516 - val_precision_m: 0.8968 - val_recall_m: 0.8111\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.4882 - acc: 0.8377 - f1_m: 0.8472 - precision_m: 0.8920 - recall_m: 0.8073 - val_loss: 0.4581 - val_acc: 0.8710 - val_f1_m: 0.8575 - val_precision_m: 0.9097 - val_recall_m: 0.8111\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.4872 - acc: 0.8467 - f1_m: 0.8515 - precision_m: 0.8876 - recall_m: 0.8191 - val_loss: 0.4581 - val_acc: 0.8710 - val_f1_m: 0.8655 - val_precision_m: 0.9104 - val_recall_m: 0.8250\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5207 - acc: 0.8368 - f1_m: 0.8369 - precision_m: 0.8861 - recall_m: 0.7938 - val_loss: 0.5802 - val_acc: 0.8226 - val_f1_m: 0.8106 - val_precision_m: 0.8634 - val_recall_m: 0.7639\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.4995 - acc: 0.8359 - f1_m: 0.8274 - precision_m: 0.8738 - recall_m: 0.7869 - val_loss: 0.4579 - val_acc: 0.8387 - val_f1_m: 0.8479 - val_precision_m: 0.8965 - val_recall_m: 0.8044\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.4987 - acc: 0.8431 - f1_m: 0.8307 - precision_m: 0.8824 - recall_m: 0.7863 - val_loss: 0.4870 - val_acc: 0.8145 - val_f1_m: 0.8284 - val_precision_m: 0.8875 - val_recall_m: 0.7772\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.4732 - acc: 0.8404 - f1_m: 0.8358 - precision_m: 0.8750 - recall_m: 0.8007 - val_loss: 0.6409 - val_acc: 0.7823 - val_f1_m: 0.7866 - val_precision_m: 0.8445 - val_recall_m: 0.7361\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.5250 - acc: 0.8233 - f1_m: 0.8157 - precision_m: 0.8629 - recall_m: 0.7743 - val_loss: 0.4832 - val_acc: 0.8468 - val_f1_m: 0.8437 - val_precision_m: 0.8952 - val_recall_m: 0.7978\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5167 - acc: 0.8206 - f1_m: 0.8176 - precision_m: 0.8575 - recall_m: 0.7820 - val_loss: 0.5062 - val_acc: 0.8387 - val_f1_m: 0.8212 - val_precision_m: 0.8796 - val_recall_m: 0.7706\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5279 - acc: 0.8278 - f1_m: 0.8192 - precision_m: 0.8606 - recall_m: 0.7824 - val_loss: 0.5026 - val_acc: 0.8306 - val_f1_m: 0.8299 - val_precision_m: 0.8738 - val_recall_m: 0.7906\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.4822 - acc: 0.8422 - f1_m: 0.8363 - precision_m: 0.8821 - recall_m: 0.7959 - val_loss: 0.4826 - val_acc: 0.8306 - val_f1_m: 0.8269 - val_precision_m: 0.8745 - val_recall_m: 0.7844\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.4728 - acc: 0.8449 - f1_m: 0.8443 - precision_m: 0.9010 - recall_m: 0.7968 - val_loss: 0.4752 - val_acc: 0.8226 - val_f1_m: 0.8339 - val_precision_m: 0.8819 - val_recall_m: 0.7911\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5271 - acc: 0.8287 - f1_m: 0.8325 - precision_m: 0.8738 - recall_m: 0.7960 - val_loss: 0.5079 - val_acc: 0.8306 - val_f1_m: 0.8339 - val_precision_m: 0.8817 - val_recall_m: 0.7911\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.4688 - acc: 0.8647 - f1_m: 0.8620 - precision_m: 0.9093 - recall_m: 0.8200 - val_loss: 0.5335 - val_acc: 0.8548 - val_f1_m: 0.8461 - val_precision_m: 0.8848 - val_recall_m: 0.8111\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5512 - acc: 0.8142 - f1_m: 0.7967 - precision_m: 0.8322 - recall_m: 0.7649 - val_loss: 0.5416 - val_acc: 0.8306 - val_f1_m: 0.8282 - val_precision_m: 0.8870 - val_recall_m: 0.7772\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.5525 - acc: 0.8224 - f1_m: 0.8221 - precision_m: 0.8755 - recall_m: 0.7760 - val_loss: 0.4972 - val_acc: 0.8387 - val_f1_m: 0.8559 - val_precision_m: 0.8971 - val_recall_m: 0.8183\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 0.5046 - acc: 0.8296 - f1_m: 0.8337 - precision_m: 0.8726 - recall_m: 0.7986 - val_loss: 0.5150 - val_acc: 0.8387 - val_f1_m: 0.8480 - val_precision_m: 0.8888 - val_recall_m: 0.8111\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.5050 - acc: 0.8215 - f1_m: 0.8176 - precision_m: 0.8653 - recall_m: 0.7768 - val_loss: 0.4939 - val_acc: 0.8306 - val_f1_m: 0.8255 - val_precision_m: 0.8811 - val_recall_m: 0.7772\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.4982 - acc: 0.8404 - f1_m: 0.8367 - precision_m: 0.8865 - recall_m: 0.7929 - val_loss: 0.5461 - val_acc: 0.8226 - val_f1_m: 0.8228 - val_precision_m: 0.8658 - val_recall_m: 0.7844\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 53ms/step - loss: 0.6024 - acc: 0.7881 - f1_m: 0.7864 - precision_m: 0.8336 - recall_m: 0.7446 - val_loss: 0.5235 - val_acc: 0.8145 - val_f1_m: 0.8271 - val_precision_m: 0.8931 - val_recall_m: 0.7706\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.5119 - acc: 0.8305 - f1_m: 0.8298 - precision_m: 0.8726 - recall_m: 0.7916 - val_loss: 0.4158 - val_acc: 0.8710 - val_f1_m: 0.8317 - val_precision_m: 0.8977 - val_recall_m: 0.7761\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.4658 - acc: 0.8476 - f1_m: 0.8496 - precision_m: 0.8950 - recall_m: 0.8095 - val_loss: 0.4265 - val_acc: 0.8790 - val_f1_m: 0.8460 - val_precision_m: 0.9131 - val_recall_m: 0.7894\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5014 - acc: 0.8386 - f1_m: 0.8407 - precision_m: 0.8807 - recall_m: 0.8051 - val_loss: 0.4347 - val_acc: 0.8548 - val_f1_m: 0.8422 - val_precision_m: 0.9208 - val_recall_m: 0.7767\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5841 - acc: 0.7962 - f1_m: 0.8046 - precision_m: 0.8625 - recall_m: 0.7547 - val_loss: 0.4535 - val_acc: 0.8710 - val_f1_m: 0.8252 - val_precision_m: 0.9091 - val_recall_m: 0.7561\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5433 - acc: 0.8179 - f1_m: 0.8181 - precision_m: 0.8700 - recall_m: 0.7742 - val_loss: 0.8825 - val_acc: 0.6855 - val_f1_m: 0.6924 - val_precision_m: 0.7267 - val_recall_m: 0.6617\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.6275 - acc: 0.7791 - f1_m: 0.7798 - precision_m: 0.8412 - recall_m: 0.7273 - val_loss: 0.4546 - val_acc: 0.8790 - val_f1_m: 0.8264 - val_precision_m: 0.9030 - val_recall_m: 0.7628\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.5048 - acc: 0.8296 - f1_m: 0.8312 - precision_m: 0.8724 - recall_m: 0.7943 - val_loss: 0.4437 - val_acc: 0.8710 - val_f1_m: 0.8491 - val_precision_m: 0.9014 - val_recall_m: 0.8033\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.4823 - acc: 0.8539 - f1_m: 0.8484 - precision_m: 0.8817 - recall_m: 0.8182 - val_loss: 0.4520 - val_acc: 0.8548 - val_f1_m: 0.8462 - val_precision_m: 0.9215 - val_recall_m: 0.7833\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5613 - acc: 0.8161 - f1_m: 0.8149 - precision_m: 0.8581 - recall_m: 0.7769 - val_loss: 0.5852 - val_acc: 0.7823 - val_f1_m: 0.7854 - val_precision_m: 0.8706 - val_recall_m: 0.7161\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.6264 - acc: 0.7836 - f1_m: 0.7845 - precision_m: 0.8423 - recall_m: 0.7356 - val_loss: 0.5148 - val_acc: 0.8145 - val_f1_m: 0.8198 - val_precision_m: 0.8954 - val_recall_m: 0.7561\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5086 - acc: 0.8368 - f1_m: 0.8412 - precision_m: 0.8815 - recall_m: 0.8052 - val_loss: 0.4502 - val_acc: 0.8548 - val_f1_m: 0.8437 - val_precision_m: 0.9062 - val_recall_m: 0.7900\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 1s 66ms/step - loss: 0.4981 - acc: 0.8377 - f1_m: 0.8304 - precision_m: 0.8764 - recall_m: 0.7899 - val_loss: 0.4545 - val_acc: 0.8871 - val_f1_m: 0.8346 - val_precision_m: 0.9044 - val_recall_m: 0.7761\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.4668 - acc: 0.8494 - f1_m: 0.8490 - precision_m: 0.8880 - recall_m: 0.8138 - val_loss: 0.4763 - val_acc: 0.8548 - val_f1_m: 0.8557 - val_precision_m: 0.8908 - val_recall_m: 0.8239\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.5111 - acc: 0.8323 - f1_m: 0.8280 - precision_m: 0.8773 - recall_m: 0.7851 - val_loss: 0.4422 - val_acc: 0.8468 - val_f1_m: 0.8501 - val_precision_m: 0.9220 - val_recall_m: 0.7900\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.4934 - acc: 0.8359 - f1_m: 0.8416 - precision_m: 0.8798 - recall_m: 0.8073 - val_loss: 0.4408 - val_acc: 0.8790 - val_f1_m: 0.8520 - val_precision_m: 0.9079 - val_recall_m: 0.8033\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.4902 - acc: 0.8368 - f1_m: 0.8367 - precision_m: 0.8751 - recall_m: 0.8021 - val_loss: 0.4565 - val_acc: 0.8710 - val_f1_m: 0.8359 - val_precision_m: 0.8987 - val_recall_m: 0.7828\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 1s 60ms/step - loss: 0.4850 - acc: 0.8377 - f1_m: 0.8271 - precision_m: 0.8711 - recall_m: 0.7881 - val_loss: 0.5072 - val_acc: 0.8065 - val_f1_m: 0.8208 - val_precision_m: 0.8885 - val_recall_m: 0.7628\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.4862 - acc: 0.8413 - f1_m: 0.8388 - precision_m: 0.8766 - recall_m: 0.8052 - val_loss: 0.4472 - val_acc: 0.8710 - val_f1_m: 0.8317 - val_precision_m: 0.8977 - val_recall_m: 0.7761\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.4555 - acc: 0.8521 - f1_m: 0.8549 - precision_m: 0.8906 - recall_m: 0.8225 - val_loss: 0.4492 - val_acc: 0.8548 - val_f1_m: 0.8408 - val_precision_m: 0.8995 - val_recall_m: 0.7900\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.4992 - acc: 0.8386 - f1_m: 0.8367 - precision_m: 0.8726 - recall_m: 0.8043 - val_loss: 0.5234 - val_acc: 0.8145 - val_f1_m: 0.8343 - val_precision_m: 0.8675 - val_recall_m: 0.8039\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5243 - acc: 0.8368 - f1_m: 0.8288 - precision_m: 0.8787 - recall_m: 0.7864 - val_loss: 0.6320 - val_acc: 0.7742 - val_f1_m: 0.7559 - val_precision_m: 0.8186 - val_recall_m: 0.7022\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.4901 - acc: 0.8413 - f1_m: 0.8367 - precision_m: 0.8686 - recall_m: 0.8077 - val_loss: 0.4492 - val_acc: 0.8629 - val_f1_m: 0.8408 - val_precision_m: 0.8995 - val_recall_m: 0.7900\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 0.5245 - acc: 0.8278 - f1_m: 0.8301 - precision_m: 0.8811 - recall_m: 0.7856 - val_loss: 0.4666 - val_acc: 0.8548 - val_f1_m: 0.8380 - val_precision_m: 0.8931 - val_recall_m: 0.7900\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.4852 - acc: 0.8458 - f1_m: 0.8374 - precision_m: 0.8778 - recall_m: 0.8016 - val_loss: 0.4773 - val_acc: 0.8548 - val_f1_m: 0.8433 - val_precision_m: 0.9148 - val_recall_m: 0.7833\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 0.5290 - acc: 0.8179 - f1_m: 0.8143 - precision_m: 0.8612 - recall_m: 0.7729 - val_loss: 0.4946 - val_acc: 0.8226 - val_f1_m: 0.8475 - val_precision_m: 0.8886 - val_recall_m: 0.8106\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.5014 - acc: 0.8287 - f1_m: 0.8359 - precision_m: 0.8791 - recall_m: 0.7978 - val_loss: 0.4467 - val_acc: 0.8790 - val_f1_m: 0.8408 - val_precision_m: 0.8995 - val_recall_m: 0.7900\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 0.4700 - acc: 0.8512 - f1_m: 0.8553 - precision_m: 0.8876 - recall_m: 0.8261 - val_loss: 0.4610 - val_acc: 0.8548 - val_f1_m: 0.8408 - val_precision_m: 0.8995 - val_recall_m: 0.7900\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4738 - acc: 0.8494 - f1_m: 0.8380 - precision_m: 0.8830 - recall_m: 0.7986 - val_loss: 0.4671 - val_acc: 0.8548 - val_f1_m: 0.8401 - val_precision_m: 0.9061 - val_recall_m: 0.7833\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4932 - acc: 0.8440 - f1_m: 0.8446 - precision_m: 0.8817 - recall_m: 0.8113 - val_loss: 0.4948 - val_acc: 0.8306 - val_f1_m: 0.8390 - val_precision_m: 0.9124 - val_recall_m: 0.7767\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.5368 - acc: 0.8332 - f1_m: 0.8244 - precision_m: 0.8756 - recall_m: 0.7799 - val_loss: 0.4634 - val_acc: 0.8629 - val_f1_m: 0.8359 - val_precision_m: 0.8809 - val_recall_m: 0.7967\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.4861 - acc: 0.8413 - f1_m: 0.8444 - precision_m: 0.8807 - recall_m: 0.8117 - val_loss: 0.4614 - val_acc: 0.8629 - val_f1_m: 0.8337 - val_precision_m: 0.8919 - val_recall_m: 0.7833\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5059 - acc: 0.8341 - f1_m: 0.8295 - precision_m: 0.8694 - recall_m: 0.7938 - val_loss: 0.4706 - val_acc: 0.8629 - val_f1_m: 0.8246 - val_precision_m: 0.8901 - val_recall_m: 0.7694\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5009 - acc: 0.8359 - f1_m: 0.8310 - precision_m: 0.8693 - recall_m: 0.7969 - val_loss: 0.5127 - val_acc: 0.8145 - val_f1_m: 0.8067 - val_precision_m: 0.8737 - val_recall_m: 0.7494\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5007 - acc: 0.8269 - f1_m: 0.8316 - precision_m: 0.8734 - recall_m: 0.7947 - val_loss: 0.4533 - val_acc: 0.8710 - val_f1_m: 0.8359 - val_precision_m: 0.8987 - val_recall_m: 0.7828\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.5794 - acc: 0.7980 - f1_m: 0.7951 - precision_m: 0.8340 - recall_m: 0.7608 - val_loss: 0.6425 - val_acc: 0.7661 - val_f1_m: 0.7586 - val_precision_m: 0.8248 - val_recall_m: 0.7022\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5230 - acc: 0.8341 - f1_m: 0.8224 - precision_m: 0.8736 - recall_m: 0.7786 - val_loss: 0.4825 - val_acc: 0.8306 - val_f1_m: 0.8370 - val_precision_m: 0.8990 - val_recall_m: 0.7833\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.4683 - acc: 0.8413 - f1_m: 0.8420 - precision_m: 0.8832 - recall_m: 0.8051 - val_loss: 0.4501 - val_acc: 0.8710 - val_f1_m: 0.8395 - val_precision_m: 0.8993 - val_recall_m: 0.7894\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.4857 - acc: 0.8404 - f1_m: 0.8474 - precision_m: 0.8844 - recall_m: 0.8139 - val_loss: 0.4594 - val_acc: 0.8629 - val_f1_m: 0.8408 - val_precision_m: 0.8995 - val_recall_m: 0.7900\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.4992 - acc: 0.8395 - f1_m: 0.8300 - precision_m: 0.8679 - recall_m: 0.7963 - val_loss: 0.4569 - val_acc: 0.8790 - val_f1_m: 0.8408 - val_precision_m: 0.8995 - val_recall_m: 0.7900\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.5014 - acc: 0.8260 - f1_m: 0.8374 - precision_m: 0.8830 - recall_m: 0.7974 - val_loss: 0.4895 - val_acc: 0.8629 - val_f1_m: 0.8359 - val_precision_m: 0.8809 - val_recall_m: 0.7967\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.4909 - acc: 0.8422 - f1_m: 0.8396 - precision_m: 0.8726 - recall_m: 0.8095 - val_loss: 0.7474 - val_acc: 0.7258 - val_f1_m: 0.7150 - val_precision_m: 0.7778 - val_recall_m: 0.6617\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.6012 - acc: 0.8025 - f1_m: 0.7951 - precision_m: 0.8503 - recall_m: 0.7482 - val_loss: 0.4699 - val_acc: 0.8548 - val_f1_m: 0.8250 - val_precision_m: 0.8908 - val_recall_m: 0.7694\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.4716 - acc: 0.8404 - f1_m: 0.8475 - precision_m: 0.8850 - recall_m: 0.8134 - val_loss: 0.4799 - val_acc: 0.8387 - val_f1_m: 0.8362 - val_precision_m: 0.9072 - val_recall_m: 0.7767\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.4791 - acc: 0.8359 - f1_m: 0.8381 - precision_m: 0.8844 - recall_m: 0.7973 - val_loss: 0.4750 - val_acc: 0.8710 - val_f1_m: 0.8408 - val_precision_m: 0.8995 - val_recall_m: 0.7900\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4798 - acc: 0.8503 - f1_m: 0.8485 - precision_m: 0.8895 - recall_m: 0.8117 - val_loss: 0.5048 - val_acc: 0.8226 - val_f1_m: 0.8361 - val_precision_m: 0.9057 - val_recall_m: 0.7767\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.5475 - acc: 0.8007 - f1_m: 0.8068 - precision_m: 0.8468 - recall_m: 0.7717 - val_loss: 0.4592 - val_acc: 0.8790 - val_f1_m: 0.8286 - val_precision_m: 0.8911 - val_recall_m: 0.7761\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.4795 - acc: 0.8395 - f1_m: 0.8365 - precision_m: 0.8780 - recall_m: 0.7990 - val_loss: 0.5510 - val_acc: 0.7823 - val_f1_m: 0.8008 - val_precision_m: 0.8597 - val_recall_m: 0.7494\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.4966 - acc: 0.8404 - f1_m: 0.8313 - precision_m: 0.8740 - recall_m: 0.7946 - val_loss: 0.4574 - val_acc: 0.8548 - val_f1_m: 0.8264 - val_precision_m: 0.9030 - val_recall_m: 0.7628\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.4846 - acc: 0.8575 - f1_m: 0.8385 - precision_m: 0.8887 - recall_m: 0.7942 - val_loss: 0.5528 - val_acc: 0.7903 - val_f1_m: 0.7845 - val_precision_m: 0.8495 - val_recall_m: 0.7289\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.5255 - acc: 0.8215 - f1_m: 0.8278 - precision_m: 0.8703 - recall_m: 0.7900 - val_loss: 0.5296 - val_acc: 0.8145 - val_f1_m: 0.8200 - val_precision_m: 0.8619 - val_recall_m: 0.7833\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5604 - acc: 0.8088 - f1_m: 0.8107 - precision_m: 0.8543 - recall_m: 0.7721 - val_loss: 0.5069 - val_acc: 0.8145 - val_f1_m: 0.8099 - val_precision_m: 0.8629 - val_recall_m: 0.7633\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.5419 - acc: 0.8269 - f1_m: 0.8264 - precision_m: 0.8763 - recall_m: 0.7830 - val_loss: 0.4745 - val_acc: 0.8306 - val_f1_m: 0.8185 - val_precision_m: 0.8272 - val_recall_m: 0.8100\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.5562 - acc: 0.8206 - f1_m: 0.8121 - precision_m: 0.8514 - recall_m: 0.7773 - val_loss: 0.4538 - val_acc: 0.8548 - val_f1_m: 0.8272 - val_precision_m: 0.8460 - val_recall_m: 0.8094\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4896 - acc: 0.8485 - f1_m: 0.8423 - precision_m: 0.8795 - recall_m: 0.8086 - val_loss: 0.5067 - val_acc: 0.8387 - val_f1_m: 0.8156 - val_precision_m: 0.8684 - val_recall_m: 0.7689\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.4620 - acc: 0.8503 - f1_m: 0.8488 - precision_m: 0.8814 - recall_m: 0.8195 - val_loss: 0.5841 - val_acc: 0.8145 - val_f1_m: 0.8091 - val_precision_m: 0.8293 - val_recall_m: 0.7900\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 1s 61ms/step - loss: 0.6269 - acc: 0.7773 - f1_m: 0.7878 - precision_m: 0.8242 - recall_m: 0.7556 - val_loss: 0.6246 - val_acc: 0.7823 - val_f1_m: 0.7584 - val_precision_m: 0.8465 - val_recall_m: 0.6878\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.5823 - acc: 0.8043 - f1_m: 0.7935 - precision_m: 0.8538 - recall_m: 0.7429 - val_loss: 0.4967 - val_acc: 0.8387 - val_f1_m: 0.8085 - val_precision_m: 0.8611 - val_recall_m: 0.7622\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.5071 - acc: 0.8359 - f1_m: 0.8355 - precision_m: 0.8833 - recall_m: 0.7938 - val_loss: 0.4928 - val_acc: 0.8468 - val_f1_m: 0.8193 - val_precision_m: 0.8762 - val_recall_m: 0.7694\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.4773 - acc: 0.8512 - f1_m: 0.8534 - precision_m: 0.8914 - recall_m: 0.8195 - val_loss: 0.4952 - val_acc: 0.8306 - val_f1_m: 0.8146 - val_precision_m: 0.8264 - val_recall_m: 0.8033\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.4630 - acc: 0.8530 - f1_m: 0.8477 - precision_m: 0.8830 - recall_m: 0.8160 - val_loss: 0.5261 - val_acc: 0.8226 - val_f1_m: 0.8117 - val_precision_m: 0.8204 - val_recall_m: 0.8033\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.4887 - acc: 0.8386 - f1_m: 0.8303 - precision_m: 0.8710 - recall_m: 0.7937 - val_loss: 0.4808 - val_acc: 0.8468 - val_f1_m: 0.8224 - val_precision_m: 0.8831 - val_recall_m: 0.7694\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 2s 64ms/step - loss: 0.4575 - acc: 0.8620 - f1_m: 0.8586 - precision_m: 0.9036 - recall_m: 0.8186 - val_loss: 0.4740 - val_acc: 0.8387 - val_f1_m: 0.8374 - val_precision_m: 0.8675 - val_recall_m: 0.8094\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4755 - acc: 0.8467 - f1_m: 0.8432 - precision_m: 0.8732 - recall_m: 0.8156 - val_loss: 0.4872 - val_acc: 0.8306 - val_f1_m: 0.8185 - val_precision_m: 0.8421 - val_recall_m: 0.7961\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 64ms/step - loss: 0.5137 - acc: 0.8296 - f1_m: 0.8327 - precision_m: 0.8843 - recall_m: 0.7873 - val_loss: 0.4787 - val_acc: 0.8629 - val_f1_m: 0.8304 - val_precision_m: 0.8843 - val_recall_m: 0.7828\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 1s 58ms/step - loss: 0.4572 - acc: 0.8602 - f1_m: 0.8555 - precision_m: 0.8933 - recall_m: 0.8213 - val_loss: 0.4716 - val_acc: 0.8306 - val_f1_m: 0.8297 - val_precision_m: 0.8663 - val_recall_m: 0.7961\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.4607 - acc: 0.8503 - f1_m: 0.8497 - precision_m: 0.8862 - recall_m: 0.8169 - val_loss: 0.4740 - val_acc: 0.8226 - val_f1_m: 0.8268 - val_precision_m: 0.8600 - val_recall_m: 0.7961\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 0.4616 - acc: 0.8368 - f1_m: 0.8375 - precision_m: 0.8767 - recall_m: 0.8024 - val_loss: 0.4681 - val_acc: 0.8548 - val_f1_m: 0.8250 - val_precision_m: 0.8725 - val_recall_m: 0.7828\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4671 - acc: 0.8512 - f1_m: 0.8391 - precision_m: 0.8773 - recall_m: 0.8046 - val_loss: 0.4728 - val_acc: 0.8387 - val_f1_m: 0.8326 - val_precision_m: 0.8727 - val_recall_m: 0.7961\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.4774 - acc: 0.8449 - f1_m: 0.8421 - precision_m: 0.8824 - recall_m: 0.8064 - val_loss: 0.4624 - val_acc: 0.8629 - val_f1_m: 0.8322 - val_precision_m: 0.8803 - val_recall_m: 0.7894\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.4958 - acc: 0.8233 - f1_m: 0.8279 - precision_m: 0.8701 - recall_m: 0.7903 - val_loss: 0.4711 - val_acc: 0.8468 - val_f1_m: 0.8297 - val_precision_m: 0.8915 - val_recall_m: 0.7761\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.4861 - acc: 0.8404 - f1_m: 0.8426 - precision_m: 0.8854 - recall_m: 0.8047 - val_loss: 0.4923 - val_acc: 0.8548 - val_f1_m: 0.8219 - val_precision_m: 0.8653 - val_recall_m: 0.7828\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 2s 65ms/step - loss: 0.4877 - acc: 0.8440 - f1_m: 0.8453 - precision_m: 0.8792 - recall_m: 0.8148 - val_loss: 0.4696 - val_acc: 0.8306 - val_f1_m: 0.8182 - val_precision_m: 0.8418 - val_recall_m: 0.7961\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.5251 - acc: 0.8233 - f1_m: 0.8190 - precision_m: 0.8612 - recall_m: 0.7816 - val_loss: 0.5438 - val_acc: 0.8387 - val_f1_m: 0.7975 - val_precision_m: 0.8529 - val_recall_m: 0.7489\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5926 - acc: 0.7980 - f1_m: 0.7983 - precision_m: 0.8520 - recall_m: 0.7526 - val_loss: 0.4878 - val_acc: 0.8306 - val_f1_m: 0.8277 - val_precision_m: 0.8615 - val_recall_m: 0.7967\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4858 - acc: 0.8449 - f1_m: 0.8524 - precision_m: 0.8851 - recall_m: 0.8225 - val_loss: 0.4761 - val_acc: 0.8387 - val_f1_m: 0.8255 - val_precision_m: 0.8496 - val_recall_m: 0.8028\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4472 - acc: 0.8557 - f1_m: 0.8605 - precision_m: 0.8967 - recall_m: 0.8278 - val_loss: 0.4686 - val_acc: 0.8468 - val_f1_m: 0.8297 - val_precision_m: 0.8663 - val_recall_m: 0.7961\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.4555 - acc: 0.8449 - f1_m: 0.8434 - precision_m: 0.8851 - recall_m: 0.8064 - val_loss: 0.6596 - val_acc: 0.7742 - val_f1_m: 0.7873 - val_precision_m: 0.8132 - val_recall_m: 0.7633\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.4806 - acc: 0.8395 - f1_m: 0.8345 - precision_m: 0.8657 - recall_m: 0.8060 - val_loss: 0.4881 - val_acc: 0.8387 - val_f1_m: 0.8320 - val_precision_m: 0.8631 - val_recall_m: 0.8033\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.5026 - acc: 0.8440 - f1_m: 0.8472 - precision_m: 0.8851 - recall_m: 0.8134 - val_loss: 0.5025 - val_acc: 0.8468 - val_f1_m: 0.8045 - val_precision_m: 0.8603 - val_recall_m: 0.7556\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 0.4592 - acc: 0.8611 - f1_m: 0.8517 - precision_m: 0.8892 - recall_m: 0.8182 - val_loss: 0.5024 - val_acc: 0.8306 - val_f1_m: 0.8164 - val_precision_m: 0.8698 - val_recall_m: 0.7694\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.4668 - acc: 0.8404 - f1_m: 0.8323 - precision_m: 0.8656 - recall_m: 0.8024 - val_loss: 0.4611 - val_acc: 0.8387 - val_f1_m: 0.8317 - val_precision_m: 0.8623 - val_recall_m: 0.8033\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.4718 - acc: 0.8548 - f1_m: 0.8496 - precision_m: 0.8934 - recall_m: 0.8107 - val_loss: 0.5119 - val_acc: 0.8145 - val_f1_m: 0.8110 - val_precision_m: 0.8755 - val_recall_m: 0.7561\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.4713 - acc: 0.8395 - f1_m: 0.8444 - precision_m: 0.8825 - recall_m: 0.8100 - val_loss: 0.5536 - val_acc: 0.8065 - val_f1_m: 0.7903 - val_precision_m: 0.8452 - val_recall_m: 0.7422\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.4910 - acc: 0.8440 - f1_m: 0.8452 - precision_m: 0.8914 - recall_m: 0.8043 - val_loss: 0.5855 - val_acc: 0.7903 - val_f1_m: 0.7646 - val_precision_m: 0.8209 - val_recall_m: 0.7156\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.4878 - acc: 0.8467 - f1_m: 0.8473 - precision_m: 0.8881 - recall_m: 0.8108 - val_loss: 0.4878 - val_acc: 0.8387 - val_f1_m: 0.8219 - val_precision_m: 0.8653 - val_recall_m: 0.7828\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.4506 - acc: 0.8485 - f1_m: 0.8430 - precision_m: 0.8783 - recall_m: 0.8112 - val_loss: 0.4821 - val_acc: 0.8387 - val_f1_m: 0.8175 - val_precision_m: 0.8478 - val_recall_m: 0.7894\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5009 - acc: 0.8323 - f1_m: 0.8373 - precision_m: 0.8895 - recall_m: 0.7933 - val_loss: 0.4816 - val_acc: 0.8468 - val_f1_m: 0.8169 - val_precision_m: 0.8709 - val_recall_m: 0.7694\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.5108 - acc: 0.8440 - f1_m: 0.8339 - precision_m: 0.8762 - recall_m: 0.7964 - val_loss: 0.5098 - val_acc: 0.8306 - val_f1_m: 0.8205 - val_precision_m: 0.8537 - val_recall_m: 0.7900\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.4863 - acc: 0.8458 - f1_m: 0.8423 - precision_m: 0.8908 - recall_m: 0.7999 - val_loss: 0.4995 - val_acc: 0.8145 - val_f1_m: 0.8100 - val_precision_m: 0.8391 - val_recall_m: 0.7828\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.4777 - acc: 0.8530 - f1_m: 0.8390 - precision_m: 0.8703 - recall_m: 0.8102 - val_loss: 0.4754 - val_acc: 0.8468 - val_f1_m: 0.8329 - val_precision_m: 0.8732 - val_recall_m: 0.7961\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.5045 - acc: 0.8404 - f1_m: 0.8436 - precision_m: 0.8951 - recall_m: 0.7986 - val_loss: 0.5430 - val_acc: 0.8226 - val_f1_m: 0.8151 - val_precision_m: 0.8580 - val_recall_m: 0.7767\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.5559 - acc: 0.8088 - f1_m: 0.8100 - precision_m: 0.8540 - recall_m: 0.7712 - val_loss: 0.4907 - val_acc: 0.8468 - val_f1_m: 0.8075 - val_precision_m: 0.8673 - val_recall_m: 0.7556\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.4661 - acc: 0.8512 - f1_m: 0.8437 - precision_m: 0.8914 - recall_m: 0.8025 - val_loss: 0.4723 - val_acc: 0.8548 - val_f1_m: 0.8291 - val_precision_m: 0.8732 - val_recall_m: 0.7894\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.4518 - acc: 0.8476 - f1_m: 0.8522 - precision_m: 0.8878 - recall_m: 0.8204 - val_loss: 0.4989 - val_acc: 0.8387 - val_f1_m: 0.8007 - val_precision_m: 0.8270 - val_recall_m: 0.7761\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.4639 - acc: 0.8503 - f1_m: 0.8485 - precision_m: 0.8878 - recall_m: 0.8138 - val_loss: 0.5879 - val_acc: 0.7984 - val_f1_m: 0.7681 - val_precision_m: 0.8118 - val_recall_m: 0.7289\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 2s 85ms/step - loss: 0.4846 - acc: 0.8368 - f1_m: 0.8274 - precision_m: 0.8622 - recall_m: 0.7959 - val_loss: 0.4938 - val_acc: 0.8468 - val_f1_m: 0.8294 - val_precision_m: 0.8732 - val_recall_m: 0.7900\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 2s 91ms/step - loss: 0.4818 - acc: 0.8368 - f1_m: 0.8425 - precision_m: 0.8934 - recall_m: 0.7978 - val_loss: 0.4710 - val_acc: 0.8468 - val_f1_m: 0.8220 - val_precision_m: 0.8656 - val_recall_m: 0.7828\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 2s 94ms/step - loss: 0.4990 - acc: 0.8368 - f1_m: 0.8429 - precision_m: 0.8799 - recall_m: 0.8100 - val_loss: 0.6099 - val_acc: 0.7823 - val_f1_m: 0.7803 - val_precision_m: 0.8309 - val_recall_m: 0.7356\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.5220 - acc: 0.8224 - f1_m: 0.8281 - precision_m: 0.8686 - recall_m: 0.7917 - val_loss: 0.5046 - val_acc: 0.8548 - val_f1_m: 0.8164 - val_precision_m: 0.8698 - val_recall_m: 0.7694\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.4587 - acc: 0.8566 - f1_m: 0.8522 - precision_m: 0.8867 - recall_m: 0.8209 - val_loss: 0.4691 - val_acc: 0.8548 - val_f1_m: 0.8297 - val_precision_m: 0.8663 - val_recall_m: 0.7961\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 3s 106ms/step - loss: 0.4526 - acc: 0.8467 - f1_m: 0.8504 - precision_m: 0.8874 - recall_m: 0.8174 - val_loss: 0.4798 - val_acc: 0.8548 - val_f1_m: 0.8331 - val_precision_m: 0.9119 - val_recall_m: 0.7700\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.4521 - acc: 0.8620 - f1_m: 0.8582 - precision_m: 0.8964 - recall_m: 0.8239 - val_loss: 0.6298 - val_acc: 0.8145 - val_f1_m: 0.8143 - val_precision_m: 0.8636 - val_recall_m: 0.7706\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.5155 - acc: 0.8395 - f1_m: 0.8290 - precision_m: 0.8671 - recall_m: 0.7951 - val_loss: 0.4994 - val_acc: 0.8387 - val_f1_m: 0.8397 - val_precision_m: 0.9069 - val_recall_m: 0.7839\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.4714 - acc: 0.8494 - f1_m: 0.8410 - precision_m: 0.8864 - recall_m: 0.8008 - val_loss: 0.5161 - val_acc: 0.8548 - val_f1_m: 0.8488 - val_precision_m: 0.9219 - val_recall_m: 0.7900\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.4499 - acc: 0.8530 - f1_m: 0.8546 - precision_m: 0.9019 - recall_m: 0.8138 - val_loss: 0.5083 - val_acc: 0.8226 - val_f1_m: 0.8186 - val_precision_m: 0.9028 - val_recall_m: 0.7500\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.5077 - acc: 0.8323 - f1_m: 0.8259 - precision_m: 0.8662 - recall_m: 0.7903 - val_loss: 0.5319 - val_acc: 0.8226 - val_f1_m: 0.8180 - val_precision_m: 0.8821 - val_recall_m: 0.7633\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 0.4576 - acc: 0.8521 - f1_m: 0.8472 - precision_m: 0.8886 - recall_m: 0.8103 - val_loss: 0.5137 - val_acc: 0.8306 - val_f1_m: 0.8267 - val_precision_m: 0.8962 - val_recall_m: 0.7700\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.4875 - acc: 0.8413 - f1_m: 0.8292 - precision_m: 0.8704 - recall_m: 0.7925 - val_loss: 0.5070 - val_acc: 0.8145 - val_f1_m: 0.8267 - val_precision_m: 0.8962 - val_recall_m: 0.7700\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 2s 90ms/step - loss: 0.4871 - acc: 0.8404 - f1_m: 0.8306 - precision_m: 0.8764 - recall_m: 0.7899 - val_loss: 0.5561 - val_acc: 0.7984 - val_f1_m: 0.8029 - val_precision_m: 0.8655 - val_recall_m: 0.7494\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 2s 92ms/step - loss: 0.5026 - acc: 0.8332 - f1_m: 0.8371 - precision_m: 0.8732 - recall_m: 0.8047 - val_loss: 0.5075 - val_acc: 0.8145 - val_f1_m: 0.8272 - val_precision_m: 0.8861 - val_recall_m: 0.7772\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.4937 - acc: 0.8485 - f1_m: 0.8347 - precision_m: 0.8725 - recall_m: 0.8007 - val_loss: 0.5361 - val_acc: 0.8226 - val_f1_m: 0.8275 - val_precision_m: 0.9066 - val_recall_m: 0.7633\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.4800 - acc: 0.8440 - f1_m: 0.8370 - precision_m: 0.8843 - recall_m: 0.7956 - val_loss: 0.6028 - val_acc: 0.7984 - val_f1_m: 0.7952 - val_precision_m: 0.8568 - val_recall_m: 0.7422\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.5323 - acc: 0.8215 - f1_m: 0.8189 - precision_m: 0.8579 - recall_m: 0.7847 - val_loss: 0.5273 - val_acc: 0.8226 - val_f1_m: 0.8224 - val_precision_m: 0.9043 - val_recall_m: 0.7567\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.4687 - acc: 0.8449 - f1_m: 0.8484 - precision_m: 0.8903 - recall_m: 0.8113 - val_loss: 0.5488 - val_acc: 0.8065 - val_f1_m: 0.8017 - val_precision_m: 0.8534 - val_recall_m: 0.7567\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.4560 - acc: 0.8431 - f1_m: 0.8488 - precision_m: 0.8845 - recall_m: 0.8164 - val_loss: 0.6026 - val_acc: 0.8145 - val_f1_m: 0.8105 - val_precision_m: 0.8632 - val_recall_m: 0.7639\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.4676 - acc: 0.8557 - f1_m: 0.8497 - precision_m: 0.8886 - recall_m: 0.8148 - val_loss: 0.5353 - val_acc: 0.8226 - val_f1_m: 0.8254 - val_precision_m: 0.9107 - val_recall_m: 0.7567\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.4537 - acc: 0.8485 - f1_m: 0.8474 - precision_m: 0.8875 - recall_m: 0.8112 - val_loss: 0.5366 - val_acc: 0.8065 - val_f1_m: 0.8131 - val_precision_m: 0.8823 - val_recall_m: 0.7567\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.5401 - acc: 0.8124 - f1_m: 0.8044 - precision_m: 0.8562 - recall_m: 0.7598 - val_loss: 0.5514 - val_acc: 0.8387 - val_f1_m: 0.8231 - val_precision_m: 0.9046 - val_recall_m: 0.7567\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.4672 - acc: 0.8386 - f1_m: 0.8465 - precision_m: 0.8918 - recall_m: 0.8065 - val_loss: 0.5768 - val_acc: 0.8306 - val_f1_m: 0.8349 - val_precision_m: 0.8943 - val_recall_m: 0.7839\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.4583 - acc: 0.8350 - f1_m: 0.8465 - precision_m: 0.8854 - recall_m: 0.8122 - val_loss: 0.5469 - val_acc: 0.8065 - val_f1_m: 0.8179 - val_precision_m: 0.9022 - val_recall_m: 0.7500\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 0.4580 - acc: 0.8458 - f1_m: 0.8477 - precision_m: 0.8914 - recall_m: 0.8091 - val_loss: 0.5529 - val_acc: 0.8306 - val_f1_m: 0.8196 - val_precision_m: 0.8970 - val_recall_m: 0.7567\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.5084 - acc: 0.8314 - f1_m: 0.8352 - precision_m: 0.8750 - recall_m: 0.8000 - val_loss: 0.6409 - val_acc: 0.7581 - val_f1_m: 0.7603 - val_precision_m: 0.8334 - val_recall_m: 0.7011\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.4726 - acc: 0.8395 - f1_m: 0.8416 - precision_m: 0.8873 - recall_m: 0.8013 - val_loss: 0.5804 - val_acc: 0.8145 - val_f1_m: 0.8168 - val_precision_m: 0.8783 - val_recall_m: 0.7639\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.4477 - acc: 0.8593 - f1_m: 0.8536 - precision_m: 0.8858 - recall_m: 0.8243 - val_loss: 0.5883 - val_acc: 0.8065 - val_f1_m: 0.8116 - val_precision_m: 0.8954 - val_recall_m: 0.7433\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.4774 - acc: 0.8296 - f1_m: 0.8297 - precision_m: 0.8750 - recall_m: 0.7903 - val_loss: 0.5670 - val_acc: 0.8226 - val_f1_m: 0.8115 - val_precision_m: 0.8962 - val_recall_m: 0.7433\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 2s 65ms/step - loss: 0.4489 - acc: 0.8503 - f1_m: 0.8449 - precision_m: 0.8897 - recall_m: 0.8055 - val_loss: 0.5856 - val_acc: 0.8226 - val_f1_m: 0.8133 - val_precision_m: 0.8902 - val_recall_m: 0.7500\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.4827 - acc: 0.8485 - f1_m: 0.8441 - precision_m: 0.8947 - recall_m: 0.7999 - val_loss: 0.5811 - val_acc: 0.8065 - val_f1_m: 0.8046 - val_precision_m: 0.8880 - val_recall_m: 0.7367\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 2s 70ms/step - loss: 0.4847 - acc: 0.8368 - f1_m: 0.8362 - precision_m: 0.8821 - recall_m: 0.7968 - val_loss: 0.5748 - val_acc: 0.8145 - val_f1_m: 0.8127 - val_precision_m: 0.8899 - val_recall_m: 0.7500\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 2s 65ms/step - loss: 0.4687 - acc: 0.8449 - f1_m: 0.8351 - precision_m: 0.8790 - recall_m: 0.7963 - val_loss: 0.5715 - val_acc: 0.8145 - val_f1_m: 0.8069 - val_precision_m: 0.8754 - val_recall_m: 0.7500\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.4893 - acc: 0.8359 - f1_m: 0.8338 - precision_m: 0.8762 - recall_m: 0.7973 - val_loss: 0.5948 - val_acc: 0.8226 - val_f1_m: 0.8115 - val_precision_m: 0.8962 - val_recall_m: 0.7433\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.5860 - acc: 0.8016 - f1_m: 0.8067 - precision_m: 0.8588 - recall_m: 0.7621 - val_loss: 0.5741 - val_acc: 0.8306 - val_f1_m: 0.8110 - val_precision_m: 0.8949 - val_recall_m: 0.7433\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 2s 92ms/step - loss: 0.4656 - acc: 0.8476 - f1_m: 0.8423 - precision_m: 0.8807 - recall_m: 0.8082 - val_loss: 0.5592 - val_acc: 0.8145 - val_f1_m: 0.8075 - val_precision_m: 0.8681 - val_recall_m: 0.7567\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 0.5009 - acc: 0.8440 - f1_m: 0.8299 - precision_m: 0.8733 - recall_m: 0.7916 - val_loss: 0.5783 - val_acc: 0.8145 - val_f1_m: 0.8090 - val_precision_m: 0.9012 - val_recall_m: 0.7367\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.4553 - acc: 0.8566 - f1_m: 0.8504 - precision_m: 0.8941 - recall_m: 0.8117 - val_loss: 0.6383 - val_acc: 0.8065 - val_f1_m: 0.8105 - val_precision_m: 0.8632 - val_recall_m: 0.7639\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.4563 - acc: 0.8584 - f1_m: 0.8542 - precision_m: 0.8961 - recall_m: 0.8174 - val_loss: 0.5572 - val_acc: 0.8065 - val_f1_m: 0.7913 - val_precision_m: 0.8750 - val_recall_m: 0.7233\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.4875 - acc: 0.8395 - f1_m: 0.8246 - precision_m: 0.8718 - recall_m: 0.7833 - val_loss: 0.5886 - val_acc: 0.8065 - val_f1_m: 0.8059 - val_precision_m: 0.8913 - val_recall_m: 0.7367\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.4508 - acc: 0.8440 - f1_m: 0.8456 - precision_m: 0.8900 - recall_m: 0.8060 - val_loss: 0.5701 - val_acc: 0.8226 - val_f1_m: 0.8149 - val_precision_m: 0.8957 - val_recall_m: 0.7500\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 1s 63ms/step - loss: 0.4593 - acc: 0.8548 - f1_m: 0.8511 - precision_m: 0.8902 - recall_m: 0.8160 - val_loss: 0.5851 - val_acc: 0.8387 - val_f1_m: 0.8270 - val_precision_m: 0.9066 - val_recall_m: 0.7633\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 1s 64ms/step - loss: 0.4940 - acc: 0.8386 - f1_m: 0.8322 - precision_m: 0.8855 - recall_m: 0.7861 - val_loss: 0.5776 - val_acc: 0.8226 - val_f1_m: 0.7922 - val_precision_m: 0.8579 - val_recall_m: 0.7367\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.4594 - acc: 0.8521 - f1_m: 0.8542 - precision_m: 0.8896 - recall_m: 0.8225 - val_loss: 0.5487 - val_acc: 0.8226 - val_f1_m: 0.8046 - val_precision_m: 0.8792 - val_recall_m: 0.7433\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 1s 62ms/step - loss: 0.4711 - acc: 0.8521 - f1_m: 0.8523 - precision_m: 0.8960 - recall_m: 0.8134 - val_loss: 0.5624 - val_acc: 0.8145 - val_f1_m: 0.8155 - val_precision_m: 0.8972 - val_recall_m: 0.7500\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 1s 65ms/step - loss: 0.4962 - acc: 0.8278 - f1_m: 0.8282 - precision_m: 0.8681 - recall_m: 0.7929 - val_loss: 0.6314 - val_acc: 0.8145 - val_f1_m: 0.8018 - val_precision_m: 0.8618 - val_recall_m: 0.7500\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 2s 67ms/step - loss: 0.5182 - acc: 0.8278 - f1_m: 0.8222 - precision_m: 0.8697 - recall_m: 0.7808 - val_loss: 0.6680 - val_acc: 0.7661 - val_f1_m: 0.7667 - val_precision_m: 0.8367 - val_recall_m: 0.7083\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.4871 - acc: 0.8269 - f1_m: 0.8372 - precision_m: 0.8794 - recall_m: 0.7995 - val_loss: 0.7104 - val_acc: 0.7823 - val_f1_m: 0.7947 - val_precision_m: 0.8360 - val_recall_m: 0.7572\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.5026 - acc: 0.8341 - f1_m: 0.8351 - precision_m: 0.8785 - recall_m: 0.7969 - val_loss: 0.5558 - val_acc: 0.8065 - val_f1_m: 0.7883 - val_precision_m: 0.8682 - val_recall_m: 0.7233\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.4932 - acc: 0.8314 - f1_m: 0.8282 - precision_m: 0.8692 - recall_m: 0.7920 - val_loss: 0.5986 - val_acc: 0.8468 - val_f1_m: 0.8190 - val_precision_m: 0.9048 - val_recall_m: 0.7500\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.4675 - acc: 0.8386 - f1_m: 0.8459 - precision_m: 0.9049 - recall_m: 0.7952 - val_loss: 0.6263 - val_acc: 0.8387 - val_f1_m: 0.8319 - val_precision_m: 0.9074 - val_recall_m: 0.7700\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 2s 93ms/step - loss: 0.4491 - acc: 0.8539 - f1_m: 0.8505 - precision_m: 0.8922 - recall_m: 0.8134 - val_loss: 0.5823 - val_acc: 0.7984 - val_f1_m: 0.8087 - val_precision_m: 0.8901 - val_recall_m: 0.7433\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.4441 - acc: 0.8557 - f1_m: 0.8531 - precision_m: 0.8925 - recall_m: 0.8178 - val_loss: 0.5624 - val_acc: 0.7984 - val_f1_m: 0.7968 - val_precision_m: 0.8730 - val_recall_m: 0.7367\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.4581 - acc: 0.8413 - f1_m: 0.8498 - precision_m: 0.8935 - recall_m: 0.8108 - val_loss: 0.5735 - val_acc: 0.7903 - val_f1_m: 0.8063 - val_precision_m: 0.8753 - val_recall_m: 0.7500\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        if i==0:\n",
    "            r=70\n",
    "        elif i== 1:\n",
    "            r=80\n",
    "        elif i== 2:\n",
    "            r=90\n",
    "        elif i== 3:\n",
    "            r=100\n",
    "        elif i== 4:\n",
    "            r=130\n",
    "        elif i==6:\n",
    "            r=120\n",
    "        elif i==7:\n",
    "            r=50\n",
    "        elif i==8:\n",
    "            r=60\n",
    "        elif i==9:\n",
    "            r=30\n",
    "        elif i==5:\n",
    "            r=10\n",
    "        \n",
    "        X_t, X_val, y_t, y_val = train_test_split(X_train, y_train, test_size=0.10, stratify= y_train, shuffle=True, random_state=r)\n",
    "        h=model.fit(X_t, y_t, epochs=50, batch_size=50,  verbose=1,shuffle=True, validation_data=(X_val,y_val))\n",
    "\n",
    "        my_dict_Train[\"Accuracy_Train\"].append(round(100*np.mean(h.history['val_acc']),2))\n",
    "        my_dict_STD[\"Accuracy_Train\"].append(round(100*np.std(h.history['val_acc']), 2))\n",
    "        my_dict_Train[\"Precision_Train\"].append(round(100*np.mean(h.history['val_precision_m']),2))\n",
    "        my_dict_STD[\"Precision_Train\"].append(round(100*np.std(h.history['val_precision_m']), 2))\n",
    "        my_dict_Train[\"Recall_Train\"].append(round(100*np.mean(h.history['val_recall_m']),2))\n",
    "        my_dict_STD[\"Recall_Train\"].append(round(100*np.std(h.history['val_recall_m']), 2))\n",
    "        my_dict_Train[\"F1_score_Train\"].append(round(100*np.mean(h.history['val_f1_m']),2))\n",
    "        my_dict_STD[\"F1_score_Train\"].append(round(100*np.std(h.history['val_f1_m']), 2))\n",
    "        y_p = model.predict(X_test)\n",
    "        y_pred= np.argmax(y_p, axis=1)\n",
    "        my_dict_Test[\"Accuracy_Test\"].append(round(100*accuracy_score(y_test,y_pred), 2))\n",
    "        my_dict_Test[\"Precision_Test\"].append(round(100*precision_score(y_test, y_pred, average='weighted'), 2))\n",
    "        my_dict_Test[\"Recall_Test\"].append(round(100*recall_score(y_test, y_pred, average='weighted'), 2))\n",
    "        my_dict_Test[\"F1_score_Test\"].append(round(100*f1_score(y_test, y_pred, average='weighted') , 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Train: 82.617\n",
      "Accuracy_Train_STD: 2.647\n",
      "Precision_Train: 86.966\n",
      "Precision_Train_STD: 2.630\n",
      "Recall_Train: 78.179\n",
      "Recall_Train_STD: 2.721\n",
      "F1_score_Train: 82.273\n",
      "F1_score_Train_STD: 2.395\n"
     ]
    }
   ],
   "source": [
    "for metric in my_dict_Train.keys():\n",
    "    print(\"%s: %.3f\" % (metric, average(my_dict_Train[metric])))\n",
    "    print(\"%s: %.3f\" % (metric+\"_STD\", average(my_dict_STD[metric])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Test: 77.030\n",
      "Precision_Test: 76.884\n",
      "Recall_Test: 77.030\n",
      "F1_score_Test: 76.386\n"
     ]
    }
   ],
   "source": [
    "for metric in my_dict_Test.keys():\n",
    "    print(\"%s: %.3f\" % (metric, average(my_dict_Test[metric])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
