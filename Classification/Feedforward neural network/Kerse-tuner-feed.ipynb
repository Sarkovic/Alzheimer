{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import kerastuner as kt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score ,recall_score\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder() \n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import np_utils\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from numpy import average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1371"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"Full_LSTM_Classification.csv\")\n",
    "DX=pd.read_csv(\"DX_Four_Classes.csv\")\n",
    "df=df.sort_values(by='RID', ascending=True)\n",
    "DX=DX.sort_values(by='RID', ascending=True)\n",
    "groupby=df.groupby(\"RID\").count()\n",
    "len(groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"DX_test_four_classes.csv\")\n",
    "df1=pd.merge(df, test, on='RID', how='inner')\n",
    "for j in range(0,len(test)):\n",
    "    df=df[df.RID!=test['RID'][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.merge(DX, test, on='RID', how='inner')                        \n",
    "for j in range(0,len(test)):\n",
    "    DX=DX[DX.RID!=test['RID'][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by='RID', ascending=True)\n",
    "X_train1=df.drop(['RID','VISCODE2'],axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.sort_values(by='RID', ascending=True)\n",
    "X_test1=df1.drop(['RID','VISCODE2'],axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=len(X_train1.columns)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train1)\n",
    "scaler1 = MinMaxScaler(feature_range=(0, 1))\n",
    "X_test = scaler1.fit_transform(X_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train.reshape(len(DX), 4*num_features)\n",
    "DX=DX.sort_values(by='RID', ascending=True)\n",
    "train_label=DX.drop(['RID'],axis = 1 )\n",
    "X_test= X_test.reshape(len(y_test), 4*num_features)\n",
    "test_label1=y_test.sort_values(by='RID', ascending=True)\n",
    "test_label=test_label1.drop(['RID'],axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hager\\anaconda3\\envs\\hager\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_label)\n",
    "encoded_Y= encoder.transform(train_label)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "encoder1 = LabelEncoder()\n",
    "encoder1.fit(test_label)\n",
    "y_test = encoder.transform(test_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    num_units_min  =  100\n",
    "    num_units_max  =  800\n",
    "    num_units_step =  50\n",
    "\n",
    "    dropout_min  =  .2\n",
    "    dropout_max  =  0.9\n",
    "    dropout_step =  0.1\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=hp.Int('unit1',  min_value=num_units_min,\n",
    "                                                 max_value=num_units_max,\n",
    "                                                 step=num_units_step),\n",
    "                                                 activation='relu',\n",
    "                                                 input_dim=4* num_features, \n",
    "                                                kernel_initializer='random_normal', bias_initializer='zeros',\n",
    "                                                 kernel_regularizer=keras.regularizers.l2(hp.Choice('reg_rate',values=[0.01,0.02, 0.05, 0.1,.04,.03]))\n",
    "                          \n",
    "                                               ))\n",
    "    model.add(layers.Dropout(hp.Float('dropout_1',min_value=dropout_min,\n",
    "                                      max_value=dropout_max,\n",
    "                                      step=dropout_step) ) )\n",
    " \n",
    " \n",
    "   \n",
    "    for i in range(hp.Int('num_layers', 1, 4)):\n",
    "        model.add(layers.Dense(units=hp.Int('unitsdense_'+ str(i),\n",
    "                                            min_value=100,\n",
    "                                            max_value=800,\n",
    "                                            step=50),\n",
    "                                            activation='relu',\n",
    "                               kernel_initializer='random_normal', bias_initializer='zeros',\n",
    "                              kernel_regularizer=keras.regularizers.l2(hp.Choice('reg_rate1'+ str(i),values=[0.01,0.02, 0.05, 0.1,.04,.03]))))   \n",
    "        model.add(layers.Dropout(hp.Float('dropoutdense_'+ str(i), \n",
    "                                      min_value=dropout_min,\n",
    "                                      max_value=dropout_max,\n",
    "                                      step=dropout_step)))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[ 1e-4])),\n",
    "       loss='categorical_crossentropy', \n",
    "       metrics=['acc',f1_m,precision_m, recall_m])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1109"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t, X_val, y_t, y_val = train_test_split(\n",
    "     X_train, y_train, test_size=0.10, stratify= y_train, shuffle=True, random_state=None) \n",
    "len(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\feedffull4\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\feedffull4\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_acc',\n",
    "    max_trials=2,\n",
    "    project_name='feedffull4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x00000169DED1BE20> and <tensorflow.python.keras.layers.core.Dropout object at 0x00000169DED35FA0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x00000169DEEA9070> and <tensorflow.python.keras.layers.core.Dropout object at 0x00000169DECA5A00>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x00000169DEEA6940> and <tensorflow.python.keras.layers.core.Dropout object at 0x00000169DEEB9EB0>).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=30, verbose=1)\n",
    "callback_list = [ early_stopping ]\n",
    "h=tuner.search(X_t, y_t,\n",
    "             epochs=100,\n",
    "             batch_size=50, \n",
    "             callbacks=callback_list, validation_data=(X_val,y_val) )\n",
    "            \n",
    "model = tuner.get_best_models(num_models=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 500)               264500    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 600)               300600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 1604      \n",
      "=================================================================\n",
      "Total params: 807,104\n",
      "Trainable params: 807,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unit1': 500,\n",
       " 'reg_rate': 0.01,\n",
       " 'dropout_1': 0.30000000000000004,\n",
       " 'num_layers': 2,\n",
       " 'unitsdense_0': 600,\n",
       " 'reg_rate10': 0.05,\n",
       " 'dropoutdense_0': 0.7000000000000002,\n",
       " 'learning_rate': 0.0001,\n",
       " 'unitsdense_1': 400,\n",
       " 'reg_rate11': 0.01,\n",
       " 'dropoutdense_1': 0.8000000000000003,\n",
       " 'unitsdense_2': 700,\n",
       " 'reg_rate12': 0.05,\n",
       " 'dropoutdense_2': 0.30000000000000004}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "23/23 [==============================] - 5s 117ms/step - loss: 2.3011 - acc: 0.7969 - f1_m: 0.7880 - precision_m: 0.8433 - recall_m: 0.7401 - val_loss: 2.1879 - val_acc: 0.8306 - val_f1_m: 0.8360 - val_precision_m: 0.8801 - val_recall_m: 0.7972\n",
      "Epoch 2/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 2.2220 - acc: 0.8170 - f1_m: 0.8103 - precision_m: 0.8541 - recall_m: 0.7711 - val_loss: 2.1396 - val_acc: 0.8145 - val_f1_m: 0.8249 - val_precision_m: 0.8715 - val_recall_m: 0.7839\n",
      "Epoch 3/120\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 2.1969 - acc: 0.8156 - f1_m: 0.8032 - precision_m: 0.8503 - recall_m: 0.7620 - val_loss: 2.0989 - val_acc: 0.8306 - val_f1_m: 0.8360 - val_precision_m: 0.8801 - val_recall_m: 0.7972\n",
      "Epoch 4/120\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 2.1661 - acc: 0.7894 - f1_m: 0.7801 - precision_m: 0.8303 - recall_m: 0.7366 - val_loss: 2.0526 - val_acc: 0.8226 - val_f1_m: 0.8201 - val_precision_m: 0.8766 - val_recall_m: 0.7706\n",
      "Epoch 5/120\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 2.0970 - acc: 0.8083 - f1_m: 0.8002 - precision_m: 0.8455 - recall_m: 0.7605 - val_loss: 2.0156 - val_acc: 0.8145 - val_f1_m: 0.8221 - val_precision_m: 0.8648 - val_recall_m: 0.7839\n",
      "Epoch 6/120\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 2.0578 - acc: 0.7980 - f1_m: 0.8026 - precision_m: 0.8480 - recall_m: 0.7628 - val_loss: 1.9902 - val_acc: 0.8145 - val_f1_m: 0.8282 - val_precision_m: 0.8785 - val_recall_m: 0.7839\n",
      "Epoch 7/120\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 2.0264 - acc: 0.8139 - f1_m: 0.8146 - precision_m: 0.8842 - recall_m: 0.7566 - val_loss: 1.9284 - val_acc: 0.8145 - val_f1_m: 0.8129 - val_precision_m: 0.8453 - val_recall_m: 0.7839\n",
      "Epoch 8/120\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 1.9962 - acc: 0.8115 - f1_m: 0.8102 - precision_m: 0.8592 - recall_m: 0.7680 - val_loss: 1.9151 - val_acc: 0.7984 - val_f1_m: 0.8123 - val_precision_m: 0.8692 - val_recall_m: 0.7633\n",
      "Epoch 9/120\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 1.9133 - acc: 0.8355 - f1_m: 0.8308 - precision_m: 0.8790 - recall_m: 0.7885 - val_loss: 1.8657 - val_acc: 0.7984 - val_f1_m: 0.8153 - val_precision_m: 0.8574 - val_recall_m: 0.7772\n",
      "Epoch 10/120\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 1.9020 - acc: 0.8141 - f1_m: 0.8145 - precision_m: 0.8613 - recall_m: 0.7731 - val_loss: 1.8309 - val_acc: 0.8065 - val_f1_m: 0.8218 - val_precision_m: 0.8642 - val_recall_m: 0.7839\n",
      "Epoch 11/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 1.8536 - acc: 0.8178 - f1_m: 0.8135 - precision_m: 0.8478 - recall_m: 0.7824 - val_loss: 1.7939 - val_acc: 0.8065 - val_f1_m: 0.8122 - val_precision_m: 0.8509 - val_recall_m: 0.7772\n",
      "Epoch 12/120\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 1.8314 - acc: 0.8077 - f1_m: 0.8041 - precision_m: 0.8482 - recall_m: 0.7649 - val_loss: 1.7669 - val_acc: 0.7984 - val_f1_m: 0.8214 - val_precision_m: 0.8711 - val_recall_m: 0.7772\n",
      "Epoch 13/120\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 1.7939 - acc: 0.8343 - f1_m: 0.8246 - precision_m: 0.8650 - recall_m: 0.7885 - val_loss: 1.7451 - val_acc: 0.8145 - val_f1_m: 0.8150 - val_precision_m: 0.8757 - val_recall_m: 0.7633\n",
      "Epoch 14/120\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 1.7460 - acc: 0.8229 - f1_m: 0.8277 - precision_m: 0.8739 - recall_m: 0.7872 - val_loss: 1.7028 - val_acc: 0.7984 - val_f1_m: 0.8096 - val_precision_m: 0.8450 - val_recall_m: 0.7772\n",
      "Epoch 15/120\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 1.7310 - acc: 0.8215 - f1_m: 0.8292 - precision_m: 0.8696 - recall_m: 0.7933 - val_loss: 1.7127 - val_acc: 0.8065 - val_f1_m: 0.7699 - val_precision_m: 0.8294 - val_recall_m: 0.7217\n",
      "Epoch 16/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 1.7133 - acc: 0.8162 - f1_m: 0.8159 - precision_m: 0.8675 - recall_m: 0.7708 - val_loss: 1.6506 - val_acc: 0.8065 - val_f1_m: 0.8205 - val_precision_m: 0.8532 - val_recall_m: 0.7906\n",
      "Epoch 17/120\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 1.6558 - acc: 0.8370 - f1_m: 0.8324 - precision_m: 0.8742 - recall_m: 0.7951 - val_loss: 1.6725 - val_acc: 0.7984 - val_f1_m: 0.7754 - val_precision_m: 0.8415 - val_recall_m: 0.7217\n",
      "Epoch 18/120\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 1.6530 - acc: 0.8199 - f1_m: 0.8174 - precision_m: 0.8717 - recall_m: 0.7703 - val_loss: 1.5977 - val_acc: 0.8145 - val_f1_m: 0.8064 - val_precision_m: 0.8384 - val_recall_m: 0.7772\n",
      "Epoch 19/120\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 1.6225 - acc: 0.8152 - f1_m: 0.8163 - precision_m: 0.8541 - recall_m: 0.7826 - val_loss: 1.5779 - val_acc: 0.7984 - val_f1_m: 0.7973 - val_precision_m: 0.8261 - val_recall_m: 0.7706\n",
      "Epoch 20/120\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 1.5968 - acc: 0.8267 - f1_m: 0.8214 - precision_m: 0.8625 - recall_m: 0.7845 - val_loss: 1.5516 - val_acc: 0.8065 - val_f1_m: 0.8106 - val_precision_m: 0.8563 - val_recall_m: 0.7700\n",
      "Epoch 21/120\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 1.5841 - acc: 0.8104 - f1_m: 0.8061 - precision_m: 0.8447 - recall_m: 0.7715 - val_loss: 1.5372 - val_acc: 0.7984 - val_f1_m: 0.8051 - val_precision_m: 0.8614 - val_recall_m: 0.7567\n",
      "Epoch 22/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 1.5646 - acc: 0.8168 - f1_m: 0.8049 - precision_m: 0.8459 - recall_m: 0.7685 - val_loss: 1.5232 - val_acc: 0.8145 - val_f1_m: 0.8040 - val_precision_m: 0.8491 - val_recall_m: 0.7639\n",
      "Epoch 23/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 1.5589 - acc: 0.8099 - f1_m: 0.8067 - precision_m: 0.8511 - recall_m: 0.7676 - val_loss: 1.4810 - val_acc: 0.8145 - val_f1_m: 0.8135 - val_precision_m: 0.8460 - val_recall_m: 0.7839\n",
      "Epoch 24/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 1.5260 - acc: 0.8123 - f1_m: 0.7977 - precision_m: 0.8422 - recall_m: 0.7582 - val_loss: 1.4586 - val_acc: 0.8226 - val_f1_m: 0.8110 - val_precision_m: 0.8563 - val_recall_m: 0.7706\n",
      "Epoch 25/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 1.4671 - acc: 0.8329 - f1_m: 0.8258 - precision_m: 0.8644 - recall_m: 0.7910 - val_loss: 1.4522 - val_acc: 0.8145 - val_f1_m: 0.8103 - val_precision_m: 0.8752 - val_recall_m: 0.7561\n",
      "Epoch 26/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 1.4518 - acc: 0.8313 - f1_m: 0.8285 - precision_m: 0.8752 - recall_m: 0.7870 - val_loss: 1.4234 - val_acc: 0.7984 - val_f1_m: 0.8099 - val_precision_m: 0.8623 - val_recall_m: 0.7639\n",
      "Epoch 27/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 1.4172 - acc: 0.8415 - f1_m: 0.8360 - precision_m: 0.8763 - recall_m: 0.8003 - val_loss: 1.4047 - val_acc: 0.8226 - val_f1_m: 0.8150 - val_precision_m: 0.8577 - val_recall_m: 0.7767\n",
      "Epoch 28/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 1.3895 - acc: 0.8394 - f1_m: 0.8309 - precision_m: 0.8644 - recall_m: 0.8005 - val_loss: 1.3987 - val_acc: 0.7903 - val_f1_m: 0.7951 - val_precision_m: 0.8464 - val_recall_m: 0.7500\n",
      "Epoch 29/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.3807 - acc: 0.8342 - f1_m: 0.8322 - precision_m: 0.8812 - recall_m: 0.7890 - val_loss: 1.3663 - val_acc: 0.8145 - val_f1_m: 0.8040 - val_precision_m: 0.8491 - val_recall_m: 0.7639\n",
      "Epoch 30/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 1.3744 - acc: 0.8261 - f1_m: 0.8236 - precision_m: 0.8610 - recall_m: 0.7905 - val_loss: 1.3711 - val_acc: 0.7903 - val_f1_m: 0.7805 - val_precision_m: 0.8317 - val_recall_m: 0.7361\n",
      "Epoch 31/120\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 1.3547 - acc: 0.8228 - f1_m: 0.8313 - precision_m: 0.8805 - recall_m: 0.7885 - val_loss: 1.3295 - val_acc: 0.8065 - val_f1_m: 0.8113 - val_precision_m: 0.8567 - val_recall_m: 0.7706\n",
      "Epoch 32/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.3555 - acc: 0.8134 - f1_m: 0.8227 - precision_m: 0.8693 - recall_m: 0.7817 - val_loss: 1.3201 - val_acc: 0.7984 - val_f1_m: 0.8096 - val_precision_m: 0.8630 - val_recall_m: 0.7633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/120\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 1.3410 - acc: 0.8232 - f1_m: 0.8188 - precision_m: 0.8593 - recall_m: 0.7827 - val_loss: 1.3342 - val_acc: 0.7903 - val_f1_m: 0.7867 - val_precision_m: 0.8584 - val_recall_m: 0.7289\n",
      "Epoch 34/120\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.3392 - acc: 0.8061 - f1_m: 0.8105 - precision_m: 0.8599 - recall_m: 0.7671 - val_loss: 1.2820 - val_acc: 0.8065 - val_f1_m: 0.8025 - val_precision_m: 0.8376 - val_recall_m: 0.7706\n",
      "Epoch 35/120\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 1.3193 - acc: 0.8059 - f1_m: 0.8071 - precision_m: 0.8496 - recall_m: 0.7693 - val_loss: 1.2610 - val_acc: 0.8145 - val_f1_m: 0.8193 - val_precision_m: 0.8585 - val_recall_m: 0.7839\n",
      "Epoch 36/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.2748 - acc: 0.8268 - f1_m: 0.8333 - precision_m: 0.8823 - recall_m: 0.7901 - val_loss: 1.2750 - val_acc: 0.8065 - val_f1_m: 0.7903 - val_precision_m: 0.8454 - val_recall_m: 0.7428\n",
      "Epoch 37/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 1.2647 - acc: 0.8225 - f1_m: 0.8142 - precision_m: 0.8723 - recall_m: 0.7646 - val_loss: 1.2717 - val_acc: 0.8145 - val_f1_m: 0.7822 - val_precision_m: 0.8542 - val_recall_m: 0.7222\n",
      "Epoch 38/120\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 1.2422 - acc: 0.8334 - f1_m: 0.8339 - precision_m: 0.8735 - recall_m: 0.7981 - val_loss: 1.2231 - val_acc: 0.8065 - val_f1_m: 0.8091 - val_precision_m: 0.8446 - val_recall_m: 0.7772\n",
      "Epoch 39/120\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 1.2307 - acc: 0.8428 - f1_m: 0.8340 - precision_m: 0.8796 - recall_m: 0.7943 - val_loss: 1.2245 - val_acc: 0.7984 - val_f1_m: 0.8184 - val_precision_m: 0.8646 - val_recall_m: 0.7772\n",
      "Epoch 40/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 1.2455 - acc: 0.8188 - f1_m: 0.8094 - precision_m: 0.8505 - recall_m: 0.7730 - val_loss: 1.2105 - val_acc: 0.7984 - val_f1_m: 0.8019 - val_precision_m: 0.8731 - val_recall_m: 0.7428\n",
      "Epoch 41/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.2380 - acc: 0.8111 - f1_m: 0.8123 - precision_m: 0.8646 - recall_m: 0.7668 - val_loss: 1.1955 - val_acc: 0.7984 - val_f1_m: 0.8111 - val_precision_m: 0.8749 - val_recall_m: 0.7567\n",
      "Epoch 42/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 1.1811 - acc: 0.8280 - f1_m: 0.8362 - precision_m: 0.8808 - recall_m: 0.7965 - val_loss: 1.1783 - val_acc: 0.7823 - val_f1_m: 0.7979 - val_precision_m: 0.8433 - val_recall_m: 0.7572\n",
      "Epoch 43/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.2073 - acc: 0.8102 - f1_m: 0.8158 - precision_m: 0.8567 - recall_m: 0.7796 - val_loss: 1.1820 - val_acc: 0.7903 - val_f1_m: 0.8031 - val_precision_m: 0.8674 - val_recall_m: 0.7494\n",
      "Epoch 44/120\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 1.1603 - acc: 0.8319 - f1_m: 0.8308 - precision_m: 0.8659 - recall_m: 0.7989 - val_loss: 1.1528 - val_acc: 0.7984 - val_f1_m: 0.8171 - val_precision_m: 0.8700 - val_recall_m: 0.7706\n",
      "Epoch 45/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.1627 - acc: 0.8301 - f1_m: 0.8214 - precision_m: 0.8689 - recall_m: 0.7793 - val_loss: 1.1410 - val_acc: 0.8065 - val_f1_m: 0.8165 - val_precision_m: 0.8693 - val_recall_m: 0.7706\n",
      "Epoch 46/120\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 1.1456 - acc: 0.8103 - f1_m: 0.8220 - precision_m: 0.8676 - recall_m: 0.7818 - val_loss: 1.1299 - val_acc: 0.8065 - val_f1_m: 0.8083 - val_precision_m: 0.8501 - val_recall_m: 0.7706\n",
      "Epoch 47/120\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 1.1596 - acc: 0.8100 - f1_m: 0.7976 - precision_m: 0.8382 - recall_m: 0.7609 - val_loss: 1.1336 - val_acc: 0.7823 - val_f1_m: 0.7959 - val_precision_m: 0.8582 - val_recall_m: 0.7428\n",
      "Epoch 48/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 1.1181 - acc: 0.8298 - f1_m: 0.8289 - precision_m: 0.8811 - recall_m: 0.7838 - val_loss: 1.1175 - val_acc: 0.7742 - val_f1_m: 0.7943 - val_precision_m: 0.8353 - val_recall_m: 0.7572\n",
      "Epoch 49/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 1.0943 - acc: 0.8202 - f1_m: 0.8239 - precision_m: 0.8566 - recall_m: 0.7942 - val_loss: 1.1002 - val_acc: 0.7984 - val_f1_m: 0.7926 - val_precision_m: 0.8242 - val_recall_m: 0.7633\n",
      "Epoch 50/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.1004 - acc: 0.8218 - f1_m: 0.8189 - precision_m: 0.8632 - recall_m: 0.7800 - val_loss: 1.1261 - val_acc: 0.7903 - val_f1_m: 0.7781 - val_precision_m: 0.8366 - val_recall_m: 0.7289\n",
      "Epoch 51/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.1040 - acc: 0.8129 - f1_m: 0.8118 - precision_m: 0.8579 - recall_m: 0.7711 - val_loss: 1.0828 - val_acc: 0.8226 - val_f1_m: 0.8076 - val_precision_m: 0.8497 - val_recall_m: 0.7700\n",
      "Epoch 52/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 1.0518 - acc: 0.8345 - f1_m: 0.8441 - precision_m: 0.8846 - recall_m: 0.8077 - val_loss: 1.0695 - val_acc: 0.8145 - val_f1_m: 0.8004 - val_precision_m: 0.8419 - val_recall_m: 0.7633\n",
      "Epoch 53/120\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 1.0492 - acc: 0.8333 - f1_m: 0.8397 - precision_m: 0.8811 - recall_m: 0.8029 - val_loss: 1.0591 - val_acc: 0.8065 - val_f1_m: 0.8122 - val_precision_m: 0.8509 - val_recall_m: 0.7772\n",
      "Epoch 54/120\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 1.0681 - acc: 0.8278 - f1_m: 0.8313 - precision_m: 0.8632 - recall_m: 0.8023 - val_loss: 1.0540 - val_acc: 0.7903 - val_f1_m: 0.8096 - val_precision_m: 0.8450 - val_recall_m: 0.7772\n",
      "Epoch 55/120\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 1.0364 - acc: 0.8398 - f1_m: 0.8398 - precision_m: 0.8811 - recall_m: 0.8029 - val_loss: 1.0798 - val_acc: 0.7984 - val_f1_m: 0.7767 - val_precision_m: 0.8241 - val_recall_m: 0.7356\n",
      "Epoch 56/120\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 1.0473 - acc: 0.8379 - f1_m: 0.8353 - precision_m: 0.8662 - recall_m: 0.8076 - val_loss: 1.0393 - val_acc: 0.7984 - val_f1_m: 0.8054 - val_precision_m: 0.8438 - val_recall_m: 0.7706\n",
      "Epoch 57/120\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 1.0284 - acc: 0.8268 - f1_m: 0.8273 - precision_m: 0.8670 - recall_m: 0.7919 - val_loss: 1.0397 - val_acc: 0.7903 - val_f1_m: 0.7932 - val_precision_m: 0.8518 - val_recall_m: 0.7428\n",
      "Epoch 58/120\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 1.0553 - acc: 0.8187 - f1_m: 0.8209 - precision_m: 0.8607 - recall_m: 0.7853 - val_loss: 1.0337 - val_acc: 0.7984 - val_f1_m: 0.7900 - val_precision_m: 0.8448 - val_recall_m: 0.7428\n",
      "Epoch 59/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 1.0177 - acc: 0.8385 - f1_m: 0.8279 - precision_m: 0.8671 - recall_m: 0.7926 - val_loss: 1.0209 - val_acc: 0.8226 - val_f1_m: 0.8087 - val_precision_m: 0.8508 - val_recall_m: 0.7706\n",
      "Epoch 60/120\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 1.0149 - acc: 0.8471 - f1_m: 0.8367 - precision_m: 0.8734 - recall_m: 0.8035 - val_loss: 1.0190 - val_acc: 0.7903 - val_f1_m: 0.7943 - val_precision_m: 0.8196 - val_recall_m: 0.7706\n",
      "Epoch 61/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 1.0122 - acc: 0.8447 - f1_m: 0.8382 - precision_m: 0.8726 - recall_m: 0.8069 - val_loss: 1.0045 - val_acc: 0.7984 - val_f1_m: 0.8101 - val_precision_m: 0.8458 - val_recall_m: 0.7772\n",
      "Epoch 62/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.9776 - acc: 0.8463 - f1_m: 0.8476 - precision_m: 0.8850 - recall_m: 0.8140 - val_loss: 0.9991 - val_acc: 0.7742 - val_f1_m: 0.7962 - val_precision_m: 0.8314 - val_recall_m: 0.7639\n",
      "Epoch 63/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.9620 - acc: 0.8432 - f1_m: 0.8378 - precision_m: 0.8810 - recall_m: 0.7991 - val_loss: 0.9908 - val_acc: 0.7984 - val_f1_m: 0.8054 - val_precision_m: 0.8438 - val_recall_m: 0.7706\n",
      "Epoch 64/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.9562 - acc: 0.8372 - f1_m: 0.8327 - precision_m: 0.8730 - recall_m: 0.7966 - val_loss: 0.9787 - val_acc: 0.8065 - val_f1_m: 0.8106 - val_precision_m: 0.8563 - val_recall_m: 0.7700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.9834 - acc: 0.8310 - f1_m: 0.8325 - precision_m: 0.8737 - recall_m: 0.7957 - val_loss: 0.9812 - val_acc: 0.7823 - val_f1_m: 0.8009 - val_precision_m: 0.8422 - val_recall_m: 0.7639\n",
      "Epoch 66/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.9730 - acc: 0.8316 - f1_m: 0.8374 - precision_m: 0.8746 - recall_m: 0.8037 - val_loss: 0.9756 - val_acc: 0.7903 - val_f1_m: 0.8171 - val_precision_m: 0.8700 - val_recall_m: 0.7706\n",
      "Epoch 67/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.9500 - acc: 0.8291 - f1_m: 0.8295 - precision_m: 0.8724 - recall_m: 0.7911 - val_loss: 0.9597 - val_acc: 0.8065 - val_f1_m: 0.8193 - val_precision_m: 0.8585 - val_recall_m: 0.7839\n",
      "Epoch 68/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.9212 - acc: 0.8614 - f1_m: 0.8524 - precision_m: 0.8955 - recall_m: 0.8145 - val_loss: 0.9844 - val_acc: 0.7984 - val_f1_m: 0.7726 - val_precision_m: 0.8247 - val_recall_m: 0.7289\n",
      "Epoch 69/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.9574 - acc: 0.8319 - f1_m: 0.8333 - precision_m: 0.8722 - recall_m: 0.7988 - val_loss: 0.9508 - val_acc: 0.7823 - val_f1_m: 0.7983 - val_precision_m: 0.8362 - val_recall_m: 0.7639\n",
      "Epoch 70/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.9330 - acc: 0.8495 - f1_m: 0.8438 - precision_m: 0.8837 - recall_m: 0.8079 - val_loss: 0.9465 - val_acc: 0.7823 - val_f1_m: 0.7901 - val_precision_m: 0.8342 - val_recall_m: 0.7506\n",
      "Epoch 71/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.9351 - acc: 0.8316 - f1_m: 0.8283 - precision_m: 0.8648 - recall_m: 0.7954 - val_loss: 0.9422 - val_acc: 0.7984 - val_f1_m: 0.8004 - val_precision_m: 0.8419 - val_recall_m: 0.7633\n",
      "Epoch 72/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.9016 - acc: 0.8480 - f1_m: 0.8480 - precision_m: 0.8867 - recall_m: 0.8135 - val_loss: 0.9365 - val_acc: 0.7903 - val_f1_m: 0.7954 - val_precision_m: 0.8300 - val_recall_m: 0.7639\n",
      "Epoch 73/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.9275 - acc: 0.8294 - f1_m: 0.8327 - precision_m: 0.8786 - recall_m: 0.7920 - val_loss: 0.9331 - val_acc: 0.7903 - val_f1_m: 0.8137 - val_precision_m: 0.8628 - val_recall_m: 0.7706\n",
      "Epoch 74/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.9038 - acc: 0.8357 - f1_m: 0.8472 - precision_m: 0.8849 - recall_m: 0.8131 - val_loss: 0.9316 - val_acc: 0.7984 - val_f1_m: 0.7996 - val_precision_m: 0.8480 - val_recall_m: 0.7567\n",
      "Epoch 75/120\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.9124 - acc: 0.8405 - f1_m: 0.8386 - precision_m: 0.8847 - recall_m: 0.7985 - val_loss: 0.9240 - val_acc: 0.7903 - val_f1_m: 0.7954 - val_precision_m: 0.8300 - val_recall_m: 0.7639\n",
      "Epoch 76/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.8713 - acc: 0.8499 - f1_m: 0.8503 - precision_m: 0.8857 - recall_m: 0.8183 - val_loss: 0.9182 - val_acc: 0.7742 - val_f1_m: 0.7947 - val_precision_m: 0.8360 - val_recall_m: 0.7572\n",
      "Epoch 77/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.9153 - acc: 0.8371 - f1_m: 0.8362 - precision_m: 0.8855 - recall_m: 0.7930 - val_loss: 0.9058 - val_acc: 0.8065 - val_f1_m: 0.8135 - val_precision_m: 0.8460 - val_recall_m: 0.7839\n",
      "Epoch 78/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.8617 - acc: 0.8475 - f1_m: 0.8463 - precision_m: 0.8845 - recall_m: 0.8119 - val_loss: 0.9317 - val_acc: 0.7903 - val_f1_m: 0.7752 - val_precision_m: 0.8306 - val_recall_m: 0.7289\n",
      "Epoch 79/120\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.8928 - acc: 0.8300 - f1_m: 0.8309 - precision_m: 0.8724 - recall_m: 0.7937 - val_loss: 0.9130 - val_acc: 0.7984 - val_f1_m: 0.8077 - val_precision_m: 0.8493 - val_recall_m: 0.7706\n",
      "Epoch 80/120\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.9029 - acc: 0.8223 - f1_m: 0.8255 - precision_m: 0.8619 - recall_m: 0.7929 - val_loss: 0.9225 - val_acc: 0.7903 - val_f1_m: 0.7905 - val_precision_m: 0.8456 - val_recall_m: 0.7428\n",
      "Epoch 81/120\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.8883 - acc: 0.8280 - f1_m: 0.8285 - precision_m: 0.8682 - recall_m: 0.7928 - val_loss: 0.8916 - val_acc: 0.7984 - val_f1_m: 0.8022 - val_precision_m: 0.8373 - val_recall_m: 0.7700\n",
      "Epoch 82/120\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.8819 - acc: 0.8435 - f1_m: 0.8331 - precision_m: 0.8743 - recall_m: 0.7967 - val_loss: 0.9009 - val_acc: 0.7903 - val_f1_m: 0.7925 - val_precision_m: 0.8404 - val_recall_m: 0.7500\n",
      "Epoch 83/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.8300 - acc: 0.8664 - f1_m: 0.8650 - precision_m: 0.9127 - recall_m: 0.8226 - val_loss: 0.8958 - val_acc: 0.7903 - val_f1_m: 0.7945 - val_precision_m: 0.8464 - val_recall_m: 0.7494\n",
      "Epoch 84/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.8271 - acc: 0.8538 - f1_m: 0.8587 - precision_m: 0.8942 - recall_m: 0.8265 - val_loss: 0.9191 - val_acc: 0.7984 - val_f1_m: 0.7967 - val_precision_m: 0.8416 - val_recall_m: 0.7567\n",
      "Epoch 85/120\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.8667 - acc: 0.8298 - f1_m: 0.8346 - precision_m: 0.8769 - recall_m: 0.7966 - val_loss: 0.8823 - val_acc: 0.7823 - val_f1_m: 0.7924 - val_precision_m: 0.8237 - val_recall_m: 0.7639\n",
      "Epoch 86/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.8565 - acc: 0.8337 - f1_m: 0.8360 - precision_m: 0.8793 - recall_m: 0.7974 - val_loss: 0.8693 - val_acc: 0.8065 - val_f1_m: 0.8193 - val_precision_m: 0.8585 - val_recall_m: 0.7839\n",
      "Epoch 87/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.8644 - acc: 0.8321 - f1_m: 0.8267 - precision_m: 0.8677 - recall_m: 0.7901 - val_loss: 0.8678 - val_acc: 0.8145 - val_f1_m: 0.8149 - val_precision_m: 0.8571 - val_recall_m: 0.7772\n",
      "Epoch 88/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.8280 - acc: 0.8472 - f1_m: 0.8420 - precision_m: 0.8917 - recall_m: 0.7990 - val_loss: 0.8980 - val_acc: 0.7903 - val_f1_m: 0.7779 - val_precision_m: 0.8367 - val_recall_m: 0.7289\n",
      "Epoch 89/120\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.8287 - acc: 0.8422 - f1_m: 0.8489 - precision_m: 0.8875 - recall_m: 0.8137 - val_loss: 0.8826 - val_acc: 0.7984 - val_f1_m: 0.8122 - val_precision_m: 0.8509 - val_recall_m: 0.7772\n",
      "Epoch 90/120\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.8283 - acc: 0.8391 - f1_m: 0.8384 - precision_m: 0.8737 - recall_m: 0.8065 - val_loss: 0.8550 - val_acc: 0.8145 - val_f1_m: 0.8091 - val_precision_m: 0.8446 - val_recall_m: 0.7772\n",
      "Epoch 91/120\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.8310 - acc: 0.8348 - f1_m: 0.8382 - precision_m: 0.8810 - recall_m: 0.7999 - val_loss: 0.8535 - val_acc: 0.8065 - val_f1_m: 0.8042 - val_precision_m: 0.8333 - val_recall_m: 0.7772\n",
      "Epoch 92/120\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.8082 - acc: 0.8502 - f1_m: 0.8430 - precision_m: 0.8760 - recall_m: 0.8136 - val_loss: 0.8559 - val_acc: 0.7903 - val_f1_m: 0.7970 - val_precision_m: 0.8421 - val_recall_m: 0.7567\n",
      "Epoch 93/120\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.8205 - acc: 0.8438 - f1_m: 0.8381 - precision_m: 0.8702 - recall_m: 0.8094 - val_loss: 0.8528 - val_acc: 0.7903 - val_f1_m: 0.7996 - val_precision_m: 0.8480 - val_recall_m: 0.7567\n",
      "Epoch 94/120\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.8281 - acc: 0.8253 - f1_m: 0.8257 - precision_m: 0.8712 - recall_m: 0.7856 - val_loss: 0.8521 - val_acc: 0.7903 - val_f1_m: 0.7937 - val_precision_m: 0.8345 - val_recall_m: 0.7572\n",
      "Epoch 95/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.8282 - acc: 0.8383 - f1_m: 0.8375 - precision_m: 0.8746 - recall_m: 0.8040 - val_loss: 0.8458 - val_acc: 0.7903 - val_f1_m: 0.7947 - val_precision_m: 0.8652 - val_recall_m: 0.7361\n",
      "Epoch 96/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 23ms/step - loss: 0.8153 - acc: 0.8399 - f1_m: 0.8400 - precision_m: 0.8846 - recall_m: 0.8003 - val_loss: 0.8401 - val_acc: 0.7903 - val_f1_m: 0.7970 - val_precision_m: 0.8421 - val_recall_m: 0.7567\n",
      "Epoch 97/120\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.8094 - acc: 0.8487 - f1_m: 0.8539 - precision_m: 0.8893 - recall_m: 0.8219 - val_loss: 0.8392 - val_acc: 0.7903 - val_f1_m: 0.7996 - val_precision_m: 0.8480 - val_recall_m: 0.7567\n",
      "Epoch 98/120\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.8364 - acc: 0.8265 - f1_m: 0.8261 - precision_m: 0.8738 - recall_m: 0.7839 - val_loss: 0.8299 - val_acc: 0.7823 - val_f1_m: 0.8052 - val_precision_m: 0.8433 - val_recall_m: 0.7706\n",
      "Epoch 99/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.8278 - acc: 0.8261 - f1_m: 0.8313 - precision_m: 0.8638 - recall_m: 0.8016 - val_loss: 0.8501 - val_acc: 0.7903 - val_f1_m: 0.7793 - val_precision_m: 0.8297 - val_recall_m: 0.7356\n",
      "Epoch 100/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.8242 - acc: 0.8176 - f1_m: 0.8274 - precision_m: 0.8686 - recall_m: 0.7904 - val_loss: 0.8308 - val_acc: 0.7823 - val_f1_m: 0.7996 - val_precision_m: 0.8480 - val_recall_m: 0.7567\n",
      "Epoch 101/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.8176 - acc: 0.8197 - f1_m: 0.8264 - precision_m: 0.8691 - recall_m: 0.7880 - val_loss: 0.8200 - val_acc: 0.7984 - val_f1_m: 0.8122 - val_precision_m: 0.8509 - val_recall_m: 0.7772\n",
      "Epoch 102/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.8229 - acc: 0.8262 - f1_m: 0.8259 - precision_m: 0.8669 - recall_m: 0.7906 - val_loss: 0.8185 - val_acc: 0.7984 - val_f1_m: 0.8122 - val_precision_m: 0.8509 - val_recall_m: 0.7772\n",
      "Epoch 103/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7757 - acc: 0.8514 - f1_m: 0.8515 - precision_m: 0.8863 - recall_m: 0.8197 - val_loss: 0.8313 - val_acc: 0.7903 - val_f1_m: 0.7844 - val_precision_m: 0.8326 - val_recall_m: 0.7428\n",
      "Epoch 104/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7906 - acc: 0.8314 - f1_m: 0.8308 - precision_m: 0.8774 - recall_m: 0.7896 - val_loss: 0.8264 - val_acc: 0.7903 - val_f1_m: 0.7983 - val_precision_m: 0.8362 - val_recall_m: 0.7639\n",
      "Epoch 105/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7846 - acc: 0.8395 - f1_m: 0.8446 - precision_m: 0.8875 - recall_m: 0.8062 - val_loss: 0.8331 - val_acc: 0.7823 - val_f1_m: 0.7839 - val_precision_m: 0.8313 - val_recall_m: 0.7428\n",
      "Epoch 106/120\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.7837 - acc: 0.8441 - f1_m: 0.8432 - precision_m: 0.8866 - recall_m: 0.8047 - val_loss: 0.8108 - val_acc: 0.8065 - val_f1_m: 0.8149 - val_precision_m: 0.8571 - val_recall_m: 0.7772\n",
      "Epoch 107/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.7689 - acc: 0.8458 - f1_m: 0.8539 - precision_m: 0.8953 - recall_m: 0.8169 - val_loss: 0.8179 - val_acc: 0.7903 - val_f1_m: 0.8054 - val_precision_m: 0.8438 - val_recall_m: 0.7706\n",
      "Epoch 108/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.7710 - acc: 0.8475 - f1_m: 0.8433 - precision_m: 0.8735 - recall_m: 0.8160 - val_loss: 0.8089 - val_acc: 0.7823 - val_f1_m: 0.7983 - val_precision_m: 0.8362 - val_recall_m: 0.7639\n",
      "Epoch 109/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7638 - acc: 0.8341 - f1_m: 0.8464 - precision_m: 0.8928 - recall_m: 0.8053 - val_loss: 0.8217 - val_acc: 0.7661 - val_f1_m: 0.7941 - val_precision_m: 0.8350 - val_recall_m: 0.7572\n",
      "Epoch 110/120\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.7721 - acc: 0.8461 - f1_m: 0.8469 - precision_m: 0.8902 - recall_m: 0.8086 - val_loss: 0.8206 - val_acc: 0.7903 - val_f1_m: 0.8023 - val_precision_m: 0.8541 - val_recall_m: 0.7567\n",
      "Epoch 111/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7787 - acc: 0.8390 - f1_m: 0.8312 - precision_m: 0.8735 - recall_m: 0.7934 - val_loss: 0.7979 - val_acc: 0.8065 - val_f1_m: 0.8193 - val_precision_m: 0.8585 - val_recall_m: 0.7839\n",
      "Epoch 112/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7820 - acc: 0.8317 - f1_m: 0.8386 - precision_m: 0.8845 - recall_m: 0.7981 - val_loss: 0.7967 - val_acc: 0.7984 - val_f1_m: 0.8113 - val_precision_m: 0.8570 - val_recall_m: 0.7706\n",
      "Epoch 113/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7639 - acc: 0.8399 - f1_m: 0.8414 - precision_m: 0.8834 - recall_m: 0.8037 - val_loss: 0.8027 - val_acc: 0.7903 - val_f1_m: 0.7983 - val_precision_m: 0.8362 - val_recall_m: 0.7639\n",
      "Epoch 114/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7647 - acc: 0.8486 - f1_m: 0.8474 - precision_m: 0.8849 - recall_m: 0.8136 - val_loss: 0.7935 - val_acc: 0.7984 - val_f1_m: 0.8149 - val_precision_m: 0.8571 - val_recall_m: 0.7772\n",
      "Epoch 115/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7562 - acc: 0.8374 - f1_m: 0.8418 - precision_m: 0.8845 - recall_m: 0.8041 - val_loss: 0.8084 - val_acc: 0.7823 - val_f1_m: 0.8077 - val_precision_m: 0.8493 - val_recall_m: 0.7706\n",
      "Epoch 116/120\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.7588 - acc: 0.8304 - f1_m: 0.8415 - precision_m: 0.8722 - recall_m: 0.8133 - val_loss: 0.7942 - val_acc: 0.7823 - val_f1_m: 0.7919 - val_precision_m: 0.8394 - val_recall_m: 0.7500\n",
      "Epoch 117/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.7382 - acc: 0.8435 - f1_m: 0.8542 - precision_m: 0.8932 - recall_m: 0.8188 - val_loss: 0.7892 - val_acc: 0.7823 - val_f1_m: 0.8006 - val_precision_m: 0.8416 - val_recall_m: 0.7639\n",
      "Epoch 118/120\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.7658 - acc: 0.8454 - f1_m: 0.8529 - precision_m: 0.8922 - recall_m: 0.8178 - val_loss: 0.7842 - val_acc: 0.7903 - val_f1_m: 0.8077 - val_precision_m: 0.8493 - val_recall_m: 0.7706\n",
      "Epoch 119/120\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.7553 - acc: 0.8398 - f1_m: 0.8420 - precision_m: 0.8843 - recall_m: 0.8040 - val_loss: 0.7872 - val_acc: 0.7903 - val_f1_m: 0.7956 - val_precision_m: 0.8302 - val_recall_m: 0.7639\n",
      "Epoch 120/120\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7218 - acc: 0.8498 - f1_m: 0.8562 - precision_m: 0.8908 - recall_m: 0.8245 - val_loss: 0.7946 - val_acc: 0.7903 - val_f1_m: 0.7886 - val_precision_m: 0.8235 - val_recall_m: 0.7567\n"
     ]
    }
   ],
   "source": [
    "#model.reset_states()\n",
    "history= model.fit(X_t, y_t, epochs=120, batch_size=50,  verbose=1,shuffle=True, validation_data=(X_val,y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m', 'val_loss', 'val_acc', 'val_f1_m', 'val_precision_m', 'val_recall_m'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict_Train={\"Accuracy_Train\": [],\"Precision_Train\": [],\"Recall_Train\": [], \"F1_score_Train\":[]};\n",
    "my_dict_STD={\"Accuracy_Train\": [],\"Precision_Train\": [],\"Recall_Train\": [], \"F1_score_Train\":[]};\n",
    "my_dict_Test={\"Accuracy_Test\": [],\"Precision_Test\": [],\"Recall_Test\": [], \"F1_score_Test\":[]};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.7770 - acc: 0.8188 - f1_m: 0.8248 - precision_m: 0.8641 - recall_m: 0.7900 - val_loss: 0.6706 - val_acc: 0.8790 - val_f1_m: 0.8720 - val_precision_m: 0.8933 - val_recall_m: 0.8522\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.7639 - acc: 0.8305 - f1_m: 0.8203 - precision_m: 0.8682 - recall_m: 0.7793 - val_loss: 0.6589 - val_acc: 0.8871 - val_f1_m: 0.8819 - val_precision_m: 0.9070 - val_recall_m: 0.8589\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.7470 - acc: 0.8431 - f1_m: 0.8469 - precision_m: 0.8921 - recall_m: 0.8069 - val_loss: 0.6629 - val_acc: 0.8790 - val_f1_m: 0.8749 - val_precision_m: 0.8997 - val_recall_m: 0.8522\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.7631 - acc: 0.8305 - f1_m: 0.8329 - precision_m: 0.8750 - recall_m: 0.7952 - val_loss: 0.6682 - val_acc: 0.8710 - val_f1_m: 0.8750 - val_precision_m: 0.8998 - val_recall_m: 0.8522\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.7357 - acc: 0.8350 - f1_m: 0.8416 - precision_m: 0.8772 - recall_m: 0.8091 - val_loss: 0.6589 - val_acc: 0.8629 - val_f1_m: 0.8770 - val_precision_m: 0.9125 - val_recall_m: 0.8456\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.7602 - acc: 0.8314 - f1_m: 0.8339 - precision_m: 0.8680 - recall_m: 0.8030 - val_loss: 0.6575 - val_acc: 0.8710 - val_f1_m: 0.8720 - val_precision_m: 0.8933 - val_recall_m: 0.8522\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.7552 - acc: 0.8296 - f1_m: 0.8417 - precision_m: 0.8809 - recall_m: 0.8070 - val_loss: 0.6615 - val_acc: 0.8790 - val_f1_m: 0.8789 - val_precision_m: 0.9005 - val_recall_m: 0.8589\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.7459 - acc: 0.8350 - f1_m: 0.8301 - precision_m: 0.8700 - recall_m: 0.7942 - val_loss: 0.6626 - val_acc: 0.8710 - val_f1_m: 0.8720 - val_precision_m: 0.8933 - val_recall_m: 0.8522\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.7391 - acc: 0.8386 - f1_m: 0.8419 - precision_m: 0.8821 - recall_m: 0.8065 - val_loss: 0.6957 - val_acc: 0.8306 - val_f1_m: 0.8572 - val_precision_m: 0.9091 - val_recall_m: 0.8111\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.7660 - acc: 0.8260 - f1_m: 0.8226 - precision_m: 0.8700 - recall_m: 0.7816 - val_loss: 0.6654 - val_acc: 0.8790 - val_f1_m: 0.8809 - val_precision_m: 0.8899 - val_recall_m: 0.8722\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.7604 - acc: 0.8314 - f1_m: 0.8296 - precision_m: 0.8674 - recall_m: 0.7956 - val_loss: 0.6507 - val_acc: 0.8790 - val_f1_m: 0.8789 - val_precision_m: 0.9005 - val_recall_m: 0.8589\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.7310 - acc: 0.8485 - f1_m: 0.8508 - precision_m: 0.8882 - recall_m: 0.8174 - val_loss: 0.6482 - val_acc: 0.8790 - val_f1_m: 0.8819 - val_precision_m: 0.9070 - val_recall_m: 0.8589\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.7239 - acc: 0.8404 - f1_m: 0.8485 - precision_m: 0.8857 - recall_m: 0.8152 - val_loss: 0.6535 - val_acc: 0.8710 - val_f1_m: 0.8720 - val_precision_m: 0.8933 - val_recall_m: 0.8522\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.7237 - acc: 0.8404 - f1_m: 0.8369 - precision_m: 0.8728 - recall_m: 0.8046 - val_loss: 0.6511 - val_acc: 0.8468 - val_f1_m: 0.8841 - val_precision_m: 0.9199 - val_recall_m: 0.8522\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.7319 - acc: 0.8386 - f1_m: 0.8416 - precision_m: 0.8809 - recall_m: 0.8069 - val_loss: 0.6460 - val_acc: 0.8790 - val_f1_m: 0.8749 - val_precision_m: 0.8997 - val_recall_m: 0.8522\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.7527 - acc: 0.8215 - f1_m: 0.8302 - precision_m: 0.8718 - recall_m: 0.7934 - val_loss: 0.6629 - val_acc: 0.8710 - val_f1_m: 0.8760 - val_precision_m: 0.8942 - val_recall_m: 0.8589\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.7190 - acc: 0.8431 - f1_m: 0.8451 - precision_m: 0.8836 - recall_m: 0.8107 - val_loss: 0.6422 - val_acc: 0.8790 - val_f1_m: 0.8819 - val_precision_m: 0.9070 - val_recall_m: 0.8589\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.7195 - acc: 0.8377 - f1_m: 0.8438 - precision_m: 0.8820 - recall_m: 0.8095 - val_loss: 0.6473 - val_acc: 0.8710 - val_f1_m: 0.8720 - val_precision_m: 0.8933 - val_recall_m: 0.8522\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.7495 - acc: 0.8242 - f1_m: 0.8186 - precision_m: 0.8508 - recall_m: 0.7895 - val_loss: 0.6521 - val_acc: 0.8952 - val_f1_m: 0.8849 - val_precision_m: 0.9134 - val_recall_m: 0.8589\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7330 - acc: 0.8314 - f1_m: 0.8349 - precision_m: 0.8763 - recall_m: 0.7982 - val_loss: 0.6429 - val_acc: 0.8790 - val_f1_m: 0.8749 - val_precision_m: 0.8997 - val_recall_m: 0.8522\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.7166 - acc: 0.8377 - f1_m: 0.8453 - precision_m: 0.8828 - recall_m: 0.8113 - val_loss: 0.6487 - val_acc: 0.8710 - val_f1_m: 0.8720 - val_precision_m: 0.8933 - val_recall_m: 0.8522\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.7169 - acc: 0.8278 - f1_m: 0.8279 - precision_m: 0.8669 - recall_m: 0.7933 - val_loss: 0.6555 - val_acc: 0.8710 - val_f1_m: 0.8720 - val_precision_m: 0.8933 - val_recall_m: 0.8522\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6970 - acc: 0.8440 - f1_m: 0.8490 - precision_m: 0.8857 - recall_m: 0.8160 - val_loss: 0.6344 - val_acc: 0.8629 - val_f1_m: 0.8779 - val_precision_m: 0.9062 - val_recall_m: 0.8522\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.7108 - acc: 0.8503 - f1_m: 0.8422 - precision_m: 0.8852 - recall_m: 0.8043 - val_loss: 0.6537 - val_acc: 0.8387 - val_f1_m: 0.8800 - val_precision_m: 0.9192 - val_recall_m: 0.8456\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.7333 - acc: 0.8359 - f1_m: 0.8313 - precision_m: 0.8732 - recall_m: 0.7938 - val_loss: 0.6831 - val_acc: 0.8710 - val_f1_m: 0.8641 - val_precision_m: 0.8918 - val_recall_m: 0.8383\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7224 - acc: 0.8296 - f1_m: 0.8356 - precision_m: 0.8737 - recall_m: 0.8013 - val_loss: 0.6368 - val_acc: 0.8790 - val_f1_m: 0.8789 - val_precision_m: 0.9005 - val_recall_m: 0.8589\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.7203 - acc: 0.8350 - f1_m: 0.8402 - precision_m: 0.8847 - recall_m: 0.8009 - val_loss: 0.6488 - val_acc: 0.8548 - val_f1_m: 0.8755 - val_precision_m: 0.9252 - val_recall_m: 0.8317\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.7090 - acc: 0.8332 - f1_m: 0.8404 - precision_m: 0.8809 - recall_m: 0.8039 - val_loss: 0.6551 - val_acc: 0.8387 - val_f1_m: 0.8544 - val_precision_m: 0.8794 - val_recall_m: 0.8317\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.7100 - acc: 0.8350 - f1_m: 0.8342 - precision_m: 0.8712 - recall_m: 0.8008 - val_loss: 0.6369 - val_acc: 0.8790 - val_f1_m: 0.8789 - val_precision_m: 0.9005 - val_recall_m: 0.8589\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6902 - acc: 0.8512 - f1_m: 0.8519 - precision_m: 0.8969 - recall_m: 0.8117 - val_loss: 0.6273 - val_acc: 0.8710 - val_f1_m: 0.8819 - val_precision_m: 0.9070 - val_recall_m: 0.8589\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6909 - acc: 0.8422 - f1_m: 0.8334 - precision_m: 0.8685 - recall_m: 0.8016 - val_loss: 0.6312 - val_acc: 0.8790 - val_f1_m: 0.8789 - val_precision_m: 0.9005 - val_recall_m: 0.8589\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6980 - acc: 0.8440 - f1_m: 0.8385 - precision_m: 0.8862 - recall_m: 0.7964 - val_loss: 0.6280 - val_acc: 0.8710 - val_f1_m: 0.8790 - val_precision_m: 0.9007 - val_recall_m: 0.8589\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 22ms/step - loss: 0.7024 - acc: 0.8323 - f1_m: 0.8328 - precision_m: 0.8729 - recall_m: 0.7964 - val_loss: 0.6292 - val_acc: 0.8710 - val_f1_m: 0.8720 - val_precision_m: 0.8933 - val_recall_m: 0.8522\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6862 - acc: 0.8440 - f1_m: 0.8462 - precision_m: 0.8838 - recall_m: 0.8121 - val_loss: 0.6244 - val_acc: 0.8710 - val_f1_m: 0.8720 - val_precision_m: 0.8933 - val_recall_m: 0.8522\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6867 - acc: 0.8521 - f1_m: 0.8382 - precision_m: 0.8852 - recall_m: 0.7981 - val_loss: 0.6462 - val_acc: 0.8710 - val_f1_m: 0.8759 - val_precision_m: 0.8940 - val_recall_m: 0.8589\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.7064 - acc: 0.8413 - f1_m: 0.8431 - precision_m: 0.8867 - recall_m: 0.8043 - val_loss: 0.6315 - val_acc: 0.8710 - val_f1_m: 0.8770 - val_precision_m: 0.8889 - val_recall_m: 0.8656\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6885 - acc: 0.8431 - f1_m: 0.8404 - precision_m: 0.8792 - recall_m: 0.8055 - val_loss: 0.6239 - val_acc: 0.8790 - val_f1_m: 0.8789 - val_precision_m: 0.9005 - val_recall_m: 0.8589\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6897 - acc: 0.8467 - f1_m: 0.8365 - precision_m: 0.8778 - recall_m: 0.7993 - val_loss: 0.6351 - val_acc: 0.8548 - val_f1_m: 0.8911 - val_precision_m: 0.9274 - val_recall_m: 0.8589\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.7015 - acc: 0.8296 - f1_m: 0.8273 - precision_m: 0.8741 - recall_m: 0.7860 - val_loss: 0.6458 - val_acc: 0.8710 - val_f1_m: 0.8770 - val_precision_m: 0.8889 - val_recall_m: 0.8656\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6995 - acc: 0.8350 - f1_m: 0.8376 - precision_m: 0.8815 - recall_m: 0.7986 - val_loss: 0.6173 - val_acc: 0.8871 - val_f1_m: 0.8789 - val_precision_m: 0.9005 - val_recall_m: 0.8589\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6854 - acc: 0.8485 - f1_m: 0.8499 - precision_m: 0.8912 - recall_m: 0.8134 - val_loss: 0.6153 - val_acc: 0.8790 - val_f1_m: 0.8749 - val_precision_m: 0.8997 - val_recall_m: 0.8522\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6743 - acc: 0.8413 - f1_m: 0.8492 - precision_m: 0.8900 - recall_m: 0.8126 - val_loss: 0.6149 - val_acc: 0.8790 - val_f1_m: 0.8789 - val_precision_m: 0.9005 - val_recall_m: 0.8589\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6732 - acc: 0.8449 - f1_m: 0.8476 - precision_m: 0.8846 - recall_m: 0.8152 - val_loss: 0.6152 - val_acc: 0.8710 - val_f1_m: 0.8749 - val_precision_m: 0.8997 - val_recall_m: 0.8522\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6749 - acc: 0.8467 - f1_m: 0.8442 - precision_m: 0.8811 - recall_m: 0.8108 - val_loss: 0.6169 - val_acc: 0.8710 - val_f1_m: 0.8790 - val_precision_m: 0.9007 - val_recall_m: 0.8589\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6657 - acc: 0.8521 - f1_m: 0.8587 - precision_m: 0.8924 - recall_m: 0.8278 - val_loss: 0.6109 - val_acc: 0.8790 - val_f1_m: 0.8789 - val_precision_m: 0.9005 - val_recall_m: 0.8589\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6741 - acc: 0.8422 - f1_m: 0.8545 - precision_m: 0.8980 - recall_m: 0.8160 - val_loss: 0.6198 - val_acc: 0.8790 - val_f1_m: 0.8860 - val_precision_m: 0.9079 - val_recall_m: 0.8656\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6676 - acc: 0.8431 - f1_m: 0.8465 - precision_m: 0.8898 - recall_m: 0.8087 - val_loss: 0.6132 - val_acc: 0.8548 - val_f1_m: 0.8750 - val_precision_m: 0.8998 - val_recall_m: 0.8522\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6768 - acc: 0.8395 - f1_m: 0.8455 - precision_m: 0.8815 - recall_m: 0.8130 - val_loss: 0.6138 - val_acc: 0.8629 - val_f1_m: 0.8790 - val_precision_m: 0.9007 - val_recall_m: 0.8589\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6779 - acc: 0.8341 - f1_m: 0.8386 - precision_m: 0.8730 - recall_m: 0.8073 - val_loss: 0.6469 - val_acc: 0.8387 - val_f1_m: 0.8514 - val_precision_m: 0.8728 - val_recall_m: 0.8317\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6983 - acc: 0.8296 - f1_m: 0.8269 - precision_m: 0.8657 - recall_m: 0.7921 - val_loss: 0.6162 - val_acc: 0.8790 - val_f1_m: 0.8749 - val_precision_m: 0.8997 - val_recall_m: 0.8522\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 35ms/step - loss: 0.6869 - acc: 0.8395 - f1_m: 0.8379 - precision_m: 0.8725 - recall_m: 0.8065 - val_loss: 0.6218 - val_acc: 0.8710 - val_f1_m: 0.8707 - val_precision_m: 0.8924 - val_recall_m: 0.8506\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.6861 - acc: 0.8395 - f1_m: 0.8303 - precision_m: 0.8739 - recall_m: 0.7916 - val_loss: 0.5954 - val_acc: 0.8952 - val_f1_m: 0.8642 - val_precision_m: 0.8858 - val_recall_m: 0.8439\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.6750 - acc: 0.8422 - f1_m: 0.8457 - precision_m: 0.8826 - recall_m: 0.8126 - val_loss: 0.6224 - val_acc: 0.8548 - val_f1_m: 0.8490 - val_precision_m: 0.8836 - val_recall_m: 0.8172\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6563 - acc: 0.8494 - f1_m: 0.8431 - precision_m: 0.8870 - recall_m: 0.8038 - val_loss: 0.6129 - val_acc: 0.8710 - val_f1_m: 0.8490 - val_precision_m: 0.8836 - val_recall_m: 0.8172\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6677 - acc: 0.8458 - f1_m: 0.8568 - precision_m: 0.8926 - recall_m: 0.8243 - val_loss: 0.6220 - val_acc: 0.8710 - val_f1_m: 0.8539 - val_precision_m: 0.8719 - val_recall_m: 0.8372\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6753 - acc: 0.8431 - f1_m: 0.8363 - precision_m: 0.8762 - recall_m: 0.8003 - val_loss: 0.5972 - val_acc: 0.8871 - val_f1_m: 0.8673 - val_precision_m: 0.8922 - val_recall_m: 0.8439\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.7192 - acc: 0.8115 - f1_m: 0.8202 - precision_m: 0.8576 - recall_m: 0.7870 - val_loss: 0.6292 - val_acc: 0.8790 - val_f1_m: 0.8460 - val_precision_m: 0.8773 - val_recall_m: 0.8172\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6898 - acc: 0.8278 - f1_m: 0.8288 - precision_m: 0.8636 - recall_m: 0.7973 - val_loss: 0.6159 - val_acc: 0.8790 - val_f1_m: 0.8651 - val_precision_m: 0.8801 - val_recall_m: 0.8506\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6631 - acc: 0.8458 - f1_m: 0.8454 - precision_m: 0.8790 - recall_m: 0.8147 - val_loss: 0.6243 - val_acc: 0.8710 - val_f1_m: 0.8433 - val_precision_m: 0.8721 - val_recall_m: 0.8172\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6792 - acc: 0.8386 - f1_m: 0.8399 - precision_m: 0.8824 - recall_m: 0.8021 - val_loss: 0.6020 - val_acc: 0.8790 - val_f1_m: 0.8813 - val_precision_m: 0.9001 - val_recall_m: 0.8639\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6665 - acc: 0.8422 - f1_m: 0.8413 - precision_m: 0.8838 - recall_m: 0.8038 - val_loss: 0.6051 - val_acc: 0.8790 - val_f1_m: 0.8589 - val_precision_m: 0.8976 - val_recall_m: 0.8239\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.6737 - acc: 0.8341 - f1_m: 0.8476 - precision_m: 0.8854 - recall_m: 0.8139 - val_loss: 0.6063 - val_acc: 0.8710 - val_f1_m: 0.8558 - val_precision_m: 0.8907 - val_recall_m: 0.8239\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.6571 - acc: 0.8458 - f1_m: 0.8441 - precision_m: 0.8812 - recall_m: 0.8103 - val_loss: 0.5979 - val_acc: 0.8871 - val_f1_m: 0.8603 - val_precision_m: 0.8852 - val_recall_m: 0.8372\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6487 - acc: 0.8449 - f1_m: 0.8432 - precision_m: 0.8794 - recall_m: 0.8103 - val_loss: 0.6198 - val_acc: 0.8710 - val_f1_m: 0.8459 - val_precision_m: 0.8768 - val_recall_m: 0.8172\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6536 - acc: 0.8395 - f1_m: 0.8419 - precision_m: 0.8842 - recall_m: 0.8043 - val_loss: 0.6123 - val_acc: 0.8871 - val_f1_m: 0.8573 - val_precision_m: 0.8786 - val_recall_m: 0.8372\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.6674 - acc: 0.8323 - f1_m: 0.8403 - precision_m: 0.8812 - recall_m: 0.8039 - val_loss: 0.5983 - val_acc: 0.8871 - val_f1_m: 0.8605 - val_precision_m: 0.8853 - val_recall_m: 0.8372\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6565 - acc: 0.8431 - f1_m: 0.8452 - precision_m: 0.8813 - recall_m: 0.8126 - val_loss: 0.5991 - val_acc: 0.8790 - val_f1_m: 0.8573 - val_precision_m: 0.8786 - val_recall_m: 0.8372\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6621 - acc: 0.8359 - f1_m: 0.8413 - precision_m: 0.8785 - recall_m: 0.8082 - val_loss: 0.6154 - val_acc: 0.8710 - val_f1_m: 0.8495 - val_precision_m: 0.8772 - val_recall_m: 0.8239\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6403 - acc: 0.8422 - f1_m: 0.8507 - precision_m: 0.8897 - recall_m: 0.8160 - val_loss: 0.6369 - val_acc: 0.8387 - val_f1_m: 0.8403 - val_precision_m: 0.8653 - val_recall_m: 0.8172\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.6684 - acc: 0.8332 - f1_m: 0.8378 - precision_m: 0.8758 - recall_m: 0.8039 - val_loss: 0.5996 - val_acc: 0.8790 - val_f1_m: 0.8535 - val_precision_m: 0.8780 - val_recall_m: 0.8306\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6537 - acc: 0.8539 - f1_m: 0.8486 - precision_m: 0.8960 - recall_m: 0.8081 - val_loss: 0.6059 - val_acc: 0.8871 - val_f1_m: 0.8558 - val_precision_m: 0.8907 - val_recall_m: 0.8239\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6507 - acc: 0.8521 - f1_m: 0.8453 - precision_m: 0.8809 - recall_m: 0.8129 - val_loss: 0.6057 - val_acc: 0.8710 - val_f1_m: 0.8503 - val_precision_m: 0.8793 - val_recall_m: 0.8239\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6720 - acc: 0.8332 - f1_m: 0.8407 - precision_m: 0.8846 - recall_m: 0.8017 - val_loss: 0.6067 - val_acc: 0.8710 - val_f1_m: 0.8575 - val_precision_m: 0.8790 - val_recall_m: 0.8372\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6391 - acc: 0.8476 - f1_m: 0.8564 - precision_m: 0.8975 - recall_m: 0.8195 - val_loss: 0.6032 - val_acc: 0.8710 - val_f1_m: 0.8472 - val_precision_m: 0.8726 - val_recall_m: 0.8239\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.6338 - acc: 0.8449 - f1_m: 0.8436 - precision_m: 0.8813 - recall_m: 0.8099 - val_loss: 0.6016 - val_acc: 0.8871 - val_f1_m: 0.8605 - val_precision_m: 0.8853 - val_recall_m: 0.8372\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6584 - acc: 0.8422 - f1_m: 0.8323 - precision_m: 0.8698 - recall_m: 0.7989 - val_loss: 0.5978 - val_acc: 0.8871 - val_f1_m: 0.8598 - val_precision_m: 0.8913 - val_recall_m: 0.8306\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6558 - acc: 0.8467 - f1_m: 0.8422 - precision_m: 0.8873 - recall_m: 0.8025 - val_loss: 0.6000 - val_acc: 0.8790 - val_f1_m: 0.8558 - val_precision_m: 0.8907 - val_recall_m: 0.8239\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6563 - acc: 0.8323 - f1_m: 0.8499 - precision_m: 0.8882 - recall_m: 0.8157 - val_loss: 0.5986 - val_acc: 0.8871 - val_f1_m: 0.8558 - val_precision_m: 0.8907 - val_recall_m: 0.8239\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.6368 - acc: 0.8512 - f1_m: 0.8491 - precision_m: 0.8924 - recall_m: 0.8107 - val_loss: 0.6066 - val_acc: 0.8629 - val_f1_m: 0.8511 - val_precision_m: 0.8732 - val_recall_m: 0.8306\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.6470 - acc: 0.8503 - f1_m: 0.8459 - precision_m: 0.8831 - recall_m: 0.8126 - val_loss: 0.6003 - val_acc: 0.8871 - val_f1_m: 0.8671 - val_precision_m: 0.8919 - val_recall_m: 0.8439\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 1s 34ms/step - loss: 0.6326 - acc: 0.8521 - f1_m: 0.8485 - precision_m: 0.8901 - recall_m: 0.8116 - val_loss: 0.6132 - val_acc: 0.8548 - val_f1_m: 0.8511 - val_precision_m: 0.8732 - val_recall_m: 0.8306\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.6415 - acc: 0.8440 - f1_m: 0.8504 - precision_m: 0.8933 - recall_m: 0.8126 - val_loss: 0.6054 - val_acc: 0.8710 - val_f1_m: 0.8562 - val_precision_m: 0.8845 - val_recall_m: 0.8306\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.6448 - acc: 0.8395 - f1_m: 0.8377 - precision_m: 0.8779 - recall_m: 0.8016 - val_loss: 0.6155 - val_acc: 0.8548 - val_f1_m: 0.8441 - val_precision_m: 0.8660 - val_recall_m: 0.8239\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.6337 - acc: 0.8584 - f1_m: 0.8593 - precision_m: 0.8962 - recall_m: 0.8261 - val_loss: 0.5998 - val_acc: 0.8790 - val_f1_m: 0.8612 - val_precision_m: 0.8794 - val_recall_m: 0.8439\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6411 - acc: 0.8422 - f1_m: 0.8470 - precision_m: 0.8923 - recall_m: 0.8065 - val_loss: 0.6191 - val_acc: 0.8548 - val_f1_m: 0.8441 - val_precision_m: 0.8660 - val_recall_m: 0.8239\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.6290 - acc: 0.8449 - f1_m: 0.8522 - precision_m: 0.8847 - recall_m: 0.8230 - val_loss: 0.5953 - val_acc: 0.8790 - val_f1_m: 0.8573 - val_precision_m: 0.8786 - val_recall_m: 0.8372\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.6516 - acc: 0.8359 - f1_m: 0.8402 - precision_m: 0.8858 - recall_m: 0.7995 - val_loss: 0.6024 - val_acc: 0.8629 - val_f1_m: 0.8416 - val_precision_m: 0.8758 - val_recall_m: 0.8106\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6440 - acc: 0.8440 - f1_m: 0.8403 - precision_m: 0.8795 - recall_m: 0.8051 - val_loss: 0.6085 - val_acc: 0.8710 - val_f1_m: 0.8460 - val_precision_m: 0.8773 - val_recall_m: 0.8172\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6355 - acc: 0.8512 - f1_m: 0.8584 - precision_m: 0.8940 - recall_m: 0.8261 - val_loss: 0.6075 - val_acc: 0.8710 - val_f1_m: 0.8416 - val_precision_m: 0.8758 - val_recall_m: 0.8106\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6325 - acc: 0.8395 - f1_m: 0.8484 - precision_m: 0.8876 - recall_m: 0.8134 - val_loss: 0.5970 - val_acc: 0.8710 - val_f1_m: 0.8466 - val_precision_m: 0.8708 - val_recall_m: 0.8239\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6189 - acc: 0.8458 - f1_m: 0.8561 - precision_m: 0.8959 - recall_m: 0.8209 - val_loss: 0.6005 - val_acc: 0.8710 - val_f1_m: 0.8503 - val_precision_m: 0.8713 - val_recall_m: 0.8306\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6321 - acc: 0.8575 - f1_m: 0.8491 - precision_m: 0.8863 - recall_m: 0.8156 - val_loss: 0.6428 - val_acc: 0.8306 - val_f1_m: 0.8293 - val_precision_m: 0.8573 - val_recall_m: 0.8039\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6349 - acc: 0.8467 - f1_m: 0.8500 - precision_m: 0.8928 - recall_m: 0.8121 - val_loss: 0.6012 - val_acc: 0.8790 - val_f1_m: 0.8462 - val_precision_m: 0.8785 - val_recall_m: 0.8172\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6414 - acc: 0.8431 - f1_m: 0.8351 - precision_m: 0.8843 - recall_m: 0.7925 - val_loss: 0.6021 - val_acc: 0.8710 - val_f1_m: 0.8535 - val_precision_m: 0.8780 - val_recall_m: 0.8306\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6453 - acc: 0.8467 - f1_m: 0.8503 - precision_m: 0.8911 - recall_m: 0.8139 - val_loss: 0.6037 - val_acc: 0.8629 - val_f1_m: 0.8433 - val_precision_m: 0.8721 - val_recall_m: 0.8172\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6324 - acc: 0.8413 - f1_m: 0.8379 - precision_m: 0.8769 - recall_m: 0.8033 - val_loss: 0.5991 - val_acc: 0.8710 - val_f1_m: 0.8512 - val_precision_m: 0.8734 - val_recall_m: 0.8306\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6372 - acc: 0.8422 - f1_m: 0.8529 - precision_m: 0.8953 - recall_m: 0.8152 - val_loss: 0.5999 - val_acc: 0.8710 - val_f1_m: 0.8520 - val_precision_m: 0.8903 - val_recall_m: 0.8172\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6223 - acc: 0.8440 - f1_m: 0.8530 - precision_m: 0.8973 - recall_m: 0.8134 - val_loss: 0.5948 - val_acc: 0.8790 - val_f1_m: 0.8535 - val_precision_m: 0.8780 - val_recall_m: 0.8306\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6333 - acc: 0.8377 - f1_m: 0.8366 - precision_m: 0.8770 - recall_m: 0.8003 - val_loss: 0.6273 - val_acc: 0.8629 - val_f1_m: 0.8373 - val_precision_m: 0.8589 - val_recall_m: 0.8172\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6246 - acc: 0.8467 - f1_m: 0.8485 - precision_m: 0.8908 - recall_m: 0.8108 - val_loss: 0.5975 - val_acc: 0.8790 - val_f1_m: 0.8495 - val_precision_m: 0.8772 - val_recall_m: 0.8239\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.6262 - acc: 0.8476 - f1_m: 0.8461 - precision_m: 0.8841 - recall_m: 0.8121 - val_loss: 0.5800 - val_acc: 0.8629 - val_f1_m: 0.8654 - val_precision_m: 0.9107 - val_recall_m: 0.8244\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.6144 - acc: 0.8467 - f1_m: 0.8554 - precision_m: 0.8937 - recall_m: 0.8213 - val_loss: 0.5768 - val_acc: 0.8468 - val_f1_m: 0.8623 - val_precision_m: 0.9038 - val_recall_m: 0.8244\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.6098 - acc: 0.8494 - f1_m: 0.8505 - precision_m: 0.8882 - recall_m: 0.8164 - val_loss: 0.5769 - val_acc: 0.8387 - val_f1_m: 0.8593 - val_precision_m: 0.8972 - val_recall_m: 0.8244\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6287 - acc: 0.8494 - f1_m: 0.8384 - precision_m: 0.8811 - recall_m: 0.8003 - val_loss: 0.5786 - val_acc: 0.8468 - val_f1_m: 0.8553 - val_precision_m: 0.8964 - val_recall_m: 0.8178\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6121 - acc: 0.8593 - f1_m: 0.8595 - precision_m: 0.8949 - recall_m: 0.8273 - val_loss: 0.5783 - val_acc: 0.8387 - val_f1_m: 0.8632 - val_precision_m: 0.8980 - val_recall_m: 0.8311\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6365 - acc: 0.8350 - f1_m: 0.8356 - precision_m: 0.8724 - recall_m: 0.8025 - val_loss: 0.6112 - val_acc: 0.8468 - val_f1_m: 0.8278 - val_precision_m: 0.8612 - val_recall_m: 0.7972\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6256 - acc: 0.8494 - f1_m: 0.8462 - precision_m: 0.8838 - recall_m: 0.8126 - val_loss: 0.6119 - val_acc: 0.8548 - val_f1_m: 0.8692 - val_precision_m: 0.9111 - val_recall_m: 0.8311\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6312 - acc: 0.8422 - f1_m: 0.8463 - precision_m: 0.8880 - recall_m: 0.8095 - val_loss: 0.5888 - val_acc: 0.8468 - val_f1_m: 0.8561 - val_precision_m: 0.8907 - val_recall_m: 0.8244\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6308 - acc: 0.8530 - f1_m: 0.8546 - precision_m: 0.8874 - recall_m: 0.8252 - val_loss: 0.6033 - val_acc: 0.8548 - val_f1_m: 0.8623 - val_precision_m: 0.9038 - val_recall_m: 0.8244\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6318 - acc: 0.8449 - f1_m: 0.8385 - precision_m: 0.8776 - recall_m: 0.8038 - val_loss: 0.5875 - val_acc: 0.8548 - val_f1_m: 0.8554 - val_precision_m: 0.8968 - val_recall_m: 0.8178\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6250 - acc: 0.8656 - f1_m: 0.8604 - precision_m: 0.8945 - recall_m: 0.8300 - val_loss: 0.5951 - val_acc: 0.8387 - val_f1_m: 0.8535 - val_precision_m: 0.8849 - val_recall_m: 0.8244\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6220 - acc: 0.8584 - f1_m: 0.8484 - precision_m: 0.8843 - recall_m: 0.8164 - val_loss: 0.5875 - val_acc: 0.8387 - val_f1_m: 0.8541 - val_precision_m: 0.8785 - val_recall_m: 0.8311\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6110 - acc: 0.8458 - f1_m: 0.8556 - precision_m: 0.8890 - recall_m: 0.8252 - val_loss: 0.5872 - val_acc: 0.8468 - val_f1_m: 0.8531 - val_precision_m: 0.8841 - val_recall_m: 0.8244\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6205 - acc: 0.8521 - f1_m: 0.8462 - precision_m: 0.8824 - recall_m: 0.8138 - val_loss: 0.6224 - val_acc: 0.8387 - val_f1_m: 0.8164 - val_precision_m: 0.8524 - val_recall_m: 0.7833\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6145 - acc: 0.8494 - f1_m: 0.8511 - precision_m: 0.8937 - recall_m: 0.8133 - val_loss: 0.5988 - val_acc: 0.8629 - val_f1_m: 0.8571 - val_precision_m: 0.8848 - val_recall_m: 0.8311\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6086 - acc: 0.8521 - f1_m: 0.8457 - precision_m: 0.8928 - recall_m: 0.8055 - val_loss: 0.5902 - val_acc: 0.8468 - val_f1_m: 0.8541 - val_precision_m: 0.8786 - val_recall_m: 0.8311\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6129 - acc: 0.8521 - f1_m: 0.8609 - precision_m: 0.8901 - recall_m: 0.8339 - val_loss: 0.6024 - val_acc: 0.8468 - val_f1_m: 0.8564 - val_precision_m: 0.8909 - val_recall_m: 0.8244\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6060 - acc: 0.8476 - f1_m: 0.8470 - precision_m: 0.8815 - recall_m: 0.8159 - val_loss: 0.5862 - val_acc: 0.8387 - val_f1_m: 0.8603 - val_precision_m: 0.8917 - val_recall_m: 0.8311\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6275 - acc: 0.8440 - f1_m: 0.8472 - precision_m: 0.8825 - recall_m: 0.8152 - val_loss: 0.6006 - val_acc: 0.8468 - val_f1_m: 0.8561 - val_precision_m: 0.8907 - val_recall_m: 0.8244\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6128 - acc: 0.8530 - f1_m: 0.8461 - precision_m: 0.8797 - recall_m: 0.8159 - val_loss: 0.5889 - val_acc: 0.8468 - val_f1_m: 0.8561 - val_precision_m: 0.8907 - val_recall_m: 0.8244\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6095 - acc: 0.8476 - f1_m: 0.8432 - precision_m: 0.8856 - recall_m: 0.8060 - val_loss: 0.5899 - val_acc: 0.8548 - val_f1_m: 0.8531 - val_precision_m: 0.8841 - val_recall_m: 0.8244\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6132 - acc: 0.8494 - f1_m: 0.8521 - precision_m: 0.8884 - recall_m: 0.8195 - val_loss: 0.5864 - val_acc: 0.8548 - val_f1_m: 0.8531 - val_precision_m: 0.8841 - val_recall_m: 0.8244\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6029 - acc: 0.8593 - f1_m: 0.8582 - precision_m: 0.9004 - recall_m: 0.8220 - val_loss: 0.5830 - val_acc: 0.8387 - val_f1_m: 0.8593 - val_precision_m: 0.8972 - val_recall_m: 0.8244\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6124 - acc: 0.8557 - f1_m: 0.8381 - precision_m: 0.8697 - recall_m: 0.8094 - val_loss: 0.5962 - val_acc: 0.8387 - val_f1_m: 0.8594 - val_precision_m: 0.8975 - val_recall_m: 0.8244\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5930 - acc: 0.8548 - f1_m: 0.8543 - precision_m: 0.8936 - recall_m: 0.8195 - val_loss: 0.5843 - val_acc: 0.8387 - val_f1_m: 0.8553 - val_precision_m: 0.8964 - val_recall_m: 0.8178\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6123 - acc: 0.8467 - f1_m: 0.8511 - precision_m: 0.8849 - recall_m: 0.8204 - val_loss: 0.6023 - val_acc: 0.8468 - val_f1_m: 0.8564 - val_precision_m: 0.8909 - val_recall_m: 0.8244\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6085 - acc: 0.8512 - f1_m: 0.8583 - precision_m: 0.8945 - recall_m: 0.8256 - val_loss: 0.5870 - val_acc: 0.8387 - val_f1_m: 0.8593 - val_precision_m: 0.8972 - val_recall_m: 0.8244\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5981 - acc: 0.8575 - f1_m: 0.8607 - precision_m: 0.8978 - recall_m: 0.8273 - val_loss: 0.5932 - val_acc: 0.8387 - val_f1_m: 0.8502 - val_precision_m: 0.8777 - val_recall_m: 0.8244\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6321 - acc: 0.8377 - f1_m: 0.8429 - precision_m: 0.8773 - recall_m: 0.8117 - val_loss: 0.5856 - val_acc: 0.8387 - val_f1_m: 0.8632 - val_precision_m: 0.8980 - val_recall_m: 0.8311\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6102 - acc: 0.8539 - f1_m: 0.8482 - precision_m: 0.8918 - recall_m: 0.8107 - val_loss: 0.6098 - val_acc: 0.8226 - val_f1_m: 0.8349 - val_precision_m: 0.8684 - val_recall_m: 0.8039\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6331 - acc: 0.8431 - f1_m: 0.8378 - precision_m: 0.8738 - recall_m: 0.8056 - val_loss: 0.5896 - val_acc: 0.8468 - val_f1_m: 0.8571 - val_precision_m: 0.8848 - val_recall_m: 0.8311\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6198 - acc: 0.8422 - f1_m: 0.8443 - precision_m: 0.8785 - recall_m: 0.8134 - val_loss: 0.6005 - val_acc: 0.8387 - val_f1_m: 0.8563 - val_precision_m: 0.8908 - val_recall_m: 0.8244\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5969 - acc: 0.8512 - f1_m: 0.8566 - precision_m: 0.8928 - recall_m: 0.8239 - val_loss: 0.6022 - val_acc: 0.8468 - val_f1_m: 0.8571 - val_precision_m: 0.8848 - val_recall_m: 0.8311\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6004 - acc: 0.8539 - f1_m: 0.8576 - precision_m: 0.8901 - recall_m: 0.8282 - val_loss: 0.6583 - val_acc: 0.8387 - val_f1_m: 0.8411 - val_precision_m: 0.8817 - val_recall_m: 0.8044\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6083 - acc: 0.8539 - f1_m: 0.8502 - precision_m: 0.8894 - recall_m: 0.8156 - val_loss: 0.5913 - val_acc: 0.8468 - val_f1_m: 0.8603 - val_precision_m: 0.8917 - val_recall_m: 0.8311\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5988 - acc: 0.8503 - f1_m: 0.8526 - precision_m: 0.8965 - recall_m: 0.8138 - val_loss: 0.5844 - val_acc: 0.8468 - val_f1_m: 0.8632 - val_precision_m: 0.8980 - val_recall_m: 0.8311\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5874 - acc: 0.8548 - f1_m: 0.8529 - precision_m: 0.8878 - recall_m: 0.8213 - val_loss: 0.5901 - val_acc: 0.8387 - val_f1_m: 0.8603 - val_precision_m: 0.8917 - val_recall_m: 0.8311\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6018 - acc: 0.8539 - f1_m: 0.8493 - precision_m: 0.8946 - recall_m: 0.8091 - val_loss: 0.5926 - val_acc: 0.8468 - val_f1_m: 0.8603 - val_precision_m: 0.8917 - val_recall_m: 0.8311\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6010 - acc: 0.8458 - f1_m: 0.8457 - precision_m: 0.8845 - recall_m: 0.8112 - val_loss: 0.5837 - val_acc: 0.8548 - val_f1_m: 0.8603 - val_precision_m: 0.8917 - val_recall_m: 0.8311\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5928 - acc: 0.8512 - f1_m: 0.8507 - precision_m: 0.8893 - recall_m: 0.8159 - val_loss: 0.5889 - val_acc: 0.8387 - val_f1_m: 0.8603 - val_precision_m: 0.8917 - val_recall_m: 0.8311\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5918 - acc: 0.8548 - f1_m: 0.8552 - precision_m: 0.8953 - recall_m: 0.8195 - val_loss: 0.6065 - val_acc: 0.8468 - val_f1_m: 0.8251 - val_precision_m: 0.8551 - val_recall_m: 0.7972\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6019 - acc: 0.8539 - f1_m: 0.8550 - precision_m: 0.8957 - recall_m: 0.8190 - val_loss: 0.6021 - val_acc: 0.8387 - val_f1_m: 0.8593 - val_precision_m: 0.8972 - val_recall_m: 0.8244\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6092 - acc: 0.8422 - f1_m: 0.8442 - precision_m: 0.8832 - recall_m: 0.8091 - val_loss: 0.6208 - val_acc: 0.8548 - val_f1_m: 0.8594 - val_precision_m: 0.8975 - val_recall_m: 0.8244\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6032 - acc: 0.8449 - f1_m: 0.8483 - precision_m: 0.8923 - recall_m: 0.8095 - val_loss: 0.5875 - val_acc: 0.8548 - val_f1_m: 0.8571 - val_precision_m: 0.8848 - val_recall_m: 0.8311\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6015 - acc: 0.8476 - f1_m: 0.8514 - precision_m: 0.8844 - recall_m: 0.8217 - val_loss: 0.5898 - val_acc: 0.8468 - val_f1_m: 0.8574 - val_precision_m: 0.8856 - val_recall_m: 0.8311\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6074 - acc: 0.8458 - f1_m: 0.8554 - precision_m: 0.9009 - recall_m: 0.8156 - val_loss: 0.5853 - val_acc: 0.8387 - val_f1_m: 0.8603 - val_precision_m: 0.8917 - val_recall_m: 0.8311\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.6054 - acc: 0.8404 - f1_m: 0.8468 - precision_m: 0.8827 - recall_m: 0.8147 - val_loss: 0.6511 - val_acc: 0.8468 - val_f1_m: 0.8494 - val_precision_m: 0.8837 - val_recall_m: 0.8178\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.5893 - acc: 0.8539 - f1_m: 0.8578 - precision_m: 0.8939 - recall_m: 0.8252 - val_loss: 0.5940 - val_acc: 0.8468 - val_f1_m: 0.8541 - val_precision_m: 0.8786 - val_recall_m: 0.8311\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.5902 - acc: 0.8539 - f1_m: 0.8524 - precision_m: 0.8901 - recall_m: 0.8186 - val_loss: 0.6008 - val_acc: 0.8387 - val_f1_m: 0.8502 - val_precision_m: 0.8777 - val_recall_m: 0.8244\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.5768 - acc: 0.8665 - f1_m: 0.8690 - precision_m: 0.9071 - recall_m: 0.8348 - val_loss: 0.5905 - val_acc: 0.8387 - val_f1_m: 0.8563 - val_precision_m: 0.8908 - val_recall_m: 0.8244\n",
      "Epoch 1/50\n",
      " 5/23 [=====>........................] - ETA: 0s - loss: 0.6541 - acc: 0.8200 - f1_m: 0.8357 - precision_m: 0.8661 - recall_m: 0.8080"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hager\\anaconda3\\envs\\hager\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 22ms/step - loss: 0.5908 - acc: 0.8539 - f1_m: 0.8539 - precision_m: 0.8895 - recall_m: 0.8216 - val_loss: 0.5834 - val_acc: 0.8629 - val_f1_m: 0.8849 - val_precision_m: 0.9136 - val_recall_m: 0.8583\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5900 - acc: 0.8503 - f1_m: 0.8528 - precision_m: 0.8886 - recall_m: 0.8208 - val_loss: 0.5804 - val_acc: 0.8871 - val_f1_m: 0.8779 - val_precision_m: 0.9078 - val_recall_m: 0.8517\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.5884 - acc: 0.8503 - f1_m: 0.8469 - precision_m: 0.8820 - recall_m: 0.8151 - val_loss: 0.5866 - val_acc: 0.8871 - val_f1_m: 0.8798 - val_precision_m: 0.9187 - val_recall_m: 0.8450\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.6007 - acc: 0.8467 - f1_m: 0.8435 - precision_m: 0.8823 - recall_m: 0.8086 - val_loss: 0.5867 - val_acc: 0.8710 - val_f1_m: 0.8700 - val_precision_m: 0.9048 - val_recall_m: 0.8383\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5963 - acc: 0.8476 - f1_m: 0.8491 - precision_m: 0.8946 - recall_m: 0.8086 - val_loss: 0.5919 - val_acc: 0.8871 - val_f1_m: 0.8914 - val_precision_m: 0.9202 - val_recall_m: 0.8656\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6115 - acc: 0.8494 - f1_m: 0.8455 - precision_m: 0.8873 - recall_m: 0.8086 - val_loss: 0.6050 - val_acc: 0.8387 - val_f1_m: 0.8608 - val_precision_m: 0.8851 - val_recall_m: 0.8389\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6115 - acc: 0.8305 - f1_m: 0.8323 - precision_m: 0.8731 - recall_m: 0.7959 - val_loss: 0.6069 - val_acc: 0.8629 - val_f1_m: 0.8700 - val_precision_m: 0.9048 - val_recall_m: 0.8383\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6101 - acc: 0.8332 - f1_m: 0.8396 - precision_m: 0.8736 - recall_m: 0.8087 - val_loss: 0.5994 - val_acc: 0.8871 - val_f1_m: 0.8832 - val_precision_m: 0.9260 - val_recall_m: 0.8450\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.5903 - acc: 0.8539 - f1_m: 0.8546 - precision_m: 0.8925 - recall_m: 0.8204 - val_loss: 0.5873 - val_acc: 0.8790 - val_f1_m: 0.8771 - val_precision_m: 0.9123 - val_recall_m: 0.8450\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.5905 - acc: 0.8512 - f1_m: 0.8504 - precision_m: 0.8862 - recall_m: 0.8182 - val_loss: 0.6014 - val_acc: 0.8387 - val_f1_m: 0.8560 - val_precision_m: 0.8901 - val_recall_m: 0.8250\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.5963 - acc: 0.8530 - f1_m: 0.8517 - precision_m: 0.8887 - recall_m: 0.8183 - val_loss: 0.5931 - val_acc: 0.8710 - val_f1_m: 0.8738 - val_precision_m: 0.9058 - val_recall_m: 0.8456\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.5902 - acc: 0.8530 - f1_m: 0.8463 - precision_m: 0.8885 - recall_m: 0.8086 - val_loss: 0.5925 - val_acc: 0.8629 - val_f1_m: 0.8658 - val_precision_m: 0.9039 - val_recall_m: 0.8317\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.5730 - acc: 0.8593 - f1_m: 0.8573 - precision_m: 0.8963 - recall_m: 0.8221 - val_loss: 0.5880 - val_acc: 0.8790 - val_f1_m: 0.8801 - val_precision_m: 0.9194 - val_recall_m: 0.8450\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5789 - acc: 0.8602 - f1_m: 0.8475 - precision_m: 0.8815 - recall_m: 0.8168 - val_loss: 0.5999 - val_acc: 0.8710 - val_f1_m: 0.8700 - val_precision_m: 0.9048 - val_recall_m: 0.8383\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5945 - acc: 0.8404 - f1_m: 0.8439 - precision_m: 0.8877 - recall_m: 0.8051 - val_loss: 0.5923 - val_acc: 0.8790 - val_f1_m: 0.8839 - val_precision_m: 0.9200 - val_recall_m: 0.8517\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5864 - acc: 0.8521 - f1_m: 0.8523 - precision_m: 0.8953 - recall_m: 0.8138 - val_loss: 0.6049 - val_acc: 0.8468 - val_f1_m: 0.8515 - val_precision_m: 0.8887 - val_recall_m: 0.8189\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5855 - acc: 0.8575 - f1_m: 0.8485 - precision_m: 0.8861 - recall_m: 0.8147 - val_loss: 0.5998 - val_acc: 0.8548 - val_f1_m: 0.8560 - val_precision_m: 0.8901 - val_recall_m: 0.8250\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5793 - acc: 0.8647 - f1_m: 0.8435 - precision_m: 0.8845 - recall_m: 0.8068 - val_loss: 0.6176 - val_acc: 0.8629 - val_f1_m: 0.8632 - val_precision_m: 0.8976 - val_recall_m: 0.8317\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5920 - acc: 0.8521 - f1_m: 0.8479 - precision_m: 0.8866 - recall_m: 0.8133 - val_loss: 0.5942 - val_acc: 0.8871 - val_f1_m: 0.8848 - val_precision_m: 0.9136 - val_recall_m: 0.8589\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5752 - acc: 0.8539 - f1_m: 0.8543 - precision_m: 0.8971 - recall_m: 0.8159 - val_loss: 0.6014 - val_acc: 0.8710 - val_f1_m: 0.8700 - val_precision_m: 0.9048 - val_recall_m: 0.8383\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5760 - acc: 0.8593 - f1_m: 0.8686 - precision_m: 0.9072 - recall_m: 0.8339 - val_loss: 0.5992 - val_acc: 0.8790 - val_f1_m: 0.8700 - val_precision_m: 0.9048 - val_recall_m: 0.8383\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5709 - acc: 0.8557 - f1_m: 0.8607 - precision_m: 0.8952 - recall_m: 0.8295 - val_loss: 0.6043 - val_acc: 0.8629 - val_f1_m: 0.8619 - val_precision_m: 0.9033 - val_recall_m: 0.8250\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5847 - acc: 0.8539 - f1_m: 0.8573 - precision_m: 0.8929 - recall_m: 0.8252 - val_loss: 0.6010 - val_acc: 0.8710 - val_f1_m: 0.8670 - val_precision_m: 0.8984 - val_recall_m: 0.8389\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5851 - acc: 0.8467 - f1_m: 0.8518 - precision_m: 0.8899 - recall_m: 0.8178 - val_loss: 0.6037 - val_acc: 0.8629 - val_f1_m: 0.8679 - val_precision_m: 0.8927 - val_recall_m: 0.8456\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.5891 - acc: 0.8503 - f1_m: 0.8416 - precision_m: 0.8883 - recall_m: 0.8003 - val_loss: 0.6016 - val_acc: 0.8710 - val_f1_m: 0.8658 - val_precision_m: 0.9039 - val_recall_m: 0.8317\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5809 - acc: 0.8539 - f1_m: 0.8538 - precision_m: 0.8910 - recall_m: 0.8204 - val_loss: 0.5977 - val_acc: 0.8710 - val_f1_m: 0.8700 - val_precision_m: 0.9048 - val_recall_m: 0.8383\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5637 - acc: 0.8702 - f1_m: 0.8597 - precision_m: 0.8979 - recall_m: 0.8251 - val_loss: 0.5933 - val_acc: 0.8710 - val_f1_m: 0.8779 - val_precision_m: 0.9065 - val_recall_m: 0.8522\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5927 - acc: 0.8503 - f1_m: 0.8549 - precision_m: 0.8933 - recall_m: 0.8204 - val_loss: 0.6029 - val_acc: 0.8710 - val_f1_m: 0.8658 - val_precision_m: 0.9039 - val_recall_m: 0.8317\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5866 - acc: 0.8521 - f1_m: 0.8569 - precision_m: 0.8910 - recall_m: 0.8261 - val_loss: 0.5968 - val_acc: 0.8871 - val_f1_m: 0.8730 - val_precision_m: 0.9116 - val_recall_m: 0.8383\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5732 - acc: 0.8557 - f1_m: 0.8633 - precision_m: 0.9007 - recall_m: 0.8296 - val_loss: 0.5967 - val_acc: 0.8790 - val_f1_m: 0.8700 - val_precision_m: 0.9048 - val_recall_m: 0.8383\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5825 - acc: 0.8512 - f1_m: 0.8516 - precision_m: 0.8880 - recall_m: 0.8190 - val_loss: 0.6048 - val_acc: 0.8468 - val_f1_m: 0.8599 - val_precision_m: 0.8909 - val_recall_m: 0.8322\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6098 - acc: 0.8413 - f1_m: 0.8392 - precision_m: 0.8800 - recall_m: 0.8029 - val_loss: 0.6105 - val_acc: 0.8710 - val_f1_m: 0.8632 - val_precision_m: 0.8976 - val_recall_m: 0.8317\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5712 - acc: 0.8593 - f1_m: 0.8594 - precision_m: 0.9067 - recall_m: 0.8178 - val_loss: 0.5980 - val_acc: 0.8710 - val_f1_m: 0.8658 - val_precision_m: 0.9039 - val_recall_m: 0.8317\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5859 - acc: 0.8395 - f1_m: 0.8404 - precision_m: 0.8789 - recall_m: 0.8056 - val_loss: 0.6007 - val_acc: 0.8548 - val_f1_m: 0.8658 - val_precision_m: 0.9042 - val_recall_m: 0.8322\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5954 - acc: 0.8431 - f1_m: 0.8570 - precision_m: 0.8914 - recall_m: 0.8261 - val_loss: 0.5965 - val_acc: 0.8710 - val_f1_m: 0.8801 - val_precision_m: 0.9194 - val_recall_m: 0.8450\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5686 - acc: 0.8557 - f1_m: 0.8550 - precision_m: 0.8934 - recall_m: 0.8208 - val_loss: 0.6002 - val_acc: 0.8710 - val_f1_m: 0.8700 - val_precision_m: 0.9048 - val_recall_m: 0.8383\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5750 - acc: 0.8530 - f1_m: 0.8453 - precision_m: 0.8861 - recall_m: 0.8089 - val_loss: 0.5976 - val_acc: 0.8629 - val_f1_m: 0.8700 - val_precision_m: 0.9048 - val_recall_m: 0.8383\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5773 - acc: 0.8539 - f1_m: 0.8520 - precision_m: 0.8890 - recall_m: 0.8194 - val_loss: 0.6041 - val_acc: 0.8629 - val_f1_m: 0.8586 - val_precision_m: 0.8961 - val_recall_m: 0.8250\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5466 - acc: 0.8674 - f1_m: 0.8628 - precision_m: 0.8973 - recall_m: 0.8317 - val_loss: 0.6072 - val_acc: 0.8629 - val_f1_m: 0.8658 - val_precision_m: 0.9039 - val_recall_m: 0.8317\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5633 - acc: 0.8602 - f1_m: 0.8587 - precision_m: 0.9025 - recall_m: 0.8199 - val_loss: 0.6203 - val_acc: 0.8710 - val_f1_m: 0.8658 - val_precision_m: 0.9039 - val_recall_m: 0.8317\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5684 - acc: 0.8530 - f1_m: 0.8615 - precision_m: 0.8968 - recall_m: 0.8296 - val_loss: 0.6061 - val_acc: 0.8710 - val_f1_m: 0.8658 - val_precision_m: 0.9039 - val_recall_m: 0.8317\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5783 - acc: 0.8530 - f1_m: 0.8488 - precision_m: 0.8888 - recall_m: 0.8133 - val_loss: 0.5901 - val_acc: 0.8710 - val_f1_m: 0.8763 - val_precision_m: 0.9188 - val_recall_m: 0.8383\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5724 - acc: 0.8593 - f1_m: 0.8601 - precision_m: 0.8958 - recall_m: 0.8278 - val_loss: 0.6002 - val_acc: 0.8548 - val_f1_m: 0.8631 - val_precision_m: 0.8977 - val_recall_m: 0.8317\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5797 - acc: 0.8494 - f1_m: 0.8521 - precision_m: 0.8877 - recall_m: 0.8204 - val_loss: 0.6010 - val_acc: 0.8871 - val_f1_m: 0.8658 - val_precision_m: 0.9039 - val_recall_m: 0.8317\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5701 - acc: 0.8512 - f1_m: 0.8499 - precision_m: 0.8887 - recall_m: 0.8156 - val_loss: 0.5935 - val_acc: 0.8710 - val_f1_m: 0.8721 - val_precision_m: 0.9182 - val_recall_m: 0.8317\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5581 - acc: 0.8638 - f1_m: 0.8592 - precision_m: 0.8970 - recall_m: 0.8256 - val_loss: 0.6112 - val_acc: 0.8790 - val_f1_m: 0.8562 - val_precision_m: 0.8902 - val_recall_m: 0.8250\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5674 - acc: 0.8530 - f1_m: 0.8458 - precision_m: 0.8878 - recall_m: 0.8094 - val_loss: 0.6027 - val_acc: 0.8387 - val_f1_m: 0.8493 - val_precision_m: 0.8829 - val_recall_m: 0.8183\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5634 - acc: 0.8593 - f1_m: 0.8593 - precision_m: 0.8967 - recall_m: 0.8256 - val_loss: 0.5965 - val_acc: 0.8629 - val_f1_m: 0.8700 - val_precision_m: 0.9048 - val_recall_m: 0.8383\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5985 - acc: 0.8377 - f1_m: 0.8380 - precision_m: 0.8735 - recall_m: 0.8060 - val_loss: 0.5987 - val_acc: 0.8710 - val_f1_m: 0.8700 - val_precision_m: 0.9048 - val_recall_m: 0.8383\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5666 - acc: 0.8552 - f1_m: 0.8546 - precision_m: 0.8931 - recall_m: 0.820 - 0s 16ms/step - loss: 0.5658 - acc: 0.8566 - f1_m: 0.8605 - precision_m: 0.8968 - recall_m: 0.8278 - val_loss: 0.6068 - val_acc: 0.8629 - val_f1_m: 0.8562 - val_precision_m: 0.8902 - val_recall_m: 0.8250\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5593 - acc: 0.8674 - f1_m: 0.8639 - precision_m: 0.9029 - recall_m: 0.8291 - val_loss: 0.5718 - val_acc: 0.8548 - val_f1_m: 0.8625 - val_precision_m: 0.8807 - val_recall_m: 0.8450\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5675 - acc: 0.8602 - f1_m: 0.8547 - precision_m: 0.8979 - recall_m: 0.8173 - val_loss: 0.5836 - val_acc: 0.8306 - val_f1_m: 0.8343 - val_precision_m: 0.8521 - val_recall_m: 0.8178\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5619 - acc: 0.8557 - f1_m: 0.8547 - precision_m: 0.8932 - recall_m: 0.8204 - val_loss: 0.5866 - val_acc: 0.8468 - val_f1_m: 0.8440 - val_precision_m: 0.8653 - val_recall_m: 0.8244\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5820 - acc: 0.8386 - f1_m: 0.8457 - precision_m: 0.8819 - recall_m: 0.8130 - val_loss: 0.5881 - val_acc: 0.8387 - val_f1_m: 0.8494 - val_precision_m: 0.8611 - val_recall_m: 0.8383\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5646 - acc: 0.8566 - f1_m: 0.8500 - precision_m: 0.8912 - recall_m: 0.8133 - val_loss: 0.6333 - val_acc: 0.8387 - val_f1_m: 0.8579 - val_precision_m: 0.8792 - val_recall_m: 0.8383\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5716 - acc: 0.8575 - f1_m: 0.8562 - precision_m: 0.8940 - recall_m: 0.8225 - val_loss: 0.5983 - val_acc: 0.8468 - val_f1_m: 0.8440 - val_precision_m: 0.8648 - val_recall_m: 0.8250\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5616 - acc: 0.8584 - f1_m: 0.8616 - precision_m: 0.9002 - recall_m: 0.8270 - val_loss: 0.5925 - val_acc: 0.8387 - val_f1_m: 0.8470 - val_precision_m: 0.8711 - val_recall_m: 0.8244\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5641 - acc: 0.8656 - f1_m: 0.8639 - precision_m: 0.9018 - recall_m: 0.8296 - val_loss: 0.5941 - val_acc: 0.8548 - val_f1_m: 0.8442 - val_precision_m: 0.8651 - val_recall_m: 0.8244\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5731 - acc: 0.8503 - f1_m: 0.8420 - precision_m: 0.8802 - recall_m: 0.8081 - val_loss: 0.5929 - val_acc: 0.8548 - val_f1_m: 0.8442 - val_precision_m: 0.8651 - val_recall_m: 0.8244\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5705 - acc: 0.8539 - f1_m: 0.8531 - precision_m: 0.8824 - recall_m: 0.8265 - val_loss: 0.6241 - val_acc: 0.8548 - val_f1_m: 0.8471 - val_precision_m: 0.8713 - val_recall_m: 0.8250\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5645 - acc: 0.8620 - f1_m: 0.8567 - precision_m: 0.8928 - recall_m: 0.8243 - val_loss: 0.6158 - val_acc: 0.8548 - val_f1_m: 0.8320 - val_precision_m: 0.8623 - val_recall_m: 0.8039\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5850 - acc: 0.8341 - f1_m: 0.8436 - precision_m: 0.8783 - recall_m: 0.8126 - val_loss: 0.5901 - val_acc: 0.8387 - val_f1_m: 0.8470 - val_precision_m: 0.8711 - val_recall_m: 0.8244\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5468 - acc: 0.8593 - f1_m: 0.8530 - precision_m: 0.8916 - recall_m: 0.8186 - val_loss: 0.5922 - val_acc: 0.8468 - val_f1_m: 0.8442 - val_precision_m: 0.8651 - val_recall_m: 0.8244\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5622 - acc: 0.8620 - f1_m: 0.8600 - precision_m: 0.8983 - recall_m: 0.8256 - val_loss: 0.5928 - val_acc: 0.8387 - val_f1_m: 0.8482 - val_precision_m: 0.8661 - val_recall_m: 0.8311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5557 - acc: 0.8602 - f1_m: 0.8610 - precision_m: 0.9105 - recall_m: 0.8186 - val_loss: 0.5961 - val_acc: 0.8548 - val_f1_m: 0.8442 - val_precision_m: 0.8651 - val_recall_m: 0.8244\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5563 - acc: 0.8683 - f1_m: 0.8654 - precision_m: 0.9017 - recall_m: 0.8326 - val_loss: 0.6004 - val_acc: 0.8387 - val_f1_m: 0.8556 - val_precision_m: 0.8738 - val_recall_m: 0.8383\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.5612 - acc: 0.8503 - f1_m: 0.8556 - precision_m: 0.8910 - recall_m: 0.8239 - val_loss: 0.5995 - val_acc: 0.8387 - val_f1_m: 0.8596 - val_precision_m: 0.8748 - val_recall_m: 0.8450\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5555 - acc: 0.8629 - f1_m: 0.8691 - precision_m: 0.9077 - recall_m: 0.8343 - val_loss: 0.6110 - val_acc: 0.8468 - val_f1_m: 0.8585 - val_precision_m: 0.8799 - val_recall_m: 0.8383\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5447 - acc: 0.8539 - f1_m: 0.8590 - precision_m: 0.8960 - recall_m: 0.8251 - val_loss: 0.6010 - val_acc: 0.8306 - val_f1_m: 0.8476 - val_precision_m: 0.8724 - val_recall_m: 0.8244\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5661 - acc: 0.8494 - f1_m: 0.8557 - precision_m: 0.8973 - recall_m: 0.8186 - val_loss: 0.6052 - val_acc: 0.8387 - val_f1_m: 0.8482 - val_precision_m: 0.8661 - val_recall_m: 0.8311\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5510 - acc: 0.8665 - f1_m: 0.8788 - precision_m: 0.9149 - recall_m: 0.8461 - val_loss: 0.6134 - val_acc: 0.8387 - val_f1_m: 0.8441 - val_precision_m: 0.8650 - val_recall_m: 0.8244\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5610 - acc: 0.8512 - f1_m: 0.8494 - precision_m: 0.8865 - recall_m: 0.8164 - val_loss: 0.6097 - val_acc: 0.8387 - val_f1_m: 0.8557 - val_precision_m: 0.8738 - val_recall_m: 0.8383\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5659 - acc: 0.8566 - f1_m: 0.8441 - precision_m: 0.8826 - recall_m: 0.8099 - val_loss: 0.6121 - val_acc: 0.8387 - val_f1_m: 0.8544 - val_precision_m: 0.8786 - val_recall_m: 0.8317\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5547 - acc: 0.8566 - f1_m: 0.8647 - precision_m: 0.9020 - recall_m: 0.8313 - val_loss: 0.6127 - val_acc: 0.8387 - val_f1_m: 0.8432 - val_precision_m: 0.8701 - val_recall_m: 0.8183\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5451 - acc: 0.8602 - f1_m: 0.8637 - precision_m: 0.8978 - recall_m: 0.8326 - val_loss: 0.6076 - val_acc: 0.8387 - val_f1_m: 0.8482 - val_precision_m: 0.8661 - val_recall_m: 0.8311\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.5487 - acc: 0.8638 - f1_m: 0.8599 - precision_m: 0.8997 - recall_m: 0.8243 - val_loss: 0.6056 - val_acc: 0.8306 - val_f1_m: 0.8414 - val_precision_m: 0.8593 - val_recall_m: 0.8244\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5325 - acc: 0.8647 - f1_m: 0.8734 - precision_m: 0.9093 - recall_m: 0.8409 - val_loss: 0.6146 - val_acc: 0.8387 - val_f1_m: 0.8556 - val_precision_m: 0.8738 - val_recall_m: 0.8383\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5695 - acc: 0.8503 - f1_m: 0.8615 - precision_m: 0.8991 - recall_m: 0.8273 - val_loss: 0.6215 - val_acc: 0.8387 - val_f1_m: 0.8475 - val_precision_m: 0.8714 - val_recall_m: 0.8250\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5425 - acc: 0.8602 - f1_m: 0.8656 - precision_m: 0.9028 - recall_m: 0.8317 - val_loss: 0.6128 - val_acc: 0.8387 - val_f1_m: 0.8487 - val_precision_m: 0.8667 - val_recall_m: 0.8317\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5490 - acc: 0.8611 - f1_m: 0.8586 - precision_m: 0.8963 - recall_m: 0.8251 - val_loss: 0.6184 - val_acc: 0.8387 - val_f1_m: 0.8556 - val_precision_m: 0.8738 - val_recall_m: 0.8383\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5511 - acc: 0.8566 - f1_m: 0.8644 - precision_m: 0.9017 - recall_m: 0.8308 - val_loss: 0.6322 - val_acc: 0.8306 - val_f1_m: 0.8262 - val_precision_m: 0.8498 - val_recall_m: 0.8039\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.5506 - acc: 0.8602 - f1_m: 0.8640 - precision_m: 0.8990 - recall_m: 0.8322 - val_loss: 0.6140 - val_acc: 0.8387 - val_f1_m: 0.8373 - val_precision_m: 0.8582 - val_recall_m: 0.8178\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5423 - acc: 0.8593 - f1_m: 0.8551 - precision_m: 0.8928 - recall_m: 0.8215 - val_loss: 0.6266 - val_acc: 0.8468 - val_f1_m: 0.8413 - val_precision_m: 0.8587 - val_recall_m: 0.8250\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5462 - acc: 0.8539 - f1_m: 0.8645 - precision_m: 0.8980 - recall_m: 0.8339 - val_loss: 0.6229 - val_acc: 0.8468 - val_f1_m: 0.8362 - val_precision_m: 0.8631 - val_recall_m: 0.8111\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5429 - acc: 0.8647 - f1_m: 0.8567 - precision_m: 0.9020 - recall_m: 0.8168 - val_loss: 0.6133 - val_acc: 0.8468 - val_f1_m: 0.8515 - val_precision_m: 0.8727 - val_recall_m: 0.8317\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5654 - acc: 0.8485 - f1_m: 0.8543 - precision_m: 0.8891 - recall_m: 0.8230 - val_loss: 0.6364 - val_acc: 0.8548 - val_f1_m: 0.8362 - val_precision_m: 0.8631 - val_recall_m: 0.8111\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5605 - acc: 0.8530 - f1_m: 0.8612 - precision_m: 0.8930 - recall_m: 0.8322 - val_loss: 0.6365 - val_acc: 0.8468 - val_f1_m: 0.8544 - val_precision_m: 0.8786 - val_recall_m: 0.8317\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5515 - acc: 0.8476 - f1_m: 0.8459 - precision_m: 0.8883 - recall_m: 0.8086 - val_loss: 0.6147 - val_acc: 0.8387 - val_f1_m: 0.8528 - val_precision_m: 0.8678 - val_recall_m: 0.8383\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5468 - acc: 0.8620 - f1_m: 0.8599 - precision_m: 0.8963 - recall_m: 0.8269 - val_loss: 0.6213 - val_acc: 0.8306 - val_f1_m: 0.8359 - val_precision_m: 0.8631 - val_recall_m: 0.8106\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5575 - acc: 0.8566 - f1_m: 0.8545 - precision_m: 0.8905 - recall_m: 0.8221 - val_loss: 0.6173 - val_acc: 0.8387 - val_f1_m: 0.8556 - val_precision_m: 0.8738 - val_recall_m: 0.8383\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5513 - acc: 0.8575 - f1_m: 0.8667 - precision_m: 0.9009 - recall_m: 0.8357 - val_loss: 0.6476 - val_acc: 0.8468 - val_f1_m: 0.8392 - val_precision_m: 0.8696 - val_recall_m: 0.8111\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5568 - acc: 0.8548 - f1_m: 0.8600 - precision_m: 0.8963 - recall_m: 0.8273 - val_loss: 0.6152 - val_acc: 0.8468 - val_f1_m: 0.8516 - val_precision_m: 0.8726 - val_recall_m: 0.8317\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5597 - acc: 0.8476 - f1_m: 0.8552 - precision_m: 0.8926 - recall_m: 0.8217 - val_loss: 0.6528 - val_acc: 0.8145 - val_f1_m: 0.8204 - val_precision_m: 0.8377 - val_recall_m: 0.8039\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5601 - acc: 0.8521 - f1_m: 0.8526 - precision_m: 0.8843 - recall_m: 0.8239 - val_loss: 0.6289 - val_acc: 0.8387 - val_f1_m: 0.8528 - val_precision_m: 0.8678 - val_recall_m: 0.8383\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5475 - acc: 0.8593 - f1_m: 0.8558 - precision_m: 0.8939 - recall_m: 0.8213 - val_loss: 0.6499 - val_acc: 0.8629 - val_f1_m: 0.8432 - val_precision_m: 0.8703 - val_recall_m: 0.8178\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.5768 - acc: 0.8440 - f1_m: 0.8472 - precision_m: 0.8822 - recall_m: 0.8157 - val_loss: 0.6401 - val_acc: 0.8387 - val_f1_m: 0.8271 - val_precision_m: 0.8445 - val_recall_m: 0.8106\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 14ms/step - loss: 0.5442 - acc: 0.8611 - f1_m: 0.8738 - precision_m: 0.9058 - recall_m: 0.8452 - val_loss: 0.6219 - val_acc: 0.8306 - val_f1_m: 0.8435 - val_precision_m: 0.8714 - val_recall_m: 0.8178\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5436 - acc: 0.8575 - f1_m: 0.8645 - precision_m: 0.9030 - recall_m: 0.8296 - val_loss: 0.6250 - val_acc: 0.8468 - val_f1_m: 0.8487 - val_precision_m: 0.8667 - val_recall_m: 0.8317\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5353 - acc: 0.8602 - f1_m: 0.8658 - precision_m: 0.8993 - recall_m: 0.8357 - val_loss: 0.6260 - val_acc: 0.8387 - val_f1_m: 0.8346 - val_precision_m: 0.8522 - val_recall_m: 0.8178\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5438 - acc: 0.8593 - f1_m: 0.8517 - precision_m: 0.8866 - recall_m: 0.8203 - val_loss: 0.6305 - val_acc: 0.8306 - val_f1_m: 0.8333 - val_precision_m: 0.8569 - val_recall_m: 0.8111\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.5470 - acc: 0.8548 - f1_m: 0.8506 - precision_m: 0.8876 - recall_m: 0.8173 - val_loss: 0.5432 - val_acc: 0.8306 - val_f1_m: 0.8447 - val_precision_m: 0.8823 - val_recall_m: 0.8111\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5517 - acc: 0.8575 - f1_m: 0.8538 - precision_m: 0.8940 - recall_m: 0.8177 - val_loss: 0.5499 - val_acc: 0.8306 - val_f1_m: 0.8447 - val_precision_m: 0.8823 - val_recall_m: 0.8111\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5606 - acc: 0.8620 - f1_m: 0.8590 - precision_m: 0.8902 - recall_m: 0.8313 - val_loss: 0.5559 - val_acc: 0.8468 - val_f1_m: 0.8438 - val_precision_m: 0.8885 - val_recall_m: 0.8044\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5604 - acc: 0.8503 - f1_m: 0.8421 - precision_m: 0.8792 - recall_m: 0.8090 - val_loss: 0.5654 - val_acc: 0.8226 - val_f1_m: 0.8110 - val_precision_m: 0.8499 - val_recall_m: 0.7761\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5472 - acc: 0.8638 - f1_m: 0.8620 - precision_m: 0.8932 - recall_m: 0.8334 - val_loss: 0.5721 - val_acc: 0.8306 - val_f1_m: 0.8336 - val_precision_m: 0.8743 - val_recall_m: 0.7972\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5532 - acc: 0.8557 - f1_m: 0.8598 - precision_m: 0.8993 - recall_m: 0.8243 - val_loss: 0.6055 - val_acc: 0.8306 - val_f1_m: 0.8111 - val_precision_m: 0.8431 - val_recall_m: 0.7822\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5619 - acc: 0.8575 - f1_m: 0.8587 - precision_m: 0.8980 - recall_m: 0.8235 - val_loss: 0.5645 - val_acc: 0.8306 - val_f1_m: 0.8490 - val_precision_m: 0.8845 - val_recall_m: 0.8178\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5550 - acc: 0.8521 - f1_m: 0.8579 - precision_m: 0.8989 - recall_m: 0.8216 - val_loss: 0.5651 - val_acc: 0.8226 - val_f1_m: 0.8388 - val_precision_m: 0.8702 - val_recall_m: 0.8111\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5572 - acc: 0.8458 - f1_m: 0.8549 - precision_m: 0.8927 - recall_m: 0.8209 - val_loss: 0.5642 - val_acc: 0.8145 - val_f1_m: 0.8266 - val_precision_m: 0.8670 - val_recall_m: 0.7906\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5453 - acc: 0.8584 - f1_m: 0.8591 - precision_m: 0.8947 - recall_m: 0.8269 - val_loss: 0.5863 - val_acc: 0.8306 - val_f1_m: 0.8096 - val_precision_m: 0.8553 - val_recall_m: 0.7694\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5362 - acc: 0.8584 - f1_m: 0.8634 - precision_m: 0.8993 - recall_m: 0.8308 - val_loss: 0.5713 - val_acc: 0.8226 - val_f1_m: 0.8306 - val_precision_m: 0.8685 - val_recall_m: 0.7978\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5469 - acc: 0.8584 - f1_m: 0.8501 - precision_m: 0.8880 - recall_m: 0.8163 - val_loss: 0.6063 - val_acc: 0.8145 - val_f1_m: 0.7962 - val_precision_m: 0.8341 - val_recall_m: 0.7622\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5471 - acc: 0.8593 - f1_m: 0.8448 - precision_m: 0.8878 - recall_m: 0.8068 - val_loss: 0.5778 - val_acc: 0.8145 - val_f1_m: 0.8118 - val_precision_m: 0.8512 - val_recall_m: 0.7767\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5499 - acc: 0.8656 - f1_m: 0.8586 - precision_m: 0.9050 - recall_m: 0.8173 - val_loss: 0.5751 - val_acc: 0.8306 - val_f1_m: 0.8336 - val_precision_m: 0.8743 - val_recall_m: 0.7972\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5279 - acc: 0.8702 - f1_m: 0.8676 - precision_m: 0.9052 - recall_m: 0.8338 - val_loss: 0.5727 - val_acc: 0.8226 - val_f1_m: 0.8151 - val_precision_m: 0.8577 - val_recall_m: 0.7767\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5384 - acc: 0.8575 - f1_m: 0.8617 - precision_m: 0.8935 - recall_m: 0.8329 - val_loss: 0.5802 - val_acc: 0.8226 - val_f1_m: 0.8196 - val_precision_m: 0.8590 - val_recall_m: 0.7839\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5548 - acc: 0.8575 - f1_m: 0.8584 - precision_m: 0.8997 - recall_m: 0.8217 - val_loss: 0.6487 - val_acc: 0.7984 - val_f1_m: 0.7894 - val_precision_m: 0.8276 - val_recall_m: 0.7556\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5444 - acc: 0.8584 - f1_m: 0.8669 - precision_m: 0.9006 - recall_m: 0.8360 - val_loss: 0.5939 - val_acc: 0.8226 - val_f1_m: 0.8186 - val_precision_m: 0.8582 - val_recall_m: 0.7833\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5410 - acc: 0.8665 - f1_m: 0.8650 - precision_m: 0.9004 - recall_m: 0.8329 - val_loss: 0.5813 - val_acc: 0.8306 - val_f1_m: 0.8220 - val_precision_m: 0.8650 - val_recall_m: 0.7833\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5287 - acc: 0.8656 - f1_m: 0.8562 - precision_m: 0.8992 - recall_m: 0.8189 - val_loss: 0.5903 - val_acc: 0.8226 - val_f1_m: 0.8401 - val_precision_m: 0.8815 - val_recall_m: 0.8050\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5405 - acc: 0.8575 - f1_m: 0.8613 - precision_m: 0.9045 - recall_m: 0.8230 - val_loss: 0.5822 - val_acc: 0.8226 - val_f1_m: 0.8266 - val_precision_m: 0.8670 - val_recall_m: 0.7906\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5348 - acc: 0.8494 - f1_m: 0.8569 - precision_m: 0.8954 - recall_m: 0.8221 - val_loss: 0.5936 - val_acc: 0.8065 - val_f1_m: 0.8148 - val_precision_m: 0.8574 - val_recall_m: 0.7767\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5205 - acc: 0.8620 - f1_m: 0.8661 - precision_m: 0.9030 - recall_m: 0.8326 - val_loss: 0.5943 - val_acc: 0.8145 - val_f1_m: 0.8118 - val_precision_m: 0.8512 - val_recall_m: 0.7767\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5502 - acc: 0.8575 - f1_m: 0.8440 - precision_m: 0.8765 - recall_m: 0.8150 - val_loss: 0.5867 - val_acc: 0.7984 - val_f1_m: 0.8035 - val_precision_m: 0.8492 - val_recall_m: 0.7633\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.5396 - acc: 0.8629 - f1_m: 0.8655 - precision_m: 0.9038 - recall_m: 0.8308 - val_loss: 0.5862 - val_acc: 0.8226 - val_f1_m: 0.8266 - val_precision_m: 0.8670 - val_recall_m: 0.7906\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.5448 - acc: 0.8620 - f1_m: 0.8474 - precision_m: 0.8847 - recall_m: 0.8137 - val_loss: 0.5965 - val_acc: 0.8306 - val_f1_m: 0.8332 - val_precision_m: 0.8748 - val_recall_m: 0.7978\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5285 - acc: 0.8693 - f1_m: 0.8705 - precision_m: 0.9119 - recall_m: 0.8334 - val_loss: 0.6082 - val_acc: 0.8065 - val_f1_m: 0.8224 - val_precision_m: 0.8655 - val_recall_m: 0.7839\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5346 - acc: 0.8674 - f1_m: 0.8677 - precision_m: 0.9041 - recall_m: 0.8352 - val_loss: 0.5986 - val_acc: 0.7984 - val_f1_m: 0.8079 - val_precision_m: 0.8503 - val_recall_m: 0.7700\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5307 - acc: 0.8711 - f1_m: 0.8719 - precision_m: 0.9129 - recall_m: 0.8352 - val_loss: 0.6045 - val_acc: 0.8065 - val_f1_m: 0.8148 - val_precision_m: 0.8574 - val_recall_m: 0.7767\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5285 - acc: 0.8611 - f1_m: 0.8634 - precision_m: 0.8970 - recall_m: 0.8329 - val_loss: 0.6102 - val_acc: 0.7984 - val_f1_m: 0.7956 - val_precision_m: 0.8406 - val_recall_m: 0.7561\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5351 - acc: 0.8683 - f1_m: 0.8656 - precision_m: 0.9017 - recall_m: 0.8334 - val_loss: 0.6060 - val_acc: 0.8306 - val_f1_m: 0.8178 - val_precision_m: 0.8639 - val_recall_m: 0.7767\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5354 - acc: 0.8638 - f1_m: 0.8696 - precision_m: 0.9126 - recall_m: 0.8313 - val_loss: 0.6199 - val_acc: 0.7984 - val_f1_m: 0.8125 - val_precision_m: 0.8621 - val_recall_m: 0.7694\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5148 - acc: 0.8720 - f1_m: 0.8779 - precision_m: 0.9156 - recall_m: 0.8443 - val_loss: 0.5979 - val_acc: 0.7984 - val_f1_m: 0.8007 - val_precision_m: 0.8426 - val_recall_m: 0.7633\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5341 - acc: 0.8665 - f1_m: 0.8524 - precision_m: 0.8854 - recall_m: 0.8224 - val_loss: 0.6018 - val_acc: 0.7984 - val_f1_m: 0.8079 - val_precision_m: 0.8503 - val_recall_m: 0.7700\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5506 - acc: 0.8593 - f1_m: 0.8554 - precision_m: 0.8961 - recall_m: 0.8190 - val_loss: 0.5948 - val_acc: 0.8065 - val_f1_m: 0.8065 - val_precision_m: 0.8555 - val_recall_m: 0.7633\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5435 - acc: 0.8539 - f1_m: 0.8577 - precision_m: 0.9091 - recall_m: 0.8142 - val_loss: 0.6024 - val_acc: 0.7903 - val_f1_m: 0.8007 - val_precision_m: 0.8426 - val_recall_m: 0.7633\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5333 - acc: 0.8738 - f1_m: 0.8705 - precision_m: 0.9120 - recall_m: 0.8334 - val_loss: 0.6109 - val_acc: 0.8226 - val_f1_m: 0.8282 - val_precision_m: 0.8786 - val_recall_m: 0.7839\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5392 - acc: 0.8620 - f1_m: 0.8547 - precision_m: 0.8993 - recall_m: 0.8156 - val_loss: 0.6154 - val_acc: 0.7984 - val_f1_m: 0.8068 - val_precision_m: 0.8488 - val_recall_m: 0.7694\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5598 - acc: 0.8431 - f1_m: 0.8410 - precision_m: 0.8799 - recall_m: 0.8064 - val_loss: 0.6025 - val_acc: 0.8065 - val_f1_m: 0.8144 - val_precision_m: 0.8582 - val_recall_m: 0.7778\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.5328 - acc: 0.8557 - f1_m: 0.8650 - precision_m: 0.8998 - recall_m: 0.8339 - val_loss: 0.6020 - val_acc: 0.7823 - val_f1_m: 0.8035 - val_precision_m: 0.8492 - val_recall_m: 0.7633\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.5370 - acc: 0.8647 - f1_m: 0.8509 - precision_m: 0.8899 - recall_m: 0.8163 - val_loss: 0.6117 - val_acc: 0.8306 - val_f1_m: 0.8338 - val_precision_m: 0.8918 - val_recall_m: 0.7844\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5401 - acc: 0.8674 - f1_m: 0.8603 - precision_m: 0.8999 - recall_m: 0.8247 - val_loss: 0.6003 - val_acc: 0.7984 - val_f1_m: 0.8051 - val_precision_m: 0.8438 - val_recall_m: 0.7700\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5224 - acc: 0.8647 - f1_m: 0.8636 - precision_m: 0.8992 - recall_m: 0.8312 - val_loss: 0.6046 - val_acc: 0.8065 - val_f1_m: 0.8123 - val_precision_m: 0.8515 - val_recall_m: 0.7772\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5278 - acc: 0.8674 - f1_m: 0.8643 - precision_m: 0.9085 - recall_m: 0.8251 - val_loss: 0.6725 - val_acc: 0.7903 - val_f1_m: 0.7756 - val_precision_m: 0.8128 - val_recall_m: 0.7422\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5472 - acc: 0.8674 - f1_m: 0.8576 - precision_m: 0.8941 - recall_m: 0.8243 - val_loss: 0.6031 - val_acc: 0.8065 - val_f1_m: 0.8051 - val_precision_m: 0.8438 - val_recall_m: 0.7700\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5337 - acc: 0.8702 - f1_m: 0.8662 - precision_m: 0.9055 - recall_m: 0.8308 - val_loss: 0.6143 - val_acc: 0.7823 - val_f1_m: 0.8007 - val_precision_m: 0.8426 - val_recall_m: 0.7633\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5211 - acc: 0.8711 - f1_m: 0.8730 - precision_m: 0.9153 - recall_m: 0.8352 - val_loss: 0.6112 - val_acc: 0.8065 - val_f1_m: 0.8079 - val_precision_m: 0.8503 - val_recall_m: 0.7700\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5357 - acc: 0.8638 - f1_m: 0.8669 - precision_m: 0.9020 - recall_m: 0.8352 - val_loss: 0.6506 - val_acc: 0.7903 - val_f1_m: 0.7880 - val_precision_m: 0.8325 - val_recall_m: 0.7489\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5163 - acc: 0.8729 - f1_m: 0.8634 - precision_m: 0.8978 - recall_m: 0.8326 - val_loss: 0.6124 - val_acc: 0.8065 - val_f1_m: 0.8093 - val_precision_m: 0.8625 - val_recall_m: 0.7633\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5318 - acc: 0.8693 - f1_m: 0.8604 - precision_m: 0.9095 - recall_m: 0.8173 - val_loss: 0.6133 - val_acc: 0.8065 - val_f1_m: 0.8122 - val_precision_m: 0.8514 - val_recall_m: 0.7767\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5440 - acc: 0.8584 - f1_m: 0.8520 - precision_m: 0.8890 - recall_m: 0.8186 - val_loss: 0.4969 - val_acc: 0.8871 - val_f1_m: 0.8875 - val_precision_m: 0.9262 - val_recall_m: 0.8522\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5343 - acc: 0.8665 - f1_m: 0.8610 - precision_m: 0.8999 - recall_m: 0.8260 - val_loss: 0.4917 - val_acc: 0.8871 - val_f1_m: 0.8949 - val_precision_m: 0.9269 - val_recall_m: 0.8661\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5484 - acc: 0.8521 - f1_m: 0.8544 - precision_m: 0.8953 - recall_m: 0.8178 - val_loss: 0.4966 - val_acc: 0.8710 - val_f1_m: 0.8949 - val_precision_m: 0.9269 - val_recall_m: 0.8661\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5344 - acc: 0.8647 - f1_m: 0.8581 - precision_m: 0.8982 - recall_m: 0.8220 - val_loss: 0.5099 - val_acc: 0.8710 - val_f1_m: 0.8818 - val_precision_m: 0.9062 - val_recall_m: 0.8594\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5439 - acc: 0.8566 - f1_m: 0.8631 - precision_m: 0.8972 - recall_m: 0.8322 - val_loss: 0.5146 - val_acc: 0.8710 - val_f1_m: 0.8779 - val_precision_m: 0.9054 - val_recall_m: 0.8528\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5290 - acc: 0.8638 - f1_m: 0.8575 - precision_m: 0.8930 - recall_m: 0.8255 - val_loss: 0.5102 - val_acc: 0.8790 - val_f1_m: 0.8776 - val_precision_m: 0.9124 - val_recall_m: 0.8456\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.5527 - acc: 0.8539 - f1_m: 0.8497 - precision_m: 0.8853 - recall_m: 0.8178 - val_loss: 0.4919 - val_acc: 0.8710 - val_f1_m: 0.8949 - val_precision_m: 0.9269 - val_recall_m: 0.8661\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.5416 - acc: 0.8494 - f1_m: 0.8491 - precision_m: 0.8841 - recall_m: 0.8173 - val_loss: 0.5232 - val_acc: 0.8710 - val_f1_m: 0.8715 - val_precision_m: 0.8993 - val_recall_m: 0.8456\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.5462 - acc: 0.8584 - f1_m: 0.8516 - precision_m: 0.8910 - recall_m: 0.8164 - val_loss: 0.5053 - val_acc: 0.8790 - val_f1_m: 0.8917 - val_precision_m: 0.9199 - val_recall_m: 0.8661\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 1s 39ms/step - loss: 0.5403 - acc: 0.8611 - f1_m: 0.8564 - precision_m: 0.8849 - recall_m: 0.8303 - val_loss: 0.4983 - val_acc: 0.8629 - val_f1_m: 0.8978 - val_precision_m: 0.9334 - val_recall_m: 0.8661\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 22ms/step - loss: 0.5288 - acc: 0.8611 - f1_m: 0.8556 - precision_m: 0.8968 - recall_m: 0.8186 - val_loss: 0.5123 - val_acc: 0.8710 - val_f1_m: 0.8808 - val_precision_m: 0.9120 - val_recall_m: 0.8528\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5685 - acc: 0.8458 - f1_m: 0.8397 - precision_m: 0.8923 - recall_m: 0.7951 - val_loss: 0.5271 - val_acc: 0.8710 - val_f1_m: 0.8664 - val_precision_m: 0.9040 - val_recall_m: 0.8322\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5508 - acc: 0.8530 - f1_m: 0.8610 - precision_m: 0.8994 - recall_m: 0.8269 - val_loss: 0.5193 - val_acc: 0.8790 - val_f1_m: 0.8778 - val_precision_m: 0.9057 - val_recall_m: 0.8528\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.5324 - acc: 0.8647 - f1_m: 0.8595 - precision_m: 0.8993 - recall_m: 0.8238 - val_loss: 0.5182 - val_acc: 0.8710 - val_f1_m: 0.8749 - val_precision_m: 0.8991 - val_recall_m: 0.8528\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.5458 - acc: 0.8512 - f1_m: 0.8590 - precision_m: 0.8954 - recall_m: 0.8261 - val_loss: 0.5200 - val_acc: 0.8468 - val_f1_m: 0.8749 - val_precision_m: 0.8991 - val_recall_m: 0.8528\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5415 - acc: 0.8539 - f1_m: 0.8526 - precision_m: 0.8851 - recall_m: 0.8230 - val_loss: 0.5152 - val_acc: 0.8790 - val_f1_m: 0.8808 - val_precision_m: 0.9120 - val_recall_m: 0.8528\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5483 - acc: 0.8521 - f1_m: 0.8484 - precision_m: 0.8835 - recall_m: 0.8169 - val_loss: 0.5679 - val_acc: 0.8306 - val_f1_m: 0.8421 - val_precision_m: 0.8839 - val_recall_m: 0.8044\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5668 - acc: 0.8440 - f1_m: 0.8468 - precision_m: 0.8892 - recall_m: 0.8096 - val_loss: 0.5053 - val_acc: 0.8629 - val_f1_m: 0.8949 - val_precision_m: 0.9269 - val_recall_m: 0.8661\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5274 - acc: 0.8584 - f1_m: 0.8598 - precision_m: 0.8990 - recall_m: 0.8243 - val_loss: 0.5264 - val_acc: 0.8871 - val_f1_m: 0.8735 - val_precision_m: 0.9114 - val_recall_m: 0.8389\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5526 - acc: 0.8485 - f1_m: 0.8576 - precision_m: 0.8928 - recall_m: 0.8256 - val_loss: 0.5291 - val_acc: 0.8790 - val_f1_m: 0.8675 - val_precision_m: 0.8985 - val_recall_m: 0.8389\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5233 - acc: 0.8647 - f1_m: 0.8673 - precision_m: 0.9010 - recall_m: 0.8369 - val_loss: 0.5075 - val_acc: 0.8629 - val_f1_m: 0.8917 - val_precision_m: 0.9199 - val_recall_m: 0.8661\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5253 - acc: 0.8665 - f1_m: 0.8623 - precision_m: 0.9065 - recall_m: 0.8230 - val_loss: 0.5129 - val_acc: 0.8548 - val_f1_m: 0.8808 - val_precision_m: 0.9120 - val_recall_m: 0.8528\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5393 - acc: 0.8656 - f1_m: 0.8570 - precision_m: 0.9033 - recall_m: 0.8164 - val_loss: 0.5213 - val_acc: 0.8790 - val_f1_m: 0.8818 - val_precision_m: 0.9062 - val_recall_m: 0.8594\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5419 - acc: 0.8539 - f1_m: 0.8541 - precision_m: 0.8937 - recall_m: 0.8186 - val_loss: 0.5350 - val_acc: 0.8629 - val_f1_m: 0.8738 - val_precision_m: 0.9046 - val_recall_m: 0.8461\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5567 - acc: 0.8476 - f1_m: 0.8521 - precision_m: 0.8924 - recall_m: 0.8160 - val_loss: 0.5276 - val_acc: 0.8468 - val_f1_m: 0.8838 - val_precision_m: 0.9186 - val_recall_m: 0.8528\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5422 - acc: 0.8566 - f1_m: 0.8588 - precision_m: 0.8952 - recall_m: 0.8261 - val_loss: 0.5128 - val_acc: 0.8548 - val_f1_m: 0.8848 - val_precision_m: 0.9127 - val_recall_m: 0.8594\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5414 - acc: 0.8458 - f1_m: 0.8513 - precision_m: 0.8911 - recall_m: 0.8160 - val_loss: 0.5223 - val_acc: 0.8468 - val_f1_m: 0.8779 - val_precision_m: 0.9054 - val_recall_m: 0.8528\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5218 - acc: 0.8602 - f1_m: 0.8634 - precision_m: 0.9033 - recall_m: 0.8277 - val_loss: 0.5151 - val_acc: 0.8629 - val_f1_m: 0.8917 - val_precision_m: 0.9199 - val_recall_m: 0.8661\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5375 - acc: 0.8593 - f1_m: 0.8521 - precision_m: 0.8931 - recall_m: 0.8156 - val_loss: 0.5168 - val_acc: 0.8468 - val_f1_m: 0.8779 - val_precision_m: 0.9054 - val_recall_m: 0.8528\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5451 - acc: 0.8530 - f1_m: 0.8549 - precision_m: 0.8917 - recall_m: 0.8220 - val_loss: 0.5309 - val_acc: 0.8629 - val_f1_m: 0.8611 - val_precision_m: 0.8847 - val_recall_m: 0.8394\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5512 - acc: 0.8530 - f1_m: 0.8486 - precision_m: 0.8837 - recall_m: 0.8169 - val_loss: 0.5327 - val_acc: 0.8468 - val_f1_m: 0.8808 - val_precision_m: 0.9120 - val_recall_m: 0.8528\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5275 - acc: 0.8566 - f1_m: 0.8622 - precision_m: 0.8967 - recall_m: 0.8308 - val_loss: 0.5132 - val_acc: 0.8548 - val_f1_m: 0.8947 - val_precision_m: 0.9265 - val_recall_m: 0.8661\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5178 - acc: 0.8693 - f1_m: 0.8652 - precision_m: 0.9064 - recall_m: 0.8282 - val_loss: 0.5187 - val_acc: 0.8548 - val_f1_m: 0.8779 - val_precision_m: 0.9054 - val_recall_m: 0.8528\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5230 - acc: 0.8539 - f1_m: 0.8480 - precision_m: 0.8880 - recall_m: 0.8120 - val_loss: 0.5206 - val_acc: 0.8548 - val_f1_m: 0.8879 - val_precision_m: 0.9194 - val_recall_m: 0.8594\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5326 - acc: 0.8693 - f1_m: 0.8635 - precision_m: 0.9011 - recall_m: 0.8296 - val_loss: 0.5193 - val_acc: 0.8629 - val_f1_m: 0.8879 - val_precision_m: 0.9194 - val_recall_m: 0.8594\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5307 - acc: 0.8611 - f1_m: 0.8561 - precision_m: 0.8944 - recall_m: 0.8216 - val_loss: 0.5247 - val_acc: 0.8548 - val_f1_m: 0.8764 - val_precision_m: 0.9180 - val_recall_m: 0.8389\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5243 - acc: 0.8656 - f1_m: 0.8589 - precision_m: 0.9005 - recall_m: 0.8220 - val_loss: 0.5201 - val_acc: 0.8548 - val_f1_m: 0.8839 - val_precision_m: 0.9189 - val_recall_m: 0.8528\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5194 - acc: 0.8557 - f1_m: 0.8598 - precision_m: 0.8942 - recall_m: 0.8287 - val_loss: 0.5570 - val_acc: 0.8629 - val_f1_m: 0.8609 - val_precision_m: 0.8925 - val_recall_m: 0.8317\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5368 - acc: 0.8458 - f1_m: 0.8486 - precision_m: 0.8812 - recall_m: 0.8190 - val_loss: 0.5294 - val_acc: 0.8548 - val_f1_m: 0.8709 - val_precision_m: 0.8982 - val_recall_m: 0.8461\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5255 - acc: 0.8512 - f1_m: 0.8501 - precision_m: 0.8920 - recall_m: 0.8125 - val_loss: 0.5139 - val_acc: 0.8710 - val_f1_m: 0.8833 - val_precision_m: 0.9252 - val_recall_m: 0.8456\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5326 - acc: 0.8584 - f1_m: 0.8630 - precision_m: 0.9030 - recall_m: 0.8273 - val_loss: 0.5324 - val_acc: 0.8790 - val_f1_m: 0.8676 - val_precision_m: 0.8986 - val_recall_m: 0.8389\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5273 - acc: 0.8584 - f1_m: 0.8616 - precision_m: 0.8990 - recall_m: 0.8286 - val_loss: 0.5287 - val_acc: 0.8629 - val_f1_m: 0.8679 - val_precision_m: 0.8917 - val_recall_m: 0.8461\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5424 - acc: 0.8557 - f1_m: 0.8522 - precision_m: 0.8839 - recall_m: 0.8234 - val_loss: 0.5519 - val_acc: 0.8468 - val_f1_m: 0.8471 - val_precision_m: 0.8783 - val_recall_m: 0.8183\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5539 - acc: 0.8476 - f1_m: 0.8423 - precision_m: 0.8828 - recall_m: 0.8060 - val_loss: 0.5831 - val_acc: 0.8387 - val_f1_m: 0.8459 - val_precision_m: 0.8834 - val_recall_m: 0.8117\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5489 - acc: 0.8422 - f1_m: 0.8498 - precision_m: 0.8874 - recall_m: 0.8160 - val_loss: 0.5651 - val_acc: 0.8548 - val_f1_m: 0.8593 - val_precision_m: 0.8969 - val_recall_m: 0.8250\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5382 - acc: 0.8548 - f1_m: 0.8551 - precision_m: 0.8930 - recall_m: 0.8213 - val_loss: 0.5224 - val_acc: 0.8548 - val_f1_m: 0.8705 - val_precision_m: 0.9048 - val_recall_m: 0.8389\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5218 - acc: 0.8593 - f1_m: 0.8554 - precision_m: 0.8929 - recall_m: 0.8216 - val_loss: 0.5140 - val_acc: 0.8710 - val_f1_m: 0.8873 - val_precision_m: 0.9259 - val_recall_m: 0.8522\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5169 - acc: 0.8629 - f1_m: 0.8632 - precision_m: 0.8975 - recall_m: 0.8321 - val_loss: 0.5572 - val_acc: 0.8548 - val_f1_m: 0.8541 - val_precision_m: 0.8855 - val_recall_m: 0.8250\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5320 - acc: 0.8611 - f1_m: 0.8650 - precision_m: 0.9030 - recall_m: 0.8308 - val_loss: 0.5210 - val_acc: 0.8468 - val_f1_m: 0.8738 - val_precision_m: 0.9046 - val_recall_m: 0.8461\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5132 - acc: 0.8665 - f1_m: 0.8641 - precision_m: 0.9031 - recall_m: 0.8291 - val_loss: 0.5657 - val_acc: 0.8548 - val_f1_m: 0.8618 - val_precision_m: 0.8862 - val_recall_m: 0.8389\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.5467 - acc: 0.8593 - f1_m: 0.8614 - precision_m: 0.8961 - recall_m: 0.8300 - val_loss: 0.5429 - val_acc: 0.8387 - val_f1_m: 0.8296 - val_precision_m: 0.8736 - val_recall_m: 0.7906\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.5354 - acc: 0.8611 - f1_m: 0.8625 - precision_m: 0.9020 - recall_m: 0.8273 - val_loss: 0.5128 - val_acc: 0.8548 - val_f1_m: 0.8556 - val_precision_m: 0.9147 - val_recall_m: 0.8039\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5376 - acc: 0.8584 - f1_m: 0.8524 - precision_m: 0.8932 - recall_m: 0.8160 - val_loss: 0.5095 - val_acc: 0.8306 - val_f1_m: 0.8563 - val_precision_m: 0.9082 - val_recall_m: 0.8106\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5334 - acc: 0.8602 - f1_m: 0.8652 - precision_m: 0.9006 - recall_m: 0.8330 - val_loss: 0.5033 - val_acc: 0.8387 - val_f1_m: 0.8494 - val_precision_m: 0.9011 - val_recall_m: 0.8039\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5182 - acc: 0.8702 - f1_m: 0.8730 - precision_m: 0.9088 - recall_m: 0.8404 - val_loss: 0.5102 - val_acc: 0.8387 - val_f1_m: 0.8563 - val_precision_m: 0.9082 - val_recall_m: 0.8106\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5279 - acc: 0.8683 - f1_m: 0.8656 - precision_m: 0.9019 - recall_m: 0.8326 - val_loss: 0.5281 - val_acc: 0.8226 - val_f1_m: 0.8394 - val_precision_m: 0.8868 - val_recall_m: 0.7972\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5320 - acc: 0.8629 - f1_m: 0.8604 - precision_m: 0.8966 - recall_m: 0.8286 - val_loss: 0.5240 - val_acc: 0.8306 - val_f1_m: 0.8493 - val_precision_m: 0.9011 - val_recall_m: 0.8039\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5308 - acc: 0.8611 - f1_m: 0.8602 - precision_m: 0.9050 - recall_m: 0.8220 - val_loss: 0.5121 - val_acc: 0.8468 - val_f1_m: 0.8563 - val_precision_m: 0.9082 - val_recall_m: 0.8106\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5255 - acc: 0.8647 - f1_m: 0.8638 - precision_m: 0.9032 - recall_m: 0.8282 - val_loss: 0.5142 - val_acc: 0.8629 - val_f1_m: 0.8536 - val_precision_m: 0.9020 - val_recall_m: 0.8106\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5147 - acc: 0.8620 - f1_m: 0.8626 - precision_m: 0.8991 - recall_m: 0.8300 - val_loss: 0.5756 - val_acc: 0.8468 - val_f1_m: 0.8355 - val_precision_m: 0.8862 - val_recall_m: 0.7906\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5271 - acc: 0.8557 - f1_m: 0.8629 - precision_m: 0.9011 - recall_m: 0.8287 - val_loss: 0.5118 - val_acc: 0.8468 - val_f1_m: 0.8467 - val_precision_m: 0.8949 - val_recall_m: 0.8039\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.5238 - acc: 0.8575 - f1_m: 0.8623 - precision_m: 0.8963 - recall_m: 0.8317 - val_loss: 0.5246 - val_acc: 0.8306 - val_f1_m: 0.8496 - val_precision_m: 0.9011 - val_recall_m: 0.8039\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.5109 - acc: 0.8620 - f1_m: 0.8632 - precision_m: 0.9053 - recall_m: 0.8260 - val_loss: 0.5082 - val_acc: 0.8629 - val_f1_m: 0.8486 - val_precision_m: 0.9073 - val_recall_m: 0.7972\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5148 - acc: 0.8683 - f1_m: 0.8546 - precision_m: 0.8892 - recall_m: 0.8229 - val_loss: 0.5197 - val_acc: 0.8629 - val_f1_m: 0.8566 - val_precision_m: 0.9089 - val_recall_m: 0.8106\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5300 - acc: 0.8683 - f1_m: 0.8609 - precision_m: 0.9014 - recall_m: 0.8247 - val_loss: 0.5467 - val_acc: 0.8387 - val_f1_m: 0.8555 - val_precision_m: 0.9148 - val_recall_m: 0.8039\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5106 - acc: 0.8647 - f1_m: 0.8660 - precision_m: 0.8983 - recall_m: 0.8369 - val_loss: 0.5247 - val_acc: 0.8629 - val_f1_m: 0.8536 - val_precision_m: 0.9020 - val_recall_m: 0.8106\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5230 - acc: 0.8665 - f1_m: 0.8593 - precision_m: 0.8973 - recall_m: 0.8251 - val_loss: 0.5438 - val_acc: 0.8468 - val_f1_m: 0.8386 - val_precision_m: 0.8933 - val_recall_m: 0.7906\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5304 - acc: 0.8602 - f1_m: 0.8532 - precision_m: 0.8881 - recall_m: 0.8221 - val_loss: 0.5341 - val_acc: 0.8468 - val_f1_m: 0.8565 - val_precision_m: 0.9083 - val_recall_m: 0.8106\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5242 - acc: 0.8620 - f1_m: 0.8563 - precision_m: 0.8946 - recall_m: 0.8225 - val_loss: 0.5675 - val_acc: 0.8306 - val_f1_m: 0.8181 - val_precision_m: 0.8643 - val_recall_m: 0.7767\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5378 - acc: 0.8584 - f1_m: 0.8632 - precision_m: 0.8985 - recall_m: 0.8313 - val_loss: 0.5519 - val_acc: 0.8226 - val_f1_m: 0.8288 - val_precision_m: 0.8723 - val_recall_m: 0.7900\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5168 - acc: 0.8629 - f1_m: 0.8628 - precision_m: 0.9015 - recall_m: 0.8282 - val_loss: 0.5344 - val_acc: 0.8306 - val_f1_m: 0.8465 - val_precision_m: 0.8944 - val_recall_m: 0.8039\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5133 - acc: 0.8702 - f1_m: 0.8645 - precision_m: 0.9006 - recall_m: 0.8317 - val_loss: 0.5432 - val_acc: 0.8387 - val_f1_m: 0.8475 - val_precision_m: 0.8888 - val_recall_m: 0.8106\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5101 - acc: 0.8584 - f1_m: 0.8693 - precision_m: 0.9096 - recall_m: 0.8334 - val_loss: 0.5760 - val_acc: 0.8306 - val_f1_m: 0.8181 - val_precision_m: 0.8643 - val_recall_m: 0.7767\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5353 - acc: 0.8512 - f1_m: 0.8502 - precision_m: 0.8886 - recall_m: 0.8160 - val_loss: 0.5307 - val_acc: 0.8387 - val_f1_m: 0.8538 - val_precision_m: 0.9021 - val_recall_m: 0.8106\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5226 - acc: 0.8593 - f1_m: 0.8721 - precision_m: 0.9127 - recall_m: 0.8357 - val_loss: 0.5371 - val_acc: 0.8387 - val_f1_m: 0.8496 - val_precision_m: 0.9011 - val_recall_m: 0.8039\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5061 - acc: 0.8638 - f1_m: 0.8718 - precision_m: 0.9050 - recall_m: 0.8417 - val_loss: 0.5317 - val_acc: 0.8387 - val_f1_m: 0.8496 - val_precision_m: 0.9011 - val_recall_m: 0.8039\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5222 - acc: 0.8656 - f1_m: 0.8567 - precision_m: 0.8942 - recall_m: 0.8229 - val_loss: 0.5364 - val_acc: 0.8468 - val_f1_m: 0.8496 - val_precision_m: 0.9011 - val_recall_m: 0.8039\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5365 - acc: 0.8503 - f1_m: 0.8592 - precision_m: 0.8903 - recall_m: 0.8308 - val_loss: 0.5395 - val_acc: 0.8468 - val_f1_m: 0.8427 - val_precision_m: 0.8938 - val_recall_m: 0.7972\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5080 - acc: 0.8702 - f1_m: 0.8567 - precision_m: 0.8942 - recall_m: 0.8229 - val_loss: 0.5758 - val_acc: 0.8226 - val_f1_m: 0.8181 - val_precision_m: 0.8643 - val_recall_m: 0.7767\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5270 - acc: 0.8647 - f1_m: 0.8527 - precision_m: 0.8941 - recall_m: 0.8159 - val_loss: 0.5526 - val_acc: 0.8387 - val_f1_m: 0.8446 - val_precision_m: 0.8999 - val_recall_m: 0.7967\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5140 - acc: 0.8720 - f1_m: 0.8731 - precision_m: 0.9101 - recall_m: 0.8400 - val_loss: 0.5729 - val_acc: 0.8226 - val_f1_m: 0.8251 - val_precision_m: 0.8717 - val_recall_m: 0.7833\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5154 - acc: 0.8738 - f1_m: 0.8674 - precision_m: 0.9115 - recall_m: 0.8286 - val_loss: 0.5701 - val_acc: 0.8226 - val_f1_m: 0.8151 - val_precision_m: 0.8577 - val_recall_m: 0.7767\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 1s 27ms/step - loss: 0.5202 - acc: 0.8683 - f1_m: 0.8591 - precision_m: 0.8952 - recall_m: 0.8264 - val_loss: 0.5543 - val_acc: 0.8387 - val_f1_m: 0.8274 - val_precision_m: 0.8847 - val_recall_m: 0.7772\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.5442 - acc: 0.8521 - f1_m: 0.8547 - precision_m: 0.8907 - recall_m: 0.8221 - val_loss: 0.5448 - val_acc: 0.8548 - val_f1_m: 0.8408 - val_precision_m: 0.8995 - val_recall_m: 0.7900\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5216 - acc: 0.8620 - f1_m: 0.8661 - precision_m: 0.9053 - recall_m: 0.8325 - val_loss: 0.5643 - val_acc: 0.8306 - val_f1_m: 0.8348 - val_precision_m: 0.8852 - val_recall_m: 0.7900\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5054 - acc: 0.8629 - f1_m: 0.8685 - precision_m: 0.9036 - recall_m: 0.8365 - val_loss: 0.5372 - val_acc: 0.8629 - val_f1_m: 0.8450 - val_precision_m: 0.9005 - val_recall_m: 0.7967\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5054 - acc: 0.8620 - f1_m: 0.8637 - precision_m: 0.9030 - recall_m: 0.8286 - val_loss: 0.5415 - val_acc: 0.8548 - val_f1_m: 0.8427 - val_precision_m: 0.8938 - val_recall_m: 0.7972\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5159 - acc: 0.8539 - f1_m: 0.8580 - precision_m: 0.9001 - recall_m: 0.8208 - val_loss: 0.5536 - val_acc: 0.8387 - val_f1_m: 0.8378 - val_precision_m: 0.8928 - val_recall_m: 0.7900\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5165 - acc: 0.8611 - f1_m: 0.8559 - precision_m: 0.9008 - recall_m: 0.8159 - val_loss: 0.5546 - val_acc: 0.8226 - val_f1_m: 0.8246 - val_precision_m: 0.8782 - val_recall_m: 0.7772\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5251 - acc: 0.8584 - f1_m: 0.8705 - precision_m: 0.9052 - recall_m: 0.8391 - val_loss: 0.5577 - val_acc: 0.8468 - val_f1_m: 0.8496 - val_precision_m: 0.9011 - val_recall_m: 0.8039\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5258 - acc: 0.8602 - f1_m: 0.8528 - precision_m: 0.8932 - recall_m: 0.8169 - val_loss: 0.5547 - val_acc: 0.8306 - val_f1_m: 0.8246 - val_precision_m: 0.8782 - val_recall_m: 0.7772\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5367 - acc: 0.8566 - f1_m: 0.8576 - precision_m: 0.8899 - recall_m: 0.8282 - val_loss: 0.5572 - val_acc: 0.8387 - val_f1_m: 0.8534 - val_precision_m: 0.9015 - val_recall_m: 0.8106\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5155 - acc: 0.8693 - f1_m: 0.8634 - precision_m: 0.8926 - recall_m: 0.8368 - val_loss: 0.6265 - val_acc: 0.8065 - val_f1_m: 0.8079 - val_precision_m: 0.8678 - val_recall_m: 0.7561\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5467 - acc: 0.8404 - f1_m: 0.8414 - precision_m: 0.8797 - recall_m: 0.8073 - val_loss: 0.5977 - val_acc: 0.8226 - val_f1_m: 0.8141 - val_precision_m: 0.8636 - val_recall_m: 0.7700\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5219 - acc: 0.8656 - f1_m: 0.8610 - precision_m: 0.9014 - recall_m: 0.8247 - val_loss: 0.5549 - val_acc: 0.8387 - val_f1_m: 0.8408 - val_precision_m: 0.8995 - val_recall_m: 0.7900\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5062 - acc: 0.8611 - f1_m: 0.8700 - precision_m: 0.9087 - recall_m: 0.8352 - val_loss: 0.5828 - val_acc: 0.8145 - val_f1_m: 0.8151 - val_precision_m: 0.8577 - val_recall_m: 0.7767\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5135 - acc: 0.8548 - f1_m: 0.8644 - precision_m: 0.9078 - recall_m: 0.8256 - val_loss: 0.5555 - val_acc: 0.8387 - val_f1_m: 0.8416 - val_precision_m: 0.8934 - val_recall_m: 0.7967\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5184 - acc: 0.8611 - f1_m: 0.8606 - precision_m: 0.9043 - recall_m: 0.8216 - val_loss: 0.5607 - val_acc: 0.8387 - val_f1_m: 0.8317 - val_precision_m: 0.8858 - val_recall_m: 0.7839\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5196 - acc: 0.8593 - f1_m: 0.8613 - precision_m: 0.8950 - recall_m: 0.8308 - val_loss: 0.5543 - val_acc: 0.8548 - val_f1_m: 0.8381 - val_precision_m: 0.8932 - val_recall_m: 0.7900\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5069 - acc: 0.8693 - f1_m: 0.8610 - precision_m: 0.8993 - recall_m: 0.8264 - val_loss: 0.5526 - val_acc: 0.8468 - val_f1_m: 0.8468 - val_precision_m: 0.8948 - val_recall_m: 0.8039\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5316 - acc: 0.8638 - f1_m: 0.8534 - precision_m: 0.8997 - recall_m: 0.8125 - val_loss: 0.4851 - val_acc: 0.8710 - val_f1_m: 0.8757 - val_precision_m: 0.9183 - val_recall_m: 0.8372\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5269 - acc: 0.8638 - f1_m: 0.8664 - precision_m: 0.9034 - recall_m: 0.8330 - val_loss: 0.4867 - val_acc: 0.8710 - val_f1_m: 0.8609 - val_precision_m: 0.9024 - val_recall_m: 0.8233\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5063 - acc: 0.8656 - f1_m: 0.8551 - precision_m: 0.8961 - recall_m: 0.8186 - val_loss: 0.4891 - val_acc: 0.8871 - val_f1_m: 0.8577 - val_precision_m: 0.8956 - val_recall_m: 0.8233\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5106 - acc: 0.8638 - f1_m: 0.8579 - precision_m: 0.8944 - recall_m: 0.8251 - val_loss: 0.4930 - val_acc: 0.8871 - val_f1_m: 0.8595 - val_precision_m: 0.8838 - val_recall_m: 0.8367\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5241 - acc: 0.8683 - f1_m: 0.8555 - precision_m: 0.8935 - recall_m: 0.8212 - val_loss: 0.4888 - val_acc: 0.8548 - val_f1_m: 0.8579 - val_precision_m: 0.8962 - val_recall_m: 0.8233\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5084 - acc: 0.8729 - f1_m: 0.8717 - precision_m: 0.9130 - recall_m: 0.8348 - val_loss: 0.4911 - val_acc: 0.8629 - val_f1_m: 0.8609 - val_precision_m: 0.9024 - val_recall_m: 0.8233\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5224 - acc: 0.8557 - f1_m: 0.8545 - precision_m: 0.8964 - recall_m: 0.8169 - val_loss: 0.4942 - val_acc: 0.8629 - val_f1_m: 0.8609 - val_precision_m: 0.9024 - val_recall_m: 0.8233\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5174 - acc: 0.8602 - f1_m: 0.8634 - precision_m: 0.9016 - recall_m: 0.8291 - val_loss: 0.4909 - val_acc: 0.8710 - val_f1_m: 0.8609 - val_precision_m: 0.9024 - val_recall_m: 0.8233\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5234 - acc: 0.8557 - f1_m: 0.8614 - precision_m: 0.8974 - recall_m: 0.8287 - val_loss: 0.4948 - val_acc: 0.8871 - val_f1_m: 0.8461 - val_precision_m: 0.8866 - val_recall_m: 0.8094\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5141 - acc: 0.8629 - f1_m: 0.8697 - precision_m: 0.9094 - recall_m: 0.8343 - val_loss: 0.4949 - val_acc: 0.8710 - val_f1_m: 0.8609 - val_precision_m: 0.9024 - val_recall_m: 0.8233\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5144 - acc: 0.8665 - f1_m: 0.8723 - precision_m: 0.9070 - recall_m: 0.8409 - val_loss: 0.4974 - val_acc: 0.8710 - val_f1_m: 0.8757 - val_precision_m: 0.9183 - val_recall_m: 0.8372\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5310 - acc: 0.8593 - f1_m: 0.8496 - precision_m: 0.8874 - recall_m: 0.8155 - val_loss: 0.5231 - val_acc: 0.8790 - val_f1_m: 0.8477 - val_precision_m: 0.8819 - val_recall_m: 0.8167\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5324 - acc: 0.8530 - f1_m: 0.8555 - precision_m: 0.8988 - recall_m: 0.8173 - val_loss: 0.5050 - val_acc: 0.8629 - val_f1_m: 0.8602 - val_precision_m: 0.9087 - val_recall_m: 0.8167\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5165 - acc: 0.8620 - f1_m: 0.8600 - precision_m: 0.9012 - recall_m: 0.8234 - val_loss: 0.5026 - val_acc: 0.8629 - val_f1_m: 0.8641 - val_precision_m: 0.9095 - val_recall_m: 0.8233\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5303 - acc: 0.8566 - f1_m: 0.8538 - precision_m: 0.9013 - recall_m: 0.8121 - val_loss: 0.5803 - val_acc: 0.8468 - val_f1_m: 0.8240 - val_precision_m: 0.8972 - val_recall_m: 0.7628\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5277 - acc: 0.8593 - f1_m: 0.8626 - precision_m: 0.8962 - recall_m: 0.8322 - val_loss: 0.5194 - val_acc: 0.8548 - val_f1_m: 0.8609 - val_precision_m: 0.9024 - val_recall_m: 0.8233\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5157 - acc: 0.8620 - f1_m: 0.8594 - precision_m: 0.8962 - recall_m: 0.8260 - val_loss: 0.5073 - val_acc: 0.8871 - val_f1_m: 0.8466 - val_precision_m: 0.8802 - val_recall_m: 0.8161\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5060 - acc: 0.8647 - f1_m: 0.8691 - precision_m: 0.9045 - recall_m: 0.8374 - val_loss: 0.5076 - val_acc: 0.8790 - val_f1_m: 0.8466 - val_precision_m: 0.8802 - val_recall_m: 0.8161\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5172 - acc: 0.8629 - f1_m: 0.8573 - precision_m: 0.9002 - recall_m: 0.8190 - val_loss: 0.5066 - val_acc: 0.8710 - val_f1_m: 0.8466 - val_precision_m: 0.8802 - val_recall_m: 0.8161\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5129 - acc: 0.8729 - f1_m: 0.8592 - precision_m: 0.9023 - recall_m: 0.8212 - val_loss: 0.5099 - val_acc: 0.8710 - val_f1_m: 0.8466 - val_precision_m: 0.8802 - val_recall_m: 0.8161\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5284 - acc: 0.8476 - f1_m: 0.8576 - precision_m: 0.8961 - recall_m: 0.8230 - val_loss: 0.5070 - val_acc: 0.8629 - val_f1_m: 0.8518 - val_precision_m: 0.9000 - val_recall_m: 0.8094\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5383 - acc: 0.8530 - f1_m: 0.8545 - precision_m: 0.8922 - recall_m: 0.8204 - val_loss: 0.5102 - val_acc: 0.8710 - val_f1_m: 0.8466 - val_precision_m: 0.8802 - val_recall_m: 0.8161\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5120 - acc: 0.8638 - f1_m: 0.8750 - precision_m: 0.9100 - recall_m: 0.8435 - val_loss: 0.5158 - val_acc: 0.8629 - val_f1_m: 0.8569 - val_precision_m: 0.9017 - val_recall_m: 0.8167\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5082 - acc: 0.8702 - f1_m: 0.8641 - precision_m: 0.9074 - recall_m: 0.8268 - val_loss: 0.5097 - val_acc: 0.8629 - val_f1_m: 0.8569 - val_precision_m: 0.9017 - val_recall_m: 0.8167\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5265 - acc: 0.8512 - f1_m: 0.8526 - precision_m: 0.8896 - recall_m: 0.8194 - val_loss: 0.5213 - val_acc: 0.8548 - val_f1_m: 0.8491 - val_precision_m: 0.9005 - val_recall_m: 0.8033\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5093 - acc: 0.8693 - f1_m: 0.8697 - precision_m: 0.9032 - recall_m: 0.8395 - val_loss: 0.5077 - val_acc: 0.8629 - val_f1_m: 0.8461 - val_precision_m: 0.8866 - val_recall_m: 0.8094\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5207 - acc: 0.8702 - f1_m: 0.8624 - precision_m: 0.9005 - recall_m: 0.8277 - val_loss: 0.5110 - val_acc: 0.8629 - val_f1_m: 0.8461 - val_precision_m: 0.8866 - val_recall_m: 0.8094\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5007 - acc: 0.8647 - f1_m: 0.8661 - precision_m: 0.9079 - recall_m: 0.8282 - val_loss: 0.5560 - val_acc: 0.8548 - val_f1_m: 0.8327 - val_precision_m: 0.8563 - val_recall_m: 0.8106\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5225 - acc: 0.8629 - f1_m: 0.8532 - precision_m: 0.8924 - recall_m: 0.8182 - val_loss: 0.5113 - val_acc: 0.8629 - val_f1_m: 0.8466 - val_precision_m: 0.8802 - val_recall_m: 0.8161\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5056 - acc: 0.8647 - f1_m: 0.8721 - precision_m: 0.9126 - recall_m: 0.8360 - val_loss: 0.5178 - val_acc: 0.8629 - val_f1_m: 0.8461 - val_precision_m: 0.8866 - val_recall_m: 0.8094\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5006 - acc: 0.8665 - f1_m: 0.8642 - precision_m: 0.9013 - recall_m: 0.8308 - val_loss: 0.5307 - val_acc: 0.8548 - val_f1_m: 0.8561 - val_precision_m: 0.9079 - val_recall_m: 0.8100\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5059 - acc: 0.8602 - f1_m: 0.8625 - precision_m: 0.9034 - recall_m: 0.8260 - val_loss: 0.5128 - val_acc: 0.8629 - val_f1_m: 0.8461 - val_precision_m: 0.8866 - val_recall_m: 0.8094\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5114 - acc: 0.8557 - f1_m: 0.8644 - precision_m: 0.9016 - recall_m: 0.8308 - val_loss: 0.5129 - val_acc: 0.8710 - val_f1_m: 0.8579 - val_precision_m: 0.8962 - val_recall_m: 0.8233\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5133 - acc: 0.8530 - f1_m: 0.8579 - precision_m: 0.8982 - recall_m: 0.8221 - val_loss: 0.5306 - val_acc: 0.8548 - val_f1_m: 0.8561 - val_precision_m: 0.9079 - val_recall_m: 0.8100\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5153 - acc: 0.8647 - f1_m: 0.8560 - precision_m: 0.8965 - recall_m: 0.8203 - val_loss: 0.5203 - val_acc: 0.8790 - val_f1_m: 0.8396 - val_precision_m: 0.8731 - val_recall_m: 0.8094\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5000 - acc: 0.8711 - f1_m: 0.8573 - precision_m: 0.8947 - recall_m: 0.8233 - val_loss: 0.5431 - val_acc: 0.8468 - val_f1_m: 0.8531 - val_precision_m: 0.9013 - val_recall_m: 0.8100\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5124 - acc: 0.8683 - f1_m: 0.8669 - precision_m: 0.9042 - recall_m: 0.8330 - val_loss: 0.5293 - val_acc: 0.8548 - val_f1_m: 0.8602 - val_precision_m: 0.9087 - val_recall_m: 0.8167\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5027 - acc: 0.8638 - f1_m: 0.8559 - precision_m: 0.8873 - recall_m: 0.8277 - val_loss: 0.5139 - val_acc: 0.8629 - val_f1_m: 0.8612 - val_precision_m: 0.9033 - val_recall_m: 0.8233\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5291 - acc: 0.8530 - f1_m: 0.8488 - precision_m: 0.8860 - recall_m: 0.8151 - val_loss: 0.5201 - val_acc: 0.8629 - val_f1_m: 0.8461 - val_precision_m: 0.8866 - val_recall_m: 0.8094\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5158 - acc: 0.8584 - f1_m: 0.8510 - precision_m: 0.8913 - recall_m: 0.8155 - val_loss: 0.5435 - val_acc: 0.8629 - val_f1_m: 0.8441 - val_precision_m: 0.8991 - val_recall_m: 0.7961\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5207 - acc: 0.8620 - f1_m: 0.8671 - precision_m: 0.9083 - recall_m: 0.8304 - val_loss: 0.5177 - val_acc: 0.8710 - val_f1_m: 0.8551 - val_precision_m: 0.8894 - val_recall_m: 0.8233\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5051 - acc: 0.8683 - f1_m: 0.8611 - precision_m: 0.8985 - recall_m: 0.8272 - val_loss: 0.5188 - val_acc: 0.8629 - val_f1_m: 0.8461 - val_precision_m: 0.8866 - val_recall_m: 0.8094\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4985 - acc: 0.8765 - f1_m: 0.8714 - precision_m: 0.9090 - recall_m: 0.8373 - val_loss: 0.5303 - val_acc: 0.8548 - val_f1_m: 0.8398 - val_precision_m: 0.8731 - val_recall_m: 0.8094\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5071 - acc: 0.8620 - f1_m: 0.8675 - precision_m: 0.9054 - recall_m: 0.8339 - val_loss: 0.5347 - val_acc: 0.8629 - val_f1_m: 0.8561 - val_precision_m: 0.9079 - val_recall_m: 0.8100\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5033 - acc: 0.8756 - f1_m: 0.8704 - precision_m: 0.9114 - recall_m: 0.8334 - val_loss: 0.5239 - val_acc: 0.8629 - val_f1_m: 0.8431 - val_precision_m: 0.8803 - val_recall_m: 0.8094\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5298 - acc: 0.8548 - f1_m: 0.8589 - precision_m: 0.8951 - recall_m: 0.8265 - val_loss: 0.5459 - val_acc: 0.8629 - val_f1_m: 0.8532 - val_precision_m: 0.9015 - val_recall_m: 0.8100\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4947 - acc: 0.8720 - f1_m: 0.8617 - precision_m: 0.8995 - recall_m: 0.8276 - val_loss: 0.5274 - val_acc: 0.8629 - val_f1_m: 0.8612 - val_precision_m: 0.9033 - val_recall_m: 0.8233\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5042 - acc: 0.8683 - f1_m: 0.8732 - precision_m: 0.9079 - recall_m: 0.8417 - val_loss: 0.5256 - val_acc: 0.8629 - val_f1_m: 0.8461 - val_precision_m: 0.8866 - val_recall_m: 0.8094\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4920 - acc: 0.8665 - f1_m: 0.8726 - precision_m: 0.9152 - recall_m: 0.8347 - val_loss: 0.5320 - val_acc: 0.8629 - val_f1_m: 0.8561 - val_precision_m: 0.9079 - val_recall_m: 0.8100\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4912 - acc: 0.8765 - f1_m: 0.8741 - precision_m: 0.9137 - recall_m: 0.8386 - val_loss: 0.5305 - val_acc: 0.8629 - val_f1_m: 0.8561 - val_precision_m: 0.9079 - val_recall_m: 0.8100\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5163 - acc: 0.8593 - f1_m: 0.8530 - precision_m: 0.8959 - recall_m: 0.8147 - val_loss: 0.5008 - val_acc: 0.8871 - val_f1_m: 0.8631 - val_precision_m: 0.9360 - val_recall_m: 0.8033\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4982 - acc: 0.8674 - f1_m: 0.8748 - precision_m: 0.9145 - recall_m: 0.8391 - val_loss: 0.4993 - val_acc: 0.8952 - val_f1_m: 0.8674 - val_precision_m: 0.9368 - val_recall_m: 0.8100\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5052 - acc: 0.8647 - f1_m: 0.8617 - precision_m: 0.8994 - recall_m: 0.8281 - val_loss: 0.5068 - val_acc: 0.8790 - val_f1_m: 0.8631 - val_precision_m: 0.9360 - val_recall_m: 0.8033\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5080 - acc: 0.8656 - f1_m: 0.8617 - precision_m: 0.9005 - recall_m: 0.8269 - val_loss: 0.5105 - val_acc: 0.8790 - val_f1_m: 0.8638 - val_precision_m: 0.9358 - val_recall_m: 0.8039\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5058 - acc: 0.8702 - f1_m: 0.8593 - precision_m: 0.8936 - recall_m: 0.8281 - val_loss: 0.5102 - val_acc: 0.8871 - val_f1_m: 0.8587 - val_precision_m: 0.9352 - val_recall_m: 0.7967\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5061 - acc: 0.8638 - f1_m: 0.8611 - precision_m: 0.9054 - recall_m: 0.8216 - val_loss: 0.5090 - val_acc: 0.8790 - val_f1_m: 0.8587 - val_precision_m: 0.9352 - val_recall_m: 0.7967\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5134 - acc: 0.8557 - f1_m: 0.8597 - precision_m: 0.8943 - recall_m: 0.8282 - val_loss: 0.5123 - val_acc: 0.8871 - val_f1_m: 0.8587 - val_precision_m: 0.9352 - val_recall_m: 0.7967\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4964 - acc: 0.8674 - f1_m: 0.8725 - precision_m: 0.9124 - recall_m: 0.8365 - val_loss: 0.5117 - val_acc: 0.8548 - val_f1_m: 0.8631 - val_precision_m: 0.9360 - val_recall_m: 0.8033\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4994 - acc: 0.8683 - f1_m: 0.8650 - precision_m: 0.9029 - recall_m: 0.8312 - val_loss: 0.5097 - val_acc: 0.8710 - val_f1_m: 0.8587 - val_precision_m: 0.9352 - val_recall_m: 0.7967\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4980 - acc: 0.8720 - f1_m: 0.8719 - precision_m: 0.9067 - recall_m: 0.8404 - val_loss: 0.5338 - val_acc: 0.8710 - val_f1_m: 0.8689 - val_precision_m: 0.9298 - val_recall_m: 0.8172\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4985 - acc: 0.8693 - f1_m: 0.8694 - precision_m: 0.9053 - recall_m: 0.8374 - val_loss: 0.5418 - val_acc: 0.8468 - val_f1_m: 0.8448 - val_precision_m: 0.8994 - val_recall_m: 0.7972\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4951 - acc: 0.8729 - f1_m: 0.8699 - precision_m: 0.9105 - recall_m: 0.8343 - val_loss: 0.5198 - val_acc: 0.8548 - val_f1_m: 0.8549 - val_precision_m: 0.9075 - val_recall_m: 0.8100\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5036 - acc: 0.8665 - f1_m: 0.8675 - precision_m: 0.9028 - recall_m: 0.8357 - val_loss: 0.5220 - val_acc: 0.8710 - val_f1_m: 0.8549 - val_precision_m: 0.9149 - val_recall_m: 0.8039\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5089 - acc: 0.8674 - f1_m: 0.8630 - precision_m: 0.9094 - recall_m: 0.8221 - val_loss: 0.5252 - val_acc: 0.8790 - val_f1_m: 0.8719 - val_precision_m: 0.9369 - val_recall_m: 0.8172\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4998 - acc: 0.8720 - f1_m: 0.8765 - precision_m: 0.9143 - recall_m: 0.8426 - val_loss: 0.5928 - val_acc: 0.8387 - val_f1_m: 0.8385 - val_precision_m: 0.8755 - val_recall_m: 0.8044\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5012 - acc: 0.8665 - f1_m: 0.8648 - precision_m: 0.9032 - recall_m: 0.8303 - val_loss: 0.5324 - val_acc: 0.8548 - val_f1_m: 0.8591 - val_precision_m: 0.9084 - val_recall_m: 0.8167\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4876 - acc: 0.8620 - f1_m: 0.8638 - precision_m: 0.9030 - recall_m: 0.8286 - val_loss: 0.5317 - val_acc: 0.8710 - val_f1_m: 0.8587 - val_precision_m: 0.9352 - val_recall_m: 0.7967\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4937 - acc: 0.8638 - f1_m: 0.8691 - precision_m: 0.9073 - recall_m: 0.8348 - val_loss: 0.5201 - val_acc: 0.8629 - val_f1_m: 0.8445 - val_precision_m: 0.9200 - val_recall_m: 0.7833\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5091 - acc: 0.8611 - f1_m: 0.8629 - precision_m: 0.9051 - recall_m: 0.8256 - val_loss: 0.5540 - val_acc: 0.8468 - val_f1_m: 0.8482 - val_precision_m: 0.9007 - val_recall_m: 0.8033\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5034 - acc: 0.8629 - f1_m: 0.8666 - precision_m: 0.9134 - recall_m: 0.8251 - val_loss: 0.5298 - val_acc: 0.8548 - val_f1_m: 0.8492 - val_precision_m: 0.9129 - val_recall_m: 0.7967\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5056 - acc: 0.8575 - f1_m: 0.8544 - precision_m: 0.8869 - recall_m: 0.8246 - val_loss: 0.5654 - val_acc: 0.8629 - val_f1_m: 0.8528 - val_precision_m: 0.9009 - val_recall_m: 0.8106\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4992 - acc: 0.8702 - f1_m: 0.8573 - precision_m: 0.8913 - recall_m: 0.8268 - val_loss: 0.6053 - val_acc: 0.8145 - val_f1_m: 0.8150 - val_precision_m: 0.8680 - val_recall_m: 0.7694\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5193 - acc: 0.8575 - f1_m: 0.8556 - precision_m: 0.8918 - recall_m: 0.8230 - val_loss: 0.5880 - val_acc: 0.8306 - val_f1_m: 0.8338 - val_precision_m: 0.8852 - val_recall_m: 0.7900\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5052 - acc: 0.8593 - f1_m: 0.8635 - precision_m: 0.8979 - recall_m: 0.8322 - val_loss: 0.5397 - val_acc: 0.8629 - val_f1_m: 0.8504 - val_precision_m: 0.9137 - val_recall_m: 0.7972\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5033 - acc: 0.8647 - f1_m: 0.8642 - precision_m: 0.9004 - recall_m: 0.8317 - val_loss: 0.5674 - val_acc: 0.8226 - val_f1_m: 0.8439 - val_precision_m: 0.8998 - val_recall_m: 0.7967\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5039 - acc: 0.8711 - f1_m: 0.8629 - precision_m: 0.9072 - recall_m: 0.8234 - val_loss: 0.5321 - val_acc: 0.8548 - val_f1_m: 0.8448 - val_precision_m: 0.9195 - val_recall_m: 0.7833\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.4967 - acc: 0.8720 - f1_m: 0.8655 - precision_m: 0.9075 - recall_m: 0.8281 - val_loss: 0.5357 - val_acc: 0.8468 - val_f1_m: 0.8416 - val_precision_m: 0.9128 - val_recall_m: 0.7833\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.4837 - acc: 0.8783 - f1_m: 0.8754 - precision_m: 0.9144 - recall_m: 0.8404 - val_loss: 0.5317 - val_acc: 0.8629 - val_f1_m: 0.8462 - val_precision_m: 0.9056 - val_recall_m: 0.7967\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5006 - acc: 0.8620 - f1_m: 0.8657 - precision_m: 0.9013 - recall_m: 0.8334 - val_loss: 0.5297 - val_acc: 0.8548 - val_f1_m: 0.8426 - val_precision_m: 0.9052 - val_recall_m: 0.7900\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4924 - acc: 0.8683 - f1_m: 0.8648 - precision_m: 0.9006 - recall_m: 0.8321 - val_loss: 0.5721 - val_acc: 0.8387 - val_f1_m: 0.8350 - val_precision_m: 0.8978 - val_recall_m: 0.7833\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5123 - acc: 0.8611 - f1_m: 0.8656 - precision_m: 0.9007 - recall_m: 0.8339 - val_loss: 0.5594 - val_acc: 0.8548 - val_f1_m: 0.8481 - val_precision_m: 0.9079 - val_recall_m: 0.7972\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4992 - acc: 0.8747 - f1_m: 0.8674 - precision_m: 0.9051 - recall_m: 0.8334 - val_loss: 0.5353 - val_acc: 0.8387 - val_f1_m: 0.8416 - val_precision_m: 0.9128 - val_recall_m: 0.7833\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4867 - acc: 0.8693 - f1_m: 0.8657 - precision_m: 0.9114 - recall_m: 0.8264 - val_loss: 0.5469 - val_acc: 0.8629 - val_f1_m: 0.8557 - val_precision_m: 0.9279 - val_recall_m: 0.7967\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4937 - acc: 0.8683 - f1_m: 0.8715 - precision_m: 0.9082 - recall_m: 0.8386 - val_loss: 0.5649 - val_acc: 0.8387 - val_f1_m: 0.8448 - val_precision_m: 0.8994 - val_recall_m: 0.7972\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4933 - acc: 0.8702 - f1_m: 0.8592 - precision_m: 0.9027 - recall_m: 0.8207 - val_loss: 0.5432 - val_acc: 0.8790 - val_f1_m: 0.8557 - val_precision_m: 0.9279 - val_recall_m: 0.7967\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5153 - acc: 0.8611 - f1_m: 0.8653 - precision_m: 0.9033 - recall_m: 0.8313 - val_loss: 0.5497 - val_acc: 0.8790 - val_f1_m: 0.8557 - val_precision_m: 0.9279 - val_recall_m: 0.7967\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5099 - acc: 0.8629 - f1_m: 0.8597 - precision_m: 0.8969 - recall_m: 0.8260 - val_loss: 0.5430 - val_acc: 0.8468 - val_f1_m: 0.8416 - val_precision_m: 0.9128 - val_recall_m: 0.7833\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4896 - acc: 0.8656 - f1_m: 0.8724 - precision_m: 0.9108 - recall_m: 0.8378 - val_loss: 0.5550 - val_acc: 0.8468 - val_f1_m: 0.8438 - val_precision_m: 0.9186 - val_recall_m: 0.7833\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.4943 - acc: 0.8702 - f1_m: 0.8664 - precision_m: 0.9078 - recall_m: 0.8295 - val_loss: 0.5493 - val_acc: 0.8548 - val_f1_m: 0.8416 - val_precision_m: 0.9128 - val_recall_m: 0.7833\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.4936 - acc: 0.8665 - f1_m: 0.8632 - precision_m: 0.9052 - recall_m: 0.8255 - val_loss: 0.5474 - val_acc: 0.8226 - val_f1_m: 0.8288 - val_precision_m: 0.8898 - val_recall_m: 0.7767\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4992 - acc: 0.8593 - f1_m: 0.8613 - precision_m: 0.9070 - recall_m: 0.8204 - val_loss: 0.5558 - val_acc: 0.8548 - val_f1_m: 0.8370 - val_precision_m: 0.9116 - val_recall_m: 0.7767\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5022 - acc: 0.8530 - f1_m: 0.8570 - precision_m: 0.8934 - recall_m: 0.8243 - val_loss: 0.5906 - val_acc: 0.8387 - val_f1_m: 0.8379 - val_precision_m: 0.8923 - val_recall_m: 0.7906\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4887 - acc: 0.8702 - f1_m: 0.8582 - precision_m: 0.8998 - recall_m: 0.8212 - val_loss: 0.5581 - val_acc: 0.8468 - val_f1_m: 0.8370 - val_precision_m: 0.9116 - val_recall_m: 0.7767\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4958 - acc: 0.8720 - f1_m: 0.8609 - precision_m: 0.8930 - recall_m: 0.8316 - val_loss: 0.5506 - val_acc: 0.8468 - val_f1_m: 0.8416 - val_precision_m: 0.9128 - val_recall_m: 0.7833\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4902 - acc: 0.8693 - f1_m: 0.8699 - precision_m: 0.9149 - recall_m: 0.8303 - val_loss: 0.5634 - val_acc: 0.8710 - val_f1_m: 0.8601 - val_precision_m: 0.9278 - val_recall_m: 0.8039\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4849 - acc: 0.8801 - f1_m: 0.8688 - precision_m: 0.9190 - recall_m: 0.8259 - val_loss: 0.5496 - val_acc: 0.8387 - val_f1_m: 0.8353 - val_precision_m: 0.8971 - val_recall_m: 0.7833\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4854 - acc: 0.8711 - f1_m: 0.8668 - precision_m: 0.9049 - recall_m: 0.8329 - val_loss: 0.5642 - val_acc: 0.8548 - val_f1_m: 0.8494 - val_precision_m: 0.9121 - val_recall_m: 0.7967\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4854 - acc: 0.8602 - f1_m: 0.8656 - precision_m: 0.9054 - recall_m: 0.8295 - val_loss: 0.5819 - val_acc: 0.8548 - val_f1_m: 0.8564 - val_precision_m: 0.9275 - val_recall_m: 0.7972\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4884 - acc: 0.8693 - f1_m: 0.8580 - precision_m: 0.8983 - recall_m: 0.8220 - val_loss: 0.5865 - val_acc: 0.8468 - val_f1_m: 0.8520 - val_precision_m: 0.9073 - val_recall_m: 0.8039\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5051 - acc: 0.8566 - f1_m: 0.8550 - precision_m: 0.8923 - recall_m: 0.8212 - val_loss: 0.5653 - val_acc: 0.8387 - val_f1_m: 0.8462 - val_precision_m: 0.9056 - val_recall_m: 0.7967\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        if i==0:\n",
    "            r=70\n",
    "        elif i== 1:\n",
    "            r=80\n",
    "        elif i== 2:\n",
    "            r=90\n",
    "        elif i== 3:\n",
    "            r=100\n",
    "        elif i== 4:\n",
    "            r=130\n",
    "        elif i==6:\n",
    "            r=120\n",
    "        elif i==7:\n",
    "            r=50\n",
    "        elif i==8:\n",
    "            r=60\n",
    "        elif i==9:\n",
    "            r=30\n",
    "        elif i==5:\n",
    "            r=10\n",
    "        \n",
    "        X_t, X_val, y_t, y_val = train_test_split(X_train, y_train, test_size=0.10, stratify= y_train, shuffle=True, random_state=r)\n",
    "        h=model.fit(X_t, y_t, epochs=50, batch_size=50,  verbose=1,shuffle=True, validation_data=(X_val,y_val))\n",
    "\n",
    "        my_dict_Train[\"Accuracy_Train\"].append(round(100*np.mean(h.history['val_acc']),2))\n",
    "        my_dict_STD[\"Accuracy_Train\"].append(round(100*np.std(h.history['val_acc']), 2))\n",
    "        my_dict_Train[\"Precision_Train\"].append(round(100*np.mean(h.history['val_precision_m']),2))\n",
    "        my_dict_STD[\"Precision_Train\"].append(round(100*np.std(h.history['val_precision_m']), 2))\n",
    "        my_dict_Train[\"Recall_Train\"].append(round(100*np.mean(h.history['val_recall_m']),2))\n",
    "        my_dict_STD[\"Recall_Train\"].append(round(100*np.std(h.history['val_recall_m']), 2))\n",
    "        my_dict_Train[\"F1_score_Train\"].append(round(100*np.mean(h.history['val_f1_m']),2))\n",
    "        my_dict_STD[\"F1_score_Train\"].append(round(100*np.std(h.history['val_f1_m']), 2))\n",
    "        y_p = model.predict(X_test)\n",
    "        y_pred= np.argmax(y_p, axis=1)\n",
    "        my_dict_Test[\"Accuracy_Test\"].append(round(100*accuracy_score(y_test,y_pred), 2))\n",
    "        my_dict_Test[\"Precision_Test\"].append(round(100*precision_score(y_test, y_pred, average='weighted'), 2))\n",
    "        my_dict_Test[\"Recall_Test\"].append(round(100*recall_score(y_test, y_pred, average='weighted'), 2))\n",
    "        my_dict_Test[\"F1_score_Test\"].append(round(100*f1_score(y_test, y_pred, average='weighted') , 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Train: 85.358\n",
      "Accuracy_Train_STD: 1.223\n",
      "Precision_Train: 89.056\n",
      "Precision_Train_STD: 1.236\n",
      "Recall_Train: 82.009\n",
      "Recall_Train_STD: 1.182\n",
      "F1_score_Train: 85.333\n",
      "F1_score_Train_STD: 1.067\n"
     ]
    }
   ],
   "source": [
    "for metric in my_dict_Train.keys():\n",
    "    print(\"%s: %.3f\" % (metric, average(my_dict_Train[metric])))\n",
    "    print(\"%s: %.3f\" % (metric+\"_STD\", average(my_dict_STD[metric])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Test: 80.000\n",
      "Precision_Test: 77.785\n",
      "Recall_Test: 80.000\n",
      "F1_score_Test: 77.330\n"
     ]
    }
   ],
   "source": [
    "for metric in my_dict_Test.keys():\n",
    "    print(\"%s: %.3f\" % (metric, average(my_dict_Test[metric])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
